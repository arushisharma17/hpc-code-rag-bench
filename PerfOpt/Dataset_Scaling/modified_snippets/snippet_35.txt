/*\n ******************************************************************\n * HISTORY\n * 15-Oct-94  Jeff Shufelt (js), Carnegie Mellon University\n *	Prepared for 15-681, Fall 1994.\n * Modified by Shuai Che\n ******************************************************************\n */\n\n#include <omp.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include "backprop.h"\n#include <math.h>\n#define OPEN\n\n#define ABS(x)          (((x) > 0.0) ? (x) : (-(x)))\n\n#define fastcopy(to,from,len)\\n{\\n  register char *_to,*_from;\\n  register int _i,_l;\\n  _to = (char *)(to);\\n  _from = (char *)(from);\\n  _l = (len);\\n  for (_i = 0; _i < _l; _i++) *_to++ = *_from++;\\n}\n\n/*** Return random number between 0.0 and 1.0 ***/\nfloat drnd()\n{\n  return ((float) rand() / (float) BIGRND);\n}\n\n/*** Return random number between -1.0 and 1.0 ***/\nfloat dpn1()\n{\n  return ((drnd() * 2.0) - 1.0);\n}\n\n/*** The squashing function.  Currently, it's a sigmoid. ***/\n\nfloat squash(x)\nfloat x;\n{\n  float m;\n  //x = -x;\n  //m = 1 + x + x*x/2 + x*x*x/6 + x*x*x*x/24 + x*x*x*x*x/120;\n  //return(1.0 / (1.0 + m));\n  return (1.0 / (1.0 + exp(-x)));\n}\n\n\n/*** Allocate 1d array of floats ***/\n\nfloat *alloc_1d_dbl(n)\nint n;\n{\n  float *new;\n\n  new = (float *) malloc ((unsigned) (n * sizeof (float)));\n  if (new == NULL) {\n    printf("ALLOC_1D_DBL: Couldn't allocate array of floats\n");\n    return (NULL);\n  }\n  return (new);\n}\n\n\n/*** Allocate 2d array of floats ***/\n\nfloat **alloc_2d_dbl(m, n)\nint m, n;\n{\n  int i;\n  float **new;\n\n  new = (float **) malloc ((unsigned) (m * sizeof (float *)));\n  if (new == NULL) {\n    printf("ALLOC_2D_DBL: Couldn't allocate array of dbl ptrs\n");\n    return (NULL);\n  }\n\n  for (i = 0; i < m; i++) {\n    new[i] = alloc_1d_dbl(n);\n  }\n\n  return (new);\n}\n\n\nbpnn_randomize_weights(w, m, n)\nfloat **w;\nint m, n;\n{\n  int i, j;\n\n  for (i = 0; i <= m; i++) {\n    for (j = 0; j <= n; j++) {\n     w[i][j] = (float) rand()/RAND_MAX;\n    //  w[i][j] = dpn1();\n    }\n  }\n}\n\nbpnn_randomize_row(w, m)\nfloat *w;\nint m;\n{\n	int i;\n	for (i = 0; i <= m; i++) {\n     //w[i] = (float) rand()/RAND_MAX;\n	 w[i] = 0.1;\n    }\n}\n\n\nbpnn_zero_weights(w, m, n)\nfloat **w;\nint m, n;\n{\n  int i, j;\n\n  for (i = 0; i <= m; i++) {\n    for (j = 0; j <= n; j++) {\n      w[i][j] = 0.0;\n    }\n  }\n}\n\n\nvoid bpnn_initialize(seed)\n{\n  printf("Random number generator seed: %d\n", seed);\n  srand(seed);\n}\n\n\nBPNN *bpnn_internal_create(n_in, n_hidden, n_out)\nint n_in, n_hidden, n_out;\n{\n  BPNN *newnet;\n\n  newnet = (BPNN *) malloc (sizeof (BPNN));\n  if (newnet == NULL) {\n    printf("BPNN_CREATE: Couldn't allocate neural network\n");\n    return (NULL);\n  }\n\n  newnet->input_n = n_in;\n  newnet->hidden_n = n_hidden;\n  newnet->output_n = n_out;\n  newnet->input_units = alloc_1d_dbl(n_in + 1);\n  newnet->hidden_units = alloc_1d_dbl(n_hidden + 1);\n  newnet->output_units = alloc_1d_dbl(n_out + 1);\n\n  newnet->hidden_delta = alloc_1d_dbl(n_hidden + 1);\n  newnet->output_delta = alloc_1d_dbl(n_out + 1);\n  newnet->target = alloc_1d_dbl(n_out + 1);\n\n  newnet->input_weights = alloc_2d_dbl(n_in + 1, n_hidden + 1);\n  newnet->hidden_weights = alloc_2d_dbl(n_hidden + 1, n_out + 1);\n\n  newnet->input_prev_weights = alloc_2d_dbl(n_in + 1, n_hidden + 1);\n  newnet->hidden_prev_weights = alloc_2d_dbl(n_hidden + 1, n_out + 1);\n\n  return (newnet);\n}\n\n\nvoid bpnn_free(net)\nBPNN *net;\n{\n  int n1, n2, i;\n\n  n1 = net->input_n;\n  n2 = net->hidden_n;\n\n  free((char *) net->input_units);\n  free((char *) net->hidden_units);\n  free((char *) net->output_units);\n\n  free((char *) net->hidden_delta);\n  free((char *) net->output_delta);\n  free((char *) net->target);\n\n  for (i = 0; i <= n1; i++) {\n    free((char *) net->input_weights[i]);\n    free((char *) net->input_prev_weights[i]);\n  }\n  free((char *) net->input_weights);\n  free((char *) net->input_prev_weights);\n\n  for (i = 0; i <= n2; i++) {\n    free((char *) net->hidden_weights[i]);\n    free((char *) net->hidden_prev_weights[i]);\n  }\n  free((char *) net->hidden_weights);\n  free((char *) net->hidden_prev_weights);\n\n  free((char *) net);\n}\n\n\n/*** Creates a new fully-connected network from scratch,\n     with the given numbers of input, hidden, and output units.\n     Threshold units are automatically included.  All weights are\n     randomly initialized.\n\n     Space is also allocated for temporary storage (momentum weights,\n     error computations, etc).\n***/\n\nBPNN *bpnn_create(n_in, n_hidden, n_out)\nint n_in, n_hidden, n_out;\n{\n\n  BPNN *newnet;\n\n  newnet = bpnn_internal_create(n_in, n_hidden, n_out);\n\n#ifdef INITZERO\n  bpnn_zero_weights(newnet->input_weights, n_in, n_hidden);\n#else\n  bpnn_randomize_weights(newnet->input_weights, n_in, n_hidden);\n#endif\n  bpnn_randomize_weights(newnet->hidden_weights, n_hidden, n_out);\n  bpnn_zero_weights(newnet->input_prev_weights, n_in, n_hidden);\n  bpnn_zero_weights(newnet->hidden_prev_weights, n_hidden, n_out);\n  bpnn_randomize_row(newnet->target, n_out);\n  return (newnet);\n}\n\n\nvoid bpnn_layerforward(l1, l2, conn, n1, n2)\nfloat *l1, *l2, **conn;\nint n1, n2;\n{\n  float sum;\n  int j, k;\n\n  /*** Set up thresholding unit ***/\n  l1[0] = 1.0;\n#ifdef OPEN\n  omp_set_num_threads(NUM_THREAD);\n  #pragma omp parallel for shared(conn, n1, n2, l1) private(k, j) reduction(+: sum) schedule(static)\n#endif \n  /*** For each unit in second layer ***/\n  for (j = 1; j <= n2; j++) {\n\n    /*** Compute weighted sum of its inputs ***/\n    sum = 0.0;\n    for (k = 0; k <= n1; k++) {	\n      sum += conn[k][j] * l1[k]; \n    }\n    l2[j] = squash(sum);\n  }\n}\n\n//extern "C"\nvoid bpnn_output_error(delta, target, output, nj, err)  \nfloat *delta, *target, *output, *err;\nint nj;\n{\n  int j;\n  float o, t, errsum;\n  errsum = 0.0;\n  for (j = 1; j <= nj; j++) {\n    o = output[j];\n    t = target[j];\n    delta[j] = o * (1.0 - o) * (t - o);\n    errsum += ABS(delta[j]);\n  }\n  *err = errsum;\n}\n\n\nvoid bpnn_hidden_error(delta_h,   \n					   nh, \n					   delta_o, \n					   no, \n					   who, \n					   hidden, \n					   err)\nfloat *delta_h, *delta_o, *hidden, **who, *err;\nint nh, no;\n{\n  int j, k;\n  float h, sum, errsum;\n\n  errsum = 0.0;\n  for (j = 1; j <= nh; j++) {\n    h = hidden[j];\n    sum = 0.0;\n    for (k = 1; k <= no; k++) {\n      sum += delta_o[k] * who[j][k];\n    }\n    delta_h[j] = h * (1.0 - h) * sum;\n    errsum += ABS(delta_h[j]);\n  }\n  *err = errsum;\n}\n\n\nvoid bpnn_adjust_weights(delta, ndelta, ly, nly, w, oldw)\nfloat *delta, *ly, **w, **oldw;\n{\n  float new_dw;\n  int k, j;\n  ly[0] = 1.0;\n  //eta = 0.3;\n  //momentum = 0.3;\n\n#ifdef OPEN\n  omp_set_num_threads(NUM_THREAD);\n  #pragma omp parallel for  \\n      shared(oldw, w, delta) \\n	  private(j, k, new_dw) \\n	  firstprivate(ndelta, nly) \n#endif \n  for (j = 1; j <= ndelta; j++) {\n    for (k = 0; k <= nly; k++) {\n      new_dw = ((ETA * delta[j] * ly[k]) + (MOMENTUM * oldw[k][j]));\n	  w[k][j] += new_dw;\n	  oldw[k][j] = new_dw;\n    }\n  }\n}\n\n\nvoid bpnn_feedforward(net)\nBPNN *net;\n{\n  int in, hid, out;\n\n  in = net->input_n;\n  hid = net->hidden_n;\n  out = net->output_n;\n\n  /*** Feed forward input activations. ***/\n  bpnn_layerforward(net->input_units, net->hidden_units,\n      net->input_weights, in, hid);\n  bpnn_layerforward(net->hidden_units, net->output_units,\n      net->hidden_weights, hid, out);\n\n}\n\n\nvoid bpnn_train(net, eo, eh)\nBPNN *net;\nfloat *eo, *eh;\n{\n  int in, hid, out;\n  float out_err, hid_err;\n\n  in = net->input_n;\n  hid = net->hidden_n;\n  out = net->output_n;\n\n  /*** Feed forward input activations. ***/\n  bpnn_layerforward(net->input_units, net->hidden_units,\n      net->input_weights, in, hid);\n  bpnn_layerforward(net->hidden_units, net->output_units,\n      net->hidden_weights, hid, out);\n\n  /*** Compute error on output and hidden units. ***/\n  bpnn_output_error(net->output_delta, net->target, net->output_units,\n      out, &out_err);\n  bpnn_hidden_error(net->hidden_delta, hid, net->output_delta, out,\n      net->hidden_weights, net->hidden_units, &hid_err);\n  *eo = out_err;\n  *eh = hid_err;\n\n  /*** Adjust input and hidden weights. ***/\n  bpnn_adjust_weights(net->output_delta, out, net->hidden_units, hid,\n      net->hidden_weights, net->hidden_prev_weights);\n  bpnn_adjust_weights(net->hidden_delta, hid, net->input_units, in,\n      net->input_weights, net->input_prev_weights);\n\n}\n\n\n\n\nvoid bpnn_save(net, filename)\nBPNN *net;\nchar *filename;\n{\n  int n1, n2, n3, i, j, memcnt;\n  float dvalue, **w;\n  char *mem;\n  ///add//\n  FILE *pFile;\n  pFile = fopen( filename, "w+" );\n  ///////\n  /*\n  if ((fd = creat(filename, 0644)) == -1) {\n    printf("BPNN_SAVE: Cannot create '%s'\n", filename);\n    return;\n  }\n  */\n\n  n1 = net->input_n;  n2 = net->hidden_n;  n3 = net->output_n;\n  printf("Saving %dx%dx%d network to '%s'\n", n1, n2, n3, filename);\n  //fflush(stdout);\n\n  //write(fd, (char *) &n1, sizeof(int));\n  //write(fd, (char *) &n2, sizeof(int));\n  //write(fd, (char *) &n3, sizeof(int));\n\n  fwrite( (char *) &n1 , sizeof(char), sizeof(char), pFile);\n  fwrite( (char *) &n2 , sizeof(char), sizeof(char), pFile);\n  fwrite( (char *) &n3 , sizeof(char), sizeof(char), pFile);\n\n  \n\n  memcnt = 0;\n  w = net->input_weights;\n  mem = (char *) malloc ((unsigned) ((n1+1) * (n2+1) * sizeof(float)));\n  for (i = 0; i <= n1; i++) {\n    for (j = 0; j <= n2; j++) {\n      dvalue = w[i][j];\n      fastcopy(&mem[memcnt], &dvalue, sizeof(float));\n      memcnt += sizeof(float);\n    }\n  }\n  //write(fd, mem, (n1+1) * (n2+1) * sizeof(float));\n  fwrite( mem , (unsigned)(sizeof(float)), (unsigned) ((n1+1) * (n2+1) * sizeof(float)) , pFile);\n  free(mem);\n\n  memcnt = 0;\n  w = net->hidden_weights;\n  mem = (char *) malloc ((unsigned) ((n2+1) * (n3+1) * sizeof(float)));\n  for (i = 0; i <= n2; i++) {\n    for (j = 0; j <= n3; j++) {\n      dvalue = w[i][j];\n      fastcopy(&mem[memcnt], &dvalue, sizeof(float));\n      memcnt += sizeof(float);\n    }\n  }\n  //write(fd, mem, (n2+1) * (n3+1) * sizeof(float));\n  fwrite( mem , sizeof(float), (unsigned) ((n2+1) * (n3+1) * sizeof(float)) , pFile);\n  free(mem);\n\n  fclose(pFile);\n  return;\n}\n\n\nBPNN *bpnn_read(filename)\nchar *filename;\n{\n  char *mem;\n  BPNN *new;\n  int fd, n1, n2, n3, i, j, memcnt;\n\n  if ((fd = open(filename, 0, 0644)) == -1) {\n    return (NULL);\n  }\n\n  printf("Reading '%s'\n", filename);  //fflush(stdout);\n\n  read(fd, (char *) &n1, sizeof(int));\n  read(fd, (char *) &n2, sizeof(int));\n  read(fd, (char *) &n3, sizeof(int));\n  new = bpnn_internal_create(n1, n2, n3);\n\n  printf("'%s' contains a %dx%dx%d network\n", filename, n1, n2, n3);\n  printf("Reading input weights...");  //fflush(stdout);\n\n  memcnt = 0;\n  mem = (char *) malloc ((unsigned) ((n1+1) * (n2+1) * sizeof(float)));\n  read(fd, mem, (n1+1) * (n2+1) * sizeof(float));\n  for (i = 0; i <= n1; i++) {\n    for (j = 0; j <= n2; j++) {\n      fastcopy(&(new->input_weights[i][j]), &mem[memcnt], sizeof(float));\n      memcnt += sizeof(float);\n    }\n  }\n  free(mem);\n\n  printf("Done\nReading hidden weights...");  //fflush(stdout);\n\n  memcnt = 0;\n  mem = (char *) malloc ((unsigned) ((n2+1) * (n3+1) * sizeof(float)));\n  read(fd, mem, (n2+1) * (n3+1) * sizeof(float));\n  for (i = 0; i <= n2; i++) {\n    for (j = 0; j <= n3; j++) {\n      fastcopy(&(new->hidden_weights[i][j]), &mem[memcnt], sizeof(float));\n      memcnt += sizeof(float);\n    }\n  }\n  free(mem);\n  close(fd);\n\n  printf("Done\n");  //fflush(stdout);\n\n  bpnn_zero_weights(new->input_prev_weights, n1, n2);\n  bpnn_zero_weights(new->hidden_prev_weights, n2, n3);\n\n  return (new);\n}\n