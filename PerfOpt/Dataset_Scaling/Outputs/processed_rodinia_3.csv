Source,Code Snippet,Question,Answer
Rodinia BFS,"#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <stdlib.h>\n#include <omp.h>\n//#define NUM_THREAD 4\n#define OPEN\n\nFILE *fp;\n\n//Structure to hold a node information\nstruct Node\n{\n\tint starting;\n\tint no_of_edges;\n};\n\nvoid BFSGraph(int argc, char** argv);\n\nvoid Usage(int argc, char**argv){\n\nfprintf(stderr,""Usage: %s <num_threads> <input_file>\\n"", argv[0]);\n\n}\nint main( int argc, char** argv) \n{\n\tBFSGraph( argc, argv);\n}\nvoid BFSGraph( int argc, char** argv) \n{\n\tint no_of_nodes = 0;\n\tint edge_list_size = 0;\n\tchar *input_f;\n\tint\t num_omp_threads;\n\t\n\tif(argc!=3){\n\tUsage(argc, argv);\n\texit(0);\n\t}\n\t\n\tnum_omp_threads = atoi(argv[1]);\n\tinput_f = argv[2];\n\t\n\tprintf(""Reading File\\n"");\n\t//Read in Graph from a file\n\tfp = fopen(input_f,""r"");\n\tif(!fp)\n\t{\n\t\tprintf(""Error Reading graph file\\n"");\n\t\treturn;\n\t}\n\n\tint source = 0;\n\n\tfscanf(fp,""%d"",&no_of_nodes);\n   \n\t// allocate host memory\n\tNode* h_graph_nodes = (Node*) malloc(sizeof(Node)*no_of_nodes);\n\tbool *h_graph_mask = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\tbool *h_updating_graph_mask = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\tbool *h_graph_visited = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\n\tint start, edgeno;   \n\t// initalize the memory\n\tfor( unsigned int i = 0; i < no_of_nodes; i++) \n\t{\n\t\tfscanf(fp,""%d %d"",&start,&edgeno);\n\t\th_graph_nodes[i].starting = start;\n\t\th_graph_nodes[i].no_of_edges = edgeno;\n\t\th_graph_mask[i]=false;\n\t\th_updating_graph_mask[i]=false;\n\t\th_graph_visited[i]=false;\n\t}\n\n\t//read the source node from the file\n\tfscanf(fp,""%d"",&source);\n\t// source=0; //tesing code line\n\n\t//set the source node as true in the mask\n\th_graph_mask[source]=true;\n\th_graph_visited[source]=true;\n\n\tfscanf(fp,""%d"",&edge_list_size);\n\n\tint id,cost;\n\tint* h_graph_edges = (int*) malloc(sizeof(int)*edge_list_size);\n\tfor(int i=0; i < edge_list_size ; i++)\n\t{\n\t\tfscanf(fp,""%d"",&id);\n\t\tfscanf(fp,""%d"",&cost);\n\t\th_graph_edges[i] = id;\n\t}\n\n\tif(fp)\n\t\tfclose(fp);    \n\n\n\t// allocate mem for the result on host side\n\tint* h_cost = (int*) malloc( sizeof(int)*no_of_nodes);\n\tfor(int i=0;i<no_of_nodes;i++)\n\t\th_cost[i]=-1;\n\th_cost[source]=0;\n\t\n\tprintf(""Start traversing the tree\\n"");\n\t\n\tint k=0;\n#ifdef OPEN\n        double start_time = omp_get_wtime();\n#ifdef OMP_OFFLOAD\n#pragma omp target data map(to: no_of_nodes, h_graph_mask[0:no_of_nodes], h_graph_nodes[0:no_of_nodes], h_graph_edges[0:edge_list_size], h_graph_visited[0:no_of_nodes], h_updating_graph_mask[0:no_of_nodes]) map(h_cost[0:no_of_nodes])\n        {\n#endif \n#endif\n\tbool stop;\n\tdo\n        {\n            //if no thread changes this value then the loop stops\n            stop=false;\n\n#ifdef OPEN\n            //omp_set_num_threads(num_omp_threads);\n    #ifdef OMP_OFFLOAD\n    #pragma omp target\n    #endif\n    #pragma omp parallel for \n#endif \n            for(int tid = 0; tid < no_of_nodes; tid++ )\n            {\n                if (h_graph_mask[tid] == true){ \n                    h_graph_mask[tid]=false;\n                    for(int i=h_graph_nodes[tid].starting; i<(h_graph_nodes[tid].no_of_edges + h_graph_nodes[tid].starting); i++)\n",Does this code snippet implement Breadth First Search(BFS) algorithm on a graph using OpenMP for parallelism?,Yes
Rodinia BFS,"#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <stdlib.h>\n#include <omp.h>\n//#define NUM_THREAD 4\n#define OPEN\n\nFILE *fp;\n\n//Structure to hold a node information\nstruct Node\n{\n\tint starting;\n\tint no_of_edges;\n};\n\nvoid BFSGraph(int argc, char** argv);\n\nvoid Usage(int argc, char**argv){\n\nfprintf(stderr,""Usage: %s <num_threads> <input_file>\\n"", argv[0]);\n\n}\nint main( int argc, char** argv) \n{\n\tBFSGraph( argc, argv);\n}\nvoid BFSGraph( int argc, char** argv) \n{\n\tint no_of_nodes = 0;\n\tint edge_list_size = 0;\n\tchar *input_f;\n\tint\t num_omp_threads;\n\t\n\tif(argc!=3){\n\tUsage(argc, argv);\n\texit(0);\n\t}\n\t\n\tnum_omp_threads = atoi(argv[1]);\n\tinput_f = argv[2];\n\t\n\tprintf(""Reading File\\n"");\n\t//Read in Graph from a file\n\tfp = fopen(input_f,""r"");\n\tif(!fp)\n\t{\n\t\tprintf(""Error Reading graph file\\n"");\n\t\treturn;\n\t}\n\n\tint source = 0;\n\n\tfscanf(fp,""%d"",&no_of_nodes);\n   \n\t// allocate host memory\n\tNode* h_graph_nodes = (Node*) malloc(sizeof(Node)*no_of_nodes);\n\tbool *h_graph_mask = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\tbool *h_updating_graph_mask = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\tbool *h_graph_visited = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\n\tint start, edgeno;   \n\t// initalize the memory\n\tfor( unsigned int i = 0; i < no_of_nodes; i++) \n\t{\n\t\tfscanf(fp,""%d %d"",&start,&edgeno);\n\t\th_graph_nodes[i].starting = start;\n\t\th_graph_nodes[i].no_of_edges = edgeno;\n\t\th_graph_mask[i]=false;\n\t\th_updating_graph_mask[i]=false;\n\t\th_graph_visited[i]=false;\n\t}\n\n\t//read the source node from the file\n\tfscanf(fp,""%d"",&source);\n\t// source=0; //tesing code line\n\n\t//set the source node as true in the mask\n\th_graph_mask[source]=true;\n\th_graph_visited[source]=true;\n\n\tfscanf(fp,""%d"",&edge_list_size);\n\n\tint id,cost;\n\tint* h_graph_edges = (int*) malloc(sizeof(int)*edge_list_size);\n\tfor(int i=0; i < edge_list_size ; i++)\n\t{\n\t\tfscanf(fp,""%d"",&id);\n\t\tfscanf(fp,""%d"",&cost);\n\t\th_graph_edges[i] = id;\n\t}\n\n\tif(fp)\n\t\tfclose(fp);    \n\n\n\t// allocate mem for the result on host side\n\tint* h_cost = (int*) malloc( sizeof(int)*no_of_nodes);\n\tfor(int i=0;i<no_of_nodes;i++)\n\t\th_cost[i]=-1;\n\th_cost[source]=0;\n\t\n\tprintf(""Start traversing the tree\\n"");\n\t\n\tint k=0;\n#ifdef OPEN\n        double start_time = omp_get_wtime();\n#ifdef OMP_OFFLOAD\n#pragma omp target data map(to: no_of_nodes, h_graph_mask[0:no_of_nodes], h_graph_nodes[0:no_of_nodes], h_graph_edges[0:edge_list_size], h_graph_visited[0:no_of_nodes], h_updating_graph_mask[0:no_of_nodes]) map(h_cost[0:no_of_nodes])\n        {\n#endif \n#endif\n\tbool stop;\n\tdo\n        {\n            //if no thread changes this value then the loop stops\n            stop=false;\n\n#ifdef OPEN\n            //omp_set_num_threads(num_omp_threads);\n    #ifdef OMP_OFFLOAD\n    #pragma omp target\n    #endif\n    #pragma omp parallel for \n#endif \n            for(int tid = 0; tid < no_of_nodes; tid++ )\n            {\n                if (h_graph_mask[tid] == true){ \n                    h_graph_mask[tid]=false;\n                    for(int i=h_graph_nodes[tid].starting; i<(h_graph_nodes[tid].no_of_edges + h_graph_nodes[tid].starting); i++)\n",Does this code use dynamic allocation to initialize Edge array and Node array?,Yes
Rodinia BFS,"#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <stdlib.h>\n#include <omp.h>\n//#define NUM_THREAD 4\n#define OPEN\n\nFILE *fp;\n\n//Structure to hold a node information\nstruct Node\n{\n\tint starting;\n\tint no_of_edges;\n};\n\nvoid BFSGraph(int argc, char** argv);\n\nvoid Usage(int argc, char**argv){\n\nfprintf(stderr,""Usage: %s <num_threads> <input_file>\\n"", argv[0]);\n\n}\nint main( int argc, char** argv) \n{\n\tBFSGraph( argc, argv);\n}\nvoid BFSGraph( int argc, char** argv) \n{\n\tint no_of_nodes = 0;\n\tint edge_list_size = 0;\n\tchar *input_f;\n\tint\t num_omp_threads;\n\t\n\tif(argc!=3){\n\tUsage(argc, argv);\n\texit(0);\n\t}\n\t\n\tnum_omp_threads = atoi(argv[1]);\n\tinput_f = argv[2];\n\t\n\tprintf(""Reading File\\n"");\n\t//Read in Graph from a file\n\tfp = fopen(input_f,""r"");\n\tif(!fp)\n\t{\n\t\tprintf(""Error Reading graph file\\n"");\n\t\treturn;\n\t}\n\n\tint source = 0;\n\n\tfscanf(fp,""%d"",&no_of_nodes);\n   \n\t// allocate host memory\n\tNode* h_graph_nodes = (Node*) malloc(sizeof(Node)*no_of_nodes);\n\tbool *h_graph_mask = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\tbool *h_updating_graph_mask = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\tbool *h_graph_visited = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\n\tint start, edgeno;   \n\t// initalize the memory\n\tfor( unsigned int i = 0; i < no_of_nodes; i++) \n\t{\n\t\tfscanf(fp,""%d %d"",&start,&edgeno);\n\t\th_graph_nodes[i].starting = start;\n\t\th_graph_nodes[i].no_of_edges = edgeno;\n\t\th_graph_mask[i]=false;\n\t\th_updating_graph_mask[i]=false;\n\t\th_graph_visited[i]=false;\n\t}\n\n\t//read the source node from the file\n\tfscanf(fp,""%d"",&source);\n\t// source=0; //tesing code line\n\n\t//set the source node as true in the mask\n\th_graph_mask[source]=true;\n\th_graph_visited[source]=true;\n\n\tfscanf(fp,""%d"",&edge_list_size);\n\n\tint id,cost;\n\tint* h_graph_edges = (int*) malloc(sizeof(int)*edge_list_size);\n\tfor(int i=0; i < edge_list_size ; i++)\n\t{\n\t\tfscanf(fp,""%d"",&id);\n\t\tfscanf(fp,""%d"",&cost);\n\t\th_graph_edges[i] = id;\n\t}\n\n\tif(fp)\n\t\tfclose(fp);    \n\n\n\t// allocate mem for the result on host side\n\tint* h_cost = (int*) malloc( sizeof(int)*no_of_nodes);\n\tfor(int i=0;i<no_of_nodes;i++)\n\t\th_cost[i]=-1;\n\th_cost[source]=0;\n\t\n\tprintf(""Start traversing the tree\\n"");\n\t\n\tint k=0;\n#ifdef OPEN\n        double start_time = omp_get_wtime();\n#ifdef OMP_OFFLOAD\n#pragma omp target data map(to: no_of_nodes, h_graph_mask[0:no_of_nodes], h_graph_nodes[0:no_of_nodes], h_graph_edges[0:edge_list_size], h_graph_visited[0:no_of_nodes], h_updating_graph_mask[0:no_of_nodes]) map(h_cost[0:no_of_nodes])\n        {\n#endif \n#endif\n\tbool stop;\n\tdo\n        {\n            //if no thread changes this value then the loop stops\n            stop=false;\n\n#ifdef OPEN\n            //omp_set_num_threads(num_omp_threads);\n    #ifdef OMP_OFFLOAD\n    #pragma omp target\n    #endif\n    #pragma omp parallel for \n#endif \n            for(int tid = 0; tid < no_of_nodes; tid++ )\n            {\n                if (h_graph_mask[tid] == true){ \n                    h_graph_mask[tid]=false;\n                    for(int i=h_graph_nodes[tid].starting; i<(h_graph_nodes[tid].no_of_edges + h_graph_nodes[tid].starting); i++)\n",Does this code set an explicit number of threads for OpenMP operations using omp_set_num_threads() function?,No
Rodinia BFS,"#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <stdlib.h>\n#include <omp.h>\n//#define NUM_THREAD 4\n#define OPEN\n\nFILE *fp;\n\n//Structure to hold a node information\nstruct Node\n{\n\tint starting;\n\tint no_of_edges;\n};\n\nvoid BFSGraph(int argc, char** argv);\n\nvoid Usage(int argc, char**argv){\n\nfprintf(stderr,""Usage: %s <num_threads> <input_file>\\n"", argv[0]);\n\n}\nint main( int argc, char** argv) \n{\n\tBFSGraph( argc, argv);\n}\nvoid BFSGraph( int argc, char** argv) \n{\n\tint no_of_nodes = 0;\n\tint edge_list_size = 0;\n\tchar *input_f;\n\tint\t num_omp_threads;\n\t\n\tif(argc!=3){\n\tUsage(argc, argv);\n\texit(0);\n\t}\n\t\n\tnum_omp_threads = atoi(argv[1]);\n\tinput_f = argv[2];\n\t\n\tprintf(""Reading File\\n"");\n\t//Read in Graph from a file\n\tfp = fopen(input_f,""r"");\n\tif(!fp)\n\t{\n\t\tprintf(""Error Reading graph file\\n"");\n\t\treturn;\n\t}\n\n\tint source = 0;\n\n\tfscanf(fp,""%d"",&no_of_nodes);\n   \n\t// allocate host memory\n\tNode* h_graph_nodes = (Node*) malloc(sizeof(Node)*no_of_nodes);\n\tbool *h_graph_mask = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\tbool *h_updating_graph_mask = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\tbool *h_graph_visited = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\n\tint start, edgeno;   \n\t// initalize the memory\n\tfor( unsigned int i = 0; i < no_of_nodes; i++) \n\t{\n\t\tfscanf(fp,""%d %d"",&start,&edgeno);\n\t\th_graph_nodes[i].starting = start;\n\t\th_graph_nodes[i].no_of_edges = edgeno;\n\t\th_graph_mask[i]=false;\n\t\th_updating_graph_mask[i]=false;\n\t\th_graph_visited[i]=false;\n\t}\n\n\t//read the source node from the file\n\tfscanf(fp,""%d"",&source);\n\t// source=0; //tesing code line\n\n\t//set the source node as true in the mask\n\th_graph_mask[source]=true;\n\th_graph_visited[source]=true;\n\n\tfscanf(fp,""%d"",&edge_list_size);\n\n\tint id,cost;\n\tint* h_graph_edges = (int*) malloc(sizeof(int)*edge_list_size);\n\tfor(int i=0; i < edge_list_size ; i++)\n\t{\n\t\tfscanf(fp,""%d"",&id);\n\t\tfscanf(fp,""%d"",&cost);\n\t\th_graph_edges[i] = id;\n\t}\n\n\tif(fp)\n\t\tfclose(fp);    \n\n\n\t// allocate mem for the result on host side\n\tint* h_cost = (int*) malloc( sizeof(int)*no_of_nodes);\n\tfor(int i=0;i<no_of_nodes;i++)\n\t\th_cost[i]=-1;\n\th_cost[source]=0;\n\t\n\tprintf(""Start traversing the tree\\n"");\n\t\n\tint k=0;\n#ifdef OPEN\n        double start_time = omp_get_wtime();\n#ifdef OMP_OFFLOAD\n#pragma omp target data map(to: no_of_nodes, h_graph_mask[0:no_of_nodes], h_graph_nodes[0:no_of_nodes], h_graph_edges[0:edge_list_size], h_graph_visited[0:no_of_nodes], h_updating_graph_mask[0:no_of_nodes]) map(h_cost[0:no_of_nodes])\n        {\n#endif \n#endif\n\tbool stop;\n\tdo\n        {\n            //if no thread changes this value then the loop stops\n            stop=false;\n\n#ifdef OPEN\n            //omp_set_num_threads(num_omp_threads);\n    #ifdef OMP_OFFLOAD\n    #pragma omp target\n    #endif\n    #pragma omp parallel for \n#endif \n            for(int tid = 0; tid < no_of_nodes; tid++ )\n            {\n                if (h_graph_mask[tid] == true){ \n                    h_graph_mask[tid]=false;\n                    for(int i=h_graph_nodes[tid].starting; i<(h_graph_nodes[tid].no_of_edges + h_graph_nodes[tid].starting); i++)\n",Is there any usage of OpenMP's 'omp_get_wtime()' function to manage and gather timing information of the parallel execution in this code snippet?,Yes
Rodinia BFS,"#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <stdlib.h>\n#include <omp.h>\n//#define NUM_THREAD 4\n#define OPEN\n\nFILE *fp;\n\n//Structure to hold a node information\nstruct Node\n{\n\tint starting;\n\tint no_of_edges;\n};\n\nvoid BFSGraph(int argc, char** argv);\n\nvoid Usage(int argc, char**argv){\n\nfprintf(stderr,""Usage: %s <num_threads> <input_file>\\n"", argv[0]);\n\n}\nint main( int argc, char** argv) \n{\n\tBFSGraph( argc, argv);\n}\nvoid BFSGraph( int argc, char** argv) \n{\n\tint no_of_nodes = 0;\n\tint edge_list_size = 0;\n\tchar *input_f;\n\tint\t num_omp_threads;\n\t\n\tif(argc!=3){\n\tUsage(argc, argv);\n\texit(0);\n\t}\n\t\n\tnum_omp_threads = atoi(argv[1]);\n\tinput_f = argv[2];\n\t\n\tprintf(""Reading File\\n"");\n\t//Read in Graph from a file\n\tfp = fopen(input_f,""r"");\n\tif(!fp)\n\t{\n\t\tprintf(""Error Reading graph file\\n"");\n\t\treturn;\n\t}\n\n\tint source = 0;\n\n\tfscanf(fp,""%d"",&no_of_nodes);\n   \n\t// allocate host memory\n\tNode* h_graph_nodes = (Node*) malloc(sizeof(Node)*no_of_nodes);\n\tbool *h_graph_mask = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\tbool *h_updating_graph_mask = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\tbool *h_graph_visited = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\n\tint start, edgeno;   \n\t// initalize the memory\n\tfor( unsigned int i = 0; i < no_of_nodes; i++) \n\t{\n\t\tfscanf(fp,""%d %d"",&start,&edgeno);\n\t\th_graph_nodes[i].starting = start;\n\t\th_graph_nodes[i].no_of_edges = edgeno;\n\t\th_graph_mask[i]=false;\n\t\th_updating_graph_mask[i]=false;\n\t\th_graph_visited[i]=false;\n\t}\n\n\t//read the source node from the file\n\tfscanf(fp,""%d"",&source);\n\t// source=0; //tesing code line\n\n\t//set the source node as true in the mask\n\th_graph_mask[source]=true;\n\th_graph_visited[source]=true;\n\n\tfscanf(fp,""%d"",&edge_list_size);\n\n\tint id,cost;\n\tint* h_graph_edges = (int*) malloc(sizeof(int)*edge_list_size);\n\tfor(int i=0; i < edge_list_size ; i++)\n\t{\n\t\tfscanf(fp,""%d"",&id);\n\t\tfscanf(fp,""%d"",&cost);\n\t\th_graph_edges[i] = id;\n\t}\n\n\tif(fp)\n\t\tfclose(fp);    \n\n\n\t// allocate mem for the result on host side\n\tint* h_cost = (int*) malloc( sizeof(int)*no_of_nodes);\n\tfor(int i=0;i<no_of_nodes;i++)\n\t\th_cost[i]=-1;\n\th_cost[source]=0;\n\t\n\tprintf(""Start traversing the tree\\n"");\n\t\n\tint k=0;\n#ifdef OPEN\n        double start_time = omp_get_wtime();\n#ifdef OMP_OFFLOAD\n#pragma omp target data map(to: no_of_nodes, h_graph_mask[0:no_of_nodes], h_graph_nodes[0:no_of_nodes], h_graph_edges[0:edge_list_size], h_graph_visited[0:no_of_nodes], h_updating_graph_mask[0:no_of_nodes]) map(h_cost[0:no_of_nodes])\n        {\n#endif \n#endif\n\tbool stop;\n\tdo\n        {\n            //if no thread changes this value then the loop stops\n            stop=false;\n\n#ifdef OPEN\n            //omp_set_num_threads(num_omp_threads);\n    #ifdef OMP_OFFLOAD\n    #pragma omp target\n    #endif\n    #pragma omp parallel for \n#endif \n            for(int tid = 0; tid < no_of_nodes; tid++ )\n            {\n                if (h_graph_mask[tid] == true){ \n                    h_graph_mask[tid]=false;\n                    for(int i=h_graph_nodes[tid].starting; i<(h_graph_nodes[tid].no_of_edges + h_graph_nodes[tid].starting); i++)\n","Are the data structures such as graph nodes, edges, masks, visited nodes completely offloaded to a device using OpenMP's target data directive in this code snippet?",No
Rodinia BFS,"#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <stdlib.h>\n#include <omp.h>\n//#define NUM_THREAD 4\n#define OPEN\n\nFILE *fp;\n\n//Structure to hold a node information\nstruct Node\n{\n\tint starting;\n\tint no_of_edges;\n};\n\nvoid BFSGraph(int argc, char** argv);\n\nvoid Usage(int argc, char**argv){\n\nfprintf(stderr,""Usage: %s <num_threads> <input_file>\\n"", argv[0]);\n\n}\nint main( int argc, char** argv) \n{\n\tBFSGraph( argc, argv);\n}\nvoid BFSGraph( int argc, char** argv) \n{\n\tint no_of_nodes = 0;\n\tint edge_list_size = 0;\n\tchar *input_f;\n\tint\t num_omp_threads;\n\t\n\tif(argc!=3){\n\tUsage(argc, argv);\n\texit(0);\n\t}\n\t\n\tnum_omp_threads = atoi(argv[1]);\n\tinput_f = argv[2];\n\t\n\tprintf(""Reading File\\n"");\n\t//Read in Graph from a file\n\tfp = fopen(input_f,""r"");\n\tif(!fp)\n\t{\n\t\tprintf(""Error Reading graph file\\n"");\n\t\treturn;\n\t}\n\n\tint source = 0;\n\n\tfscanf(fp,""%d"",&no_of_nodes);\n   \n\t// allocate host memory\n\tNode* h_graph_nodes = (Node*) malloc(sizeof(Node)*no_of_nodes);\n\tbool *h_graph_mask = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\tbool *h_updating_graph_mask = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\tbool *h_graph_visited = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\n\tint start, edgeno;   \n\t// initalize the memory\n\tfor( unsigned int i = 0; i < no_of_nodes; i++) \n\t{\n\t\tfscanf(fp,""%d %d"",&start,&edgeno);\n\t\th_graph_nodes[i].starting = start;\n\t\th_graph_nodes[i].no_of_edges = edgeno;\n\t\th_graph_mask[i]=false;\n\t\th_updating_graph_mask[i]=false;\n\t\th_graph_visited[i]=false;\n\t}\n\n\t//read the source node from the file\n\tfscanf(fp,""%d"",&source);\n\t// source=0; //tesing code line\n\n\t//set the source node as true in the mask\n\th_graph_mask[source]=true;\n\th_graph_visited[source]=true;\n\n\tfscanf(fp,""%d"",&edge_list_size);\n\n\tint id,cost;\n\tint* h_graph_edges = (int*) malloc(sizeof(int)*edge_list_size);\n\tfor(int i=0; i < edge_list_size ; i++)\n\t{\n\t\tfscanf(fp,""%d"",&id);\n\t\tfscanf(fp,""%d"",&cost);\n\t\th_graph_edges[i] = id;\n\t}\n\n\tif(fp)\n\t\tfclose(fp);    \n\n\n\t// allocate mem for the result on host side\n\tint* h_cost = (int*) malloc( sizeof(int)*no_of_nodes);\n\tfor(int i=0;i<no_of_nodes;i++)\n\t\th_cost[i]=-1;\n\th_cost[source]=0;\n\t\n\tprintf(""Start traversing the tree\\n"");\n\t\n\tint k=0;\n#ifdef OPEN\n        double start_time = omp_get_wtime();\n#ifdef OMP_OFFLOAD\n#pragma omp target data map(to: no_of_nodes, h_graph_mask[0:no_of_nodes], h_graph_nodes[0:no_of_nodes], h_graph_edges[0:edge_list_size], h_graph_visited[0:no_of_nodes], h_updating_graph_mask[0:no_of_nodes]) map(h_cost[0:no_of_nodes])\n        {\n#endif \n#endif\n\tbool stop;\n\tdo\n        {\n            //if no thread changes this value then the loop stops\n            stop=false;\n\n#ifdef OPEN\n            //omp_set_num_threads(num_omp_threads);\n    #ifdef OMP_OFFLOAD\n    #pragma omp target\n    #endif\n    #pragma omp parallel for \n#endif \n            for(int tid = 0; tid < no_of_nodes; tid++ )\n            {\n                if (h_graph_mask[tid] == true){ \n                    h_graph_mask[tid]=false;\n                    for(int i=h_graph_nodes[tid].starting; i<(h_graph_nodes[tid].no_of_edges + h_graph_nodes[tid].starting); i++)\n",Are the OpenMP directives used in the provided code snippet enclosed in a conditional preprocessor directive '#ifdef' for OPEN and OMP_OFFLOAD?,Yes
Rodinia BFS,"#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <stdlib.h>\n#include <omp.h>\n//#define NUM_THREAD 4\n#define OPEN\n\nFILE *fp;\n\n//Structure to hold a node information\nstruct Node\n{\n\tint starting;\n\tint no_of_edges;\n};\n\nvoid BFSGraph(int argc, char** argv);\n\nvoid Usage(int argc, char**argv){\n\nfprintf(stderr,""Usage: %s <num_threads> <input_file>\\n"", argv[0]);\n\n}\nint main( int argc, char** argv) \n{\n\tBFSGraph( argc, argv);\n}\nvoid BFSGraph( int argc, char** argv) \n{\n\tint no_of_nodes = 0;\n\tint edge_list_size = 0;\n\tchar *input_f;\n\tint\t num_omp_threads;\n\t\n\tif(argc!=3){\n\tUsage(argc, argv);\n\texit(0);\n\t}\n\t\n\tnum_omp_threads = atoi(argv[1]);\n\tinput_f = argv[2];\n\t\n\tprintf(""Reading File\\n"");\n\t//Read in Graph from a file\n\tfp = fopen(input_f,""r"");\n\tif(!fp)\n\t{\n\t\tprintf(""Error Reading graph file\\n"");\n\t\treturn;\n\t}\n\n\tint source = 0;\n\n\tfscanf(fp,""%d"",&no_of_nodes);\n   \n\t// allocate host memory\n\tNode* h_graph_nodes = (Node*) malloc(sizeof(Node)*no_of_nodes);\n\tbool *h_graph_mask = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\tbool *h_updating_graph_mask = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\tbool *h_graph_visited = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\n\tint start, edgeno;   \n\t// initalize the memory\n\tfor( unsigned int i = 0; i < no_of_nodes; i++) \n\t{\n\t\tfscanf(fp,""%d %d"",&start,&edgeno);\n\t\th_graph_nodes[i].starting = start;\n\t\th_graph_nodes[i].no_of_edges = edgeno;\n\t\th_graph_mask[i]=false;\n\t\th_updating_graph_mask[i]=false;\n\t\th_graph_visited[i]=false;\n\t}\n\n\t//read the source node from the file\n\tfscanf(fp,""%d"",&source);\n\t// source=0; //tesing code line\n\n\t//set the source node as true in the mask\n\th_graph_mask[source]=true;\n\th_graph_visited[source]=true;\n\n\tfscanf(fp,""%d"",&edge_list_size);\n\n\tint id,cost;\n\tint* h_graph_edges = (int*) malloc(sizeof(int)*edge_list_size);\n\tfor(int i=0; i < edge_list_size ; i++)\n\t{\n\t\tfscanf(fp,""%d"",&id);\n\t\tfscanf(fp,""%d"",&cost);\n\t\th_graph_edges[i] = id;\n\t}\n\n\tif(fp)\n\t\tfclose(fp);    \n\n\n\t// allocate mem for the result on host side\n\tint* h_cost = (int*) malloc( sizeof(int)*no_of_nodes);\n\tfor(int i=0;i<no_of_nodes;i++)\n\t\th_cost[i]=-1;\n\th_cost[source]=0;\n\t\n\tprintf(""Start traversing the tree\\n"");\n\t\n\tint k=0;\n#ifdef OPEN\n        double start_time = omp_get_wtime();\n#ifdef OMP_OFFLOAD\n#pragma omp target data map(to: no_of_nodes, h_graph_mask[0:no_of_nodes], h_graph_nodes[0:no_of_nodes], h_graph_edges[0:edge_list_size], h_graph_visited[0:no_of_nodes], h_updating_graph_mask[0:no_of_nodes]) map(h_cost[0:no_of_nodes])\n        {\n#endif \n#endif\n\tbool stop;\n\tdo\n        {\n            //if no thread changes this value then the loop stops\n            stop=false;\n\n#ifdef OPEN\n            //omp_set_num_threads(num_omp_threads);\n    #ifdef OMP_OFFLOAD\n    #pragma omp target\n    #endif\n    #pragma omp parallel for \n#endif \n            for(int tid = 0; tid < no_of_nodes; tid++ )\n            {\n                if (h_graph_mask[tid] == true){ \n                    h_graph_mask[tid]=false;\n                    for(int i=h_graph_nodes[tid].starting; i<(h_graph_nodes[tid].no_of_edges + h_graph_nodes[tid].starting); i++)\n","In the given code, is the 'num_omp_threads' variable set from the command line arguments?",Yes
Rodinia BFS,"#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <stdlib.h>\n#include <omp.h>\n//#define NUM_THREAD 4\n#define OPEN\n\nFILE *fp;\n\n//Structure to hold a node information\nstruct Node\n{\n\tint starting;\n\tint no_of_edges;\n};\n\nvoid BFSGraph(int argc, char** argv);\n\nvoid Usage(int argc, char**argv){\n\nfprintf(stderr,""Usage: %s <num_threads> <input_file>\\n"", argv[0]);\n\n}\nint main( int argc, char** argv) \n{\n\tBFSGraph( argc, argv);\n}\nvoid BFSGraph( int argc, char** argv) \n{\n\tint no_of_nodes = 0;\n\tint edge_list_size = 0;\n\tchar *input_f;\n\tint\t num_omp_threads;\n\t\n\tif(argc!=3){\n\tUsage(argc, argv);\n\texit(0);\n\t}\n\t\n\tnum_omp_threads = atoi(argv[1]);\n\tinput_f = argv[2];\n\t\n\tprintf(""Reading File\\n"");\n\t//Read in Graph from a file\n\tfp = fopen(input_f,""r"");\n\tif(!fp)\n\t{\n\t\tprintf(""Error Reading graph file\\n"");\n\t\treturn;\n\t}\n\n\tint source = 0;\n\n\tfscanf(fp,""%d"",&no_of_nodes);\n   \n\t// allocate host memory\n\tNode* h_graph_nodes = (Node*) malloc(sizeof(Node)*no_of_nodes);\n\tbool *h_graph_mask = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\tbool *h_updating_graph_mask = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\tbool *h_graph_visited = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\n\tint start, edgeno;   \n\t// initalize the memory\n\tfor( unsigned int i = 0; i < no_of_nodes; i++) \n\t{\n\t\tfscanf(fp,""%d %d"",&start,&edgeno);\n\t\th_graph_nodes[i].starting = start;\n\t\th_graph_nodes[i].no_of_edges = edgeno;\n\t\th_graph_mask[i]=false;\n\t\th_updating_graph_mask[i]=false;\n\t\th_graph_visited[i]=false;\n\t}\n\n\t//read the source node from the file\n\tfscanf(fp,""%d"",&source);\n\t// source=0; //tesing code line\n\n\t//set the source node as true in the mask\n\th_graph_mask[source]=true;\n\th_graph_visited[source]=true;\n\n\tfscanf(fp,""%d"",&edge_list_size);\n\n\tint id,cost;\n\tint* h_graph_edges = (int*) malloc(sizeof(int)*edge_list_size);\n\tfor(int i=0; i < edge_list_size ; i++)\n\t{\n\t\tfscanf(fp,""%d"",&id);\n\t\tfscanf(fp,""%d"",&cost);\n\t\th_graph_edges[i] = id;\n\t}\n\n\tif(fp)\n\t\tfclose(fp);    \n\n\n\t// allocate mem for the result on host side\n\tint* h_cost = (int*) malloc( sizeof(int)*no_of_nodes);\n\tfor(int i=0;i<no_of_nodes;i++)\n\t\th_cost[i]=-1;\n\th_cost[source]=0;\n\t\n\tprintf(""Start traversing the tree\\n"");\n\t\n\tint k=0;\n#ifdef OPEN\n        double start_time = omp_get_wtime();\n#ifdef OMP_OFFLOAD\n#pragma omp target data map(to: no_of_nodes, h_graph_mask[0:no_of_nodes], h_graph_nodes[0:no_of_nodes], h_graph_edges[0:edge_list_size], h_graph_visited[0:no_of_nodes], h_updating_graph_mask[0:no_of_nodes]) map(h_cost[0:no_of_nodes])\n        {\n#endif \n#endif\n\tbool stop;\n\tdo\n        {\n            //if no thread changes this value then the loop stops\n            stop=false;\n\n#ifdef OPEN\n            //omp_set_num_threads(num_omp_threads);\n    #ifdef OMP_OFFLOAD\n    #pragma omp target\n    #endif\n    #pragma omp parallel for \n#endif \n            for(int tid = 0; tid < no_of_nodes; tid++ )\n            {\n                if (h_graph_mask[tid] == true){ \n                    h_graph_mask[tid]=false;\n                    for(int i=h_graph_nodes[tid].starting; i<(h_graph_nodes[tid].no_of_edges + h_graph_nodes[tid].starting); i++)\n",Is the OpenMP pragma '#pragma omp parallel for' directive used inside a 'do-while' loop in the BFS implementation in the provided code?,Yes
Rodinia BFS,"#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <stdlib.h>\n#include <omp.h>\n//#define NUM_THREAD 4\n#define OPEN\n\nFILE *fp;\n\n//Structure to hold a node information\nstruct Node\n{\n\tint starting;\n\tint no_of_edges;\n};\n\nvoid BFSGraph(int argc, char** argv);\n\nvoid Usage(int argc, char**argv){\n\nfprintf(stderr,""Usage: %s <num_threads> <input_file>\\n"", argv[0]);\n\n}\nint main( int argc, char** argv) \n{\n\tBFSGraph( argc, argv);\n}\nvoid BFSGraph( int argc, char** argv) \n{\n\tint no_of_nodes = 0;\n\tint edge_list_size = 0;\n\tchar *input_f;\n\tint\t num_omp_threads;\n\t\n\tif(argc!=3){\n\tUsage(argc, argv);\n\texit(0);\n\t}\n\t\n\tnum_omp_threads = atoi(argv[1]);\n\tinput_f = argv[2];\n\t\n\tprintf(""Reading File\\n"");\n\t//Read in Graph from a file\n\tfp = fopen(input_f,""r"");\n\tif(!fp)\n\t{\n\t\tprintf(""Error Reading graph file\\n"");\n\t\treturn;\n\t}\n\n\tint source = 0;\n\n\tfscanf(fp,""%d"",&no_of_nodes);\n   \n\t// allocate host memory\n\tNode* h_graph_nodes = (Node*) malloc(sizeof(Node)*no_of_nodes);\n\tbool *h_graph_mask = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\tbool *h_updating_graph_mask = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\tbool *h_graph_visited = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\n\tint start, edgeno;   \n\t// initalize the memory\n\tfor( unsigned int i = 0; i < no_of_nodes; i++) \n\t{\n\t\tfscanf(fp,""%d %d"",&start,&edgeno);\n\t\th_graph_nodes[i].starting = start;\n\t\th_graph_nodes[i].no_of_edges = edgeno;\n\t\th_graph_mask[i]=false;\n\t\th_updating_graph_mask[i]=false;\n\t\th_graph_visited[i]=false;\n\t}\n\n\t//read the source node from the file\n\tfscanf(fp,""%d"",&source);\n\t// source=0; //tesing code line\n\n\t//set the source node as true in the mask\n\th_graph_mask[source]=true;\n\th_graph_visited[source]=true;\n\n\tfscanf(fp,""%d"",&edge_list_size);\n\n\tint id,cost;\n\tint* h_graph_edges = (int*) malloc(sizeof(int)*edge_list_size);\n\tfor(int i=0; i < edge_list_size ; i++)\n\t{\n\t\tfscanf(fp,""%d"",&id);\n\t\tfscanf(fp,""%d"",&cost);\n\t\th_graph_edges[i] = id;\n\t}\n\n\tif(fp)\n\t\tfclose(fp);    \n\n\n\t// allocate mem for the result on host side\n\tint* h_cost = (int*) malloc( sizeof(int)*no_of_nodes);\n\tfor(int i=0;i<no_of_nodes;i++)\n\t\th_cost[i]=-1;\n\th_cost[source]=0;\n\t\n\tprintf(""Start traversing the tree\\n"");\n\t\n\tint k=0;\n#ifdef OPEN\n        double start_time = omp_get_wtime();\n#ifdef OMP_OFFLOAD\n#pragma omp target data map(to: no_of_nodes, h_graph_mask[0:no_of_nodes], h_graph_nodes[0:no_of_nodes], h_graph_edges[0:edge_list_size], h_graph_visited[0:no_of_nodes], h_updating_graph_mask[0:no_of_nodes]) map(h_cost[0:no_of_nodes])\n        {\n#endif \n#endif\n\tbool stop;\n\tdo\n        {\n            //if no thread changes this value then the loop stops\n            stop=false;\n\n#ifdef OPEN\n            //omp_set_num_threads(num_omp_threads);\n    #ifdef OMP_OFFLOAD\n    #pragma omp target\n    #endif\n    #pragma omp parallel for \n#endif \n            for(int tid = 0; tid < no_of_nodes; tid++ )\n            {\n                if (h_graph_mask[tid] == true){ \n                    h_graph_mask[tid]=false;\n                    for(int i=h_graph_nodes[tid].starting; i<(h_graph_nodes[tid].no_of_edges + h_graph_nodes[tid].starting); i++)\n",Does the code manage synchronization between threads using a 'stop' boolean variable?,Yes
Rodinia BFS,"#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <stdlib.h>\n#include <omp.h>\n//#define NUM_THREAD 4\n#define OPEN\n\nFILE *fp;\n\n//Structure to hold a node information\nstruct Node\n{\n\tint starting;\n\tint no_of_edges;\n};\n\nvoid BFSGraph(int argc, char** argv);\n\nvoid Usage(int argc, char**argv){\n\nfprintf(stderr,""Usage: %s <num_threads> <input_file>\\n"", argv[0]);\n\n}\nint main( int argc, char** argv) \n{\n\tBFSGraph( argc, argv);\n}\nvoid BFSGraph( int argc, char** argv) \n{\n\tint no_of_nodes = 0;\n\tint edge_list_size = 0;\n\tchar *input_f;\n\tint\t num_omp_threads;\n\t\n\tif(argc!=3){\n\tUsage(argc, argv);\n\texit(0);\n\t}\n\t\n\tnum_omp_threads = atoi(argv[1]);\n\tinput_f = argv[2];\n\t\n\tprintf(""Reading File\\n"");\n\t//Read in Graph from a file\n\tfp = fopen(input_f,""r"");\n\tif(!fp)\n\t{\n\t\tprintf(""Error Reading graph file\\n"");\n\t\treturn;\n\t}\n\n\tint source = 0;\n\n\tfscanf(fp,""%d"",&no_of_nodes);\n   \n\t// allocate host memory\n\tNode* h_graph_nodes = (Node*) malloc(sizeof(Node)*no_of_nodes);\n\tbool *h_graph_mask = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\tbool *h_updating_graph_mask = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\tbool *h_graph_visited = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\n\tint start, edgeno;   \n\t// initalize the memory\n\tfor( unsigned int i = 0; i < no_of_nodes; i++) \n\t{\n\t\tfscanf(fp,""%d %d"",&start,&edgeno);\n\t\th_graph_nodes[i].starting = start;\n\t\th_graph_nodes[i].no_of_edges = edgeno;\n\t\th_graph_mask[i]=false;\n\t\th_updating_graph_mask[i]=false;\n\t\th_graph_visited[i]=false;\n\t}\n\n\t//read the source node from the file\n\tfscanf(fp,""%d"",&source);\n\t// source=0; //tesing code line\n\n\t//set the source node as true in the mask\n\th_graph_mask[source]=true;\n\th_graph_visited[source]=true;\n\n\tfscanf(fp,""%d"",&edge_list_size);\n\n\tint id,cost;\n\tint* h_graph_edges = (int*) malloc(sizeof(int)*edge_list_size);\n\tfor(int i=0; i < edge_list_size ; i++)\n\t{\n\t\tfscanf(fp,""%d"",&id);\n\t\tfscanf(fp,""%d"",&cost);\n\t\th_graph_edges[i] = id;\n\t}\n\n\tif(fp)\n\t\tfclose(fp);    \n\n\n\t// allocate mem for the result on host side\n\tint* h_cost = (int*) malloc( sizeof(int)*no_of_nodes);\n\tfor(int i=0;i<no_of_nodes;i++)\n\t\th_cost[i]=-1;\n\th_cost[source]=0;\n\t\n\tprintf(""Start traversing the tree\\n"");\n\t\n\tint k=0;\n#ifdef OPEN\n        double start_time = omp_get_wtime();\n#ifdef OMP_OFFLOAD\n#pragma omp target data map(to: no_of_nodes, h_graph_mask[0:no_of_nodes], h_graph_nodes[0:no_of_nodes], h_graph_edges[0:edge_list_size], h_graph_visited[0:no_of_nodes], h_updating_graph_mask[0:no_of_nodes]) map(h_cost[0:no_of_nodes])\n        {\n#endif \n#endif\n\tbool stop;\n\tdo\n        {\n            //if no thread changes this value then the loop stops\n            stop=false;\n\n#ifdef OPEN\n            //omp_set_num_threads(num_omp_threads);\n    #ifdef OMP_OFFLOAD\n    #pragma omp target\n    #endif\n    #pragma omp parallel for \n#endif \n            for(int tid = 0; tid < no_of_nodes; tid++ )\n            {\n                if (h_graph_mask[tid] == true){ \n                    h_graph_mask[tid]=false;\n                    for(int i=h_graph_nodes[tid].starting; i<(h_graph_nodes[tid].no_of_edges + h_graph_nodes[tid].starting); i++)\n","In the BFS implementation of the code, is the source node always set as the first node of the graph?",No
Rodinia Kmeans Clustering - serial,"/******************************************************************************/\n/*IMPORTANT:  READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.         */\n/*By downloading, copying, installing or using the software you agree        */\n/*to this license.  If you do not agree to this license, do not download,    */\n/*install, copy or use the software.                                         */\n/*                                                                           */\n/*                                                                           */\n/*Copyright (c) 2005 Northwestern University                                 */\n/*All rights reserved.                                                       */\n\n/*Redistribution of the software in source and binary forms,                 */\n/*with or without modification, is permitted provided that the               */\n/*following conditions are met:                                              */\n/*                                                                           */\n/*1       Redistributions of source code must retain the above copyright     */\n/*        notice, this list of conditions and the following disclaimer.      */\n/*                                                                           */\n/*2       Redistributions in binary form must reproduce the above copyright   */\n/*        notice, this list of conditions and the following disclaimer in the */\n/*        documentation and/or other materials provided with the distribution.*/ \n/*                                                                            */\n/*3       Neither the name of Northwestern University nor the names of its    */\n/*        contributors may be used to endorse or promote products derived     */\n/*        from this software without specific prior written permission.       */\n/*                                                                            */\n/*THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ``AS    */\n/*IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED      */\n/*TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY, NON-INFRINGEMENT AND         */\n/*FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL          */\n/*NORTHWESTERN UNIVERSITY OR ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT,       */\n/*INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES          */\n/*(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR          */\n/*SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)          */\n/*HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,         */\n/*STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN    */\n/*ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE             */\n/*POSSIBILITY OF SUCH DAMAGE.                                                 */\n/******************************************************************************/\n/*************************************************************************/\n/**   File:         kmeans_clustering.c                                 **/\n/**   Description:  Implementation of regular k-means clustering        **/\n/**                 algorithm                                           **/\n/**   Author:  Wei-keng Liao                                            **/\n/**            ECE Department, Northwestern University                  **/\n/**            email: wkliao@ece.northwestern.edu                       **/\n/**                                                                     **/\n/**   Edited by: Jay Pisharath                                          **/\n/**              Northwestern University.                               **/\n/**                                                                     **/\n/**   ================================================================  **/\n/**                                                                     **/\n/**   Edited by: Sang-Ha  Lee                                           **/\n/**                 University of Virginia                              **/\n/**                                                                     **/\n/**   Description:    No longer supports fuzzy c-means clustering;     **/\n/**                     only regular k-means clustering.               **/\n/**                     Simplified for main functionality: regular k-means    **/\n/**                     clustering.                                     **/\n/**                                                                     **/\n/*************************************************************************/\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <float.h>\n#include <math.h>\n#include \kmeans.h\""\n#include <omp.h>\n\n#define RANDOM_MAX 2147483647\n\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\n\nextern double wtime(void);\n\nint find_nearest_point(float  *pt,          /* [nfeatures] */\n                       int     nfeatures,\n                       float **pts,         /* [npts][nfeatures] */\n                       int     npts)\n{\n    int index, i;\n    float min_dist=FLT_MAX;\n\n    /* find the cluster center id with min distance to pt */\n    for (i=0; i<npts; i++) {\n        float dist;\n        dist = euclid_dist_2(pt, pts[i], nfeatures);  /* no need square root */\n        if (dist < min_dist) {\n            min_dist = dist;\n            index    = i;\n        }\n    }\n    return(index);\n}\n\n/*----< euclid_dist_2() >----------------------------------------------------*/\n/* multi-dimensional spatial Euclid distance square */\n__inline\nfloat euclid_dist_2(float *pt1,\n                    float *pt2,\n                    int    numdims)\n{\n    int i;\n    float ans=0.0;\n\n    for (i=0; i<numdims; i++)\n        ans += (pt1[i]-pt2[i]) * (pt1[i]-pt2[i]);\n\n    return(ans);\n}\n\n\n/*----< kmeans_clustering() >---------------------------------------------*/\nfloat** kmeans_clustering(float **feature,    /* in: [npoints][nfeatures] */\n                          int     nfeatures,\n                          int     npoints,\n                          int     nclusters,\n                          float   threshold,\n                          int    *membership) /* out: [npoints] */\n{\n\n    int      i, j, n=0, index, loop=0;\n    int     *new_centers_len; /* [nclusters]: no. of points in each cluster */\n    float    delta;\n    float  **clusters;   /* out: [nclusters][nfeatures] */\n    float  **new_centers;     /* [nclusters][nfeatures] */\n  \n\n    /* allocate space for returning variable clusters[] */\n    clusters    = (float**) malloc(nclusters *             sizeof(float*));\n    clusters[0] = (float*)  malloc(nclusters * nfeatures * sizeof(float));\n    for (i=1; i<nclusters; i++)\n        clusters[i] = clusters[i-1] + nfeatures;\n\n    /* randomly pick cluster centers */\n    for (i=0; i<nclusters; i++) {\n        //n = (int)rand() % npoints;\n        for (j=0; j<nfeatures; j++)\n            clusters[i][j] = feature[n][j];\n\t\tn++;\n    }\n\n    for (i=0; i<npoints; i++)\n\t\tmembership[i] = -1;\n\n    /* need to initialize new_centers_len and new_centers[0] to all 0 */\n    new_centers_len = (int*) calloc(nclusters, sizeof(int));\n\n    new_centers    = (float**) malloc(nclusters *",Does the given code use OpenMP for parallel processing?,No
Rodinia Kmeans Clustering - serial,"/******************************************************************************/\n/*IMPORTANT:  READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.         */\n/*By downloading, copying, installing or using the software you agree        */\n/*to this license.  If you do not agree to this license, do not download,    */\n/*install, copy or use the software.                                         */\n/*                                                                           */\n/*                                                                           */\n/*Copyright (c) 2005 Northwestern University                                 */\n/*All rights reserved.                                                       */\n\n/*Redistribution of the software in source and binary forms,                 */\n/*with or without modification, is permitted provided that the               */\n/*following conditions are met:                                              */\n/*                                                                           */\n/*1       Redistributions of source code must retain the above copyright     */\n/*        notice, this list of conditions and the following disclaimer.      */\n/*                                                                           */\n/*2       Redistributions in binary form must reproduce the above copyright   */\n/*        notice, this list of conditions and the following disclaimer in the */\n/*        documentation and/or other materials provided with the distribution.*/ \n/*                                                                            */\n/*3       Neither the name of Northwestern University nor the names of its    */\n/*        contributors may be used to endorse or promote products derived     */\n/*        from this software without specific prior written permission.       */\n/*                                                                            */\n/*THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ``AS    */\n/*IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED      */\n/*TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY, NON-INFRINGEMENT AND         */\n/*FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL          */\n/*NORTHWESTERN UNIVERSITY OR ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT,       */\n/*INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES          */\n/*(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR          */\n/*SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)          */\n/*HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,         */\n/*STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN    */\n/*ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE             */\n/*POSSIBILITY OF SUCH DAMAGE.                                                 */\n/******************************************************************************/\n/*************************************************************************/\n/**   File:         kmeans_clustering.c                                 **/\n/**   Description:  Implementation of regular k-means clustering        **/\n/**                 algorithm                                           **/\n/**   Author:  Wei-keng Liao                                            **/\n/**            ECE Department, Northwestern University                  **/\n/**            email: wkliao@ece.northwestern.edu                       **/\n/**                                                                     **/\n/**   Edited by: Jay Pisharath                                          **/\n/**              Northwestern University.                               **/\n/**                                                                     **/\n/**   ================================================================  **/\n/**                                                                     **/\n/**   Edited by: Sang-Ha  Lee                                           **/\n/**                 University of Virginia                              **/\n/**                                                                     **/\n/**   Description:    No longer supports fuzzy c-means clustering;     **/\n/**                     only regular k-means clustering.               **/\n/**                     Simplified for main functionality: regular k-means    **/\n/**                     clustering.                                     **/\n/**                                                                     **/\n/*************************************************************************/\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <float.h>\n#include <math.h>\n#include \kmeans.h\""\n#include <omp.h>\n\n#define RANDOM_MAX 2147483647\n\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\n\nextern double wtime(void);\n\nint find_nearest_point(float  *pt,          /* [nfeatures] */\n                       int     nfeatures,\n                       float **pts,         /* [npts][nfeatures] */\n                       int     npts)\n{\n    int index, i;\n    float min_dist=FLT_MAX;\n\n    /* find the cluster center id with min distance to pt */\n    for (i=0; i<npts; i++) {\n        float dist;\n        dist = euclid_dist_2(pt, pts[i], nfeatures);  /* no need square root */\n        if (dist < min_dist) {\n            min_dist = dist;\n            index    = i;\n        }\n    }\n    return(index);\n}\n\n/*----< euclid_dist_2() >----------------------------------------------------*/\n/* multi-dimensional spatial Euclid distance square */\n__inline\nfloat euclid_dist_2(float *pt1,\n                    float *pt2,\n                    int    numdims)\n{\n    int i;\n    float ans=0.0;\n\n    for (i=0; i<numdims; i++)\n        ans += (pt1[i]-pt2[i]) * (pt1[i]-pt2[i]);\n\n    return(ans);\n}\n\n\n/*----< kmeans_clustering() >---------------------------------------------*/\nfloat** kmeans_clustering(float **feature,    /* in: [npoints][nfeatures] */\n                          int     nfeatures,\n                          int     npoints,\n                          int     nclusters,\n                          float   threshold,\n                          int    *membership) /* out: [npoints] */\n{\n\n    int      i, j, n=0, index, loop=0;\n    int     *new_centers_len; /* [nclusters]: no. of points in each cluster */\n    float    delta;\n    float  **clusters;   /* out: [nclusters][nfeatures] */\n    float  **new_centers;     /* [nclusters][nfeatures] */\n  \n\n    /* allocate space for returning variable clusters[] */\n    clusters    = (float**) malloc(nclusters *             sizeof(float*));\n    clusters[0] = (float*)  malloc(nclusters * nfeatures * sizeof(float));\n    for (i=1; i<nclusters; i++)\n        clusters[i] = clusters[i-1] + nfeatures;\n\n    /* randomly pick cluster centers */\n    for (i=0; i<nclusters; i++) {\n        //n = (int)rand() % npoints;\n        for (j=0; j<nfeatures; j++)\n            clusters[i][j] = feature[n][j];\n\t\tn++;\n    }\n\n    for (i=0; i<npoints; i++)\n\t\tmembership[i] = -1;\n\n    /* need to initialize new_centers_len and new_centers[0] to all 0 */\n    new_centers_len = (int*) calloc(nclusters, sizeof(int));\n\n    new_centers    = (float**) malloc(nclusters *",Is the k-means clustering algorithm implemented in the code parallelized with OpenMP directives?,No
Rodinia Kmeans Clustering - serial,"/******************************************************************************/\n/*IMPORTANT:  READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.         */\n/*By downloading, copying, installing or using the software you agree        */\n/*to this license.  If you do not agree to this license, do not download,    */\n/*install, copy or use the software.                                         */\n/*                                                                           */\n/*                                                                           */\n/*Copyright (c) 2005 Northwestern University                                 */\n/*All rights reserved.                                                       */\n\n/*Redistribution of the software in source and binary forms,                 */\n/*with or without modification, is permitted provided that the               */\n/*following conditions are met:                                              */\n/*                                                                           */\n/*1       Redistributions of source code must retain the above copyright     */\n/*        notice, this list of conditions and the following disclaimer.      */\n/*                                                                           */\n/*2       Redistributions in binary form must reproduce the above copyright   */\n/*        notice, this list of conditions and the following disclaimer in the */\n/*        documentation and/or other materials provided with the distribution.*/ \n/*                                                                            */\n/*3       Neither the name of Northwestern University nor the names of its    */\n/*        contributors may be used to endorse or promote products derived     */\n/*        from this software without specific prior written permission.       */\n/*                                                                            */\n/*THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ``AS    */\n/*IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED      */\n/*TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY, NON-INFRINGEMENT AND         */\n/*FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL          */\n/*NORTHWESTERN UNIVERSITY OR ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT,       */\n/*INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES          */\n/*(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR          */\n/*SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)          */\n/*HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,         */\n/*STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN    */\n/*ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE             */\n/*POSSIBILITY OF SUCH DAMAGE.                                                 */\n/******************************************************************************/\n/*************************************************************************/\n/**   File:         kmeans_clustering.c                                 **/\n/**   Description:  Implementation of regular k-means clustering        **/\n/**                 algorithm                                           **/\n/**   Author:  Wei-keng Liao                                            **/\n/**            ECE Department, Northwestern University                  **/\n/**            email: wkliao@ece.northwestern.edu                       **/\n/**                                                                     **/\n/**   Edited by: Jay Pisharath                                          **/\n/**              Northwestern University.                               **/\n/**                                                                     **/\n/**   ================================================================  **/\n/**                                                                     **/\n/**   Edited by: Sang-Ha  Lee                                           **/\n/**                 University of Virginia                              **/\n/**                                                                     **/\n/**   Description:    No longer supports fuzzy c-means clustering;     **/\n/**                     only regular k-means clustering.               **/\n/**                     Simplified for main functionality: regular k-means    **/\n/**                     clustering.                                     **/\n/**                                                                     **/\n/*************************************************************************/\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <float.h>\n#include <math.h>\n#include \kmeans.h\""\n#include <omp.h>\n\n#define RANDOM_MAX 2147483647\n\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\n\nextern double wtime(void);\n\nint find_nearest_point(float  *pt,          /* [nfeatures] */\n                       int     nfeatures,\n                       float **pts,         /* [npts][nfeatures] */\n                       int     npts)\n{\n    int index, i;\n    float min_dist=FLT_MAX;\n\n    /* find the cluster center id with min distance to pt */\n    for (i=0; i<npts; i++) {\n        float dist;\n        dist = euclid_dist_2(pt, pts[i], nfeatures);  /* no need square root */\n        if (dist < min_dist) {\n            min_dist = dist;\n            index    = i;\n        }\n    }\n    return(index);\n}\n\n/*----< euclid_dist_2() >----------------------------------------------------*/\n/* multi-dimensional spatial Euclid distance square */\n__inline\nfloat euclid_dist_2(float *pt1,\n                    float *pt2,\n                    int    numdims)\n{\n    int i;\n    float ans=0.0;\n\n    for (i=0; i<numdims; i++)\n        ans += (pt1[i]-pt2[i]) * (pt1[i]-pt2[i]);\n\n    return(ans);\n}\n\n\n/*----< kmeans_clustering() >---------------------------------------------*/\nfloat** kmeans_clustering(float **feature,    /* in: [npoints][nfeatures] */\n                          int     nfeatures,\n                          int     npoints,\n                          int     nclusters,\n                          float   threshold,\n                          int    *membership) /* out: [npoints] */\n{\n\n    int      i, j, n=0, index, loop=0;\n    int     *new_centers_len; /* [nclusters]: no. of points in each cluster */\n    float    delta;\n    float  **clusters;   /* out: [nclusters][nfeatures] */\n    float  **new_centers;     /* [nclusters][nfeatures] */\n  \n\n    /* allocate space for returning variable clusters[] */\n    clusters    = (float**) malloc(nclusters *             sizeof(float*));\n    clusters[0] = (float*)  malloc(nclusters * nfeatures * sizeof(float));\n    for (i=1; i<nclusters; i++)\n        clusters[i] = clusters[i-1] + nfeatures;\n\n    /* randomly pick cluster centers */\n    for (i=0; i<nclusters; i++) {\n        //n = (int)rand() % npoints;\n        for (j=0; j<nfeatures; j++)\n            clusters[i][j] = feature[n][j];\n\t\tn++;\n    }\n\n    for (i=0; i<npoints; i++)\n\t\tmembership[i] = -1;\n\n    /* need to initialize new_centers_len and new_centers[0] to all 0 */\n    new_centers_len = (int*) calloc(nclusters, sizeof(int));\n\n    new_centers    = (float**) malloc(nclusters *",Is the function 'euclid_dist_2' responsible for calculating the Euclidean distance between two points?,Yes
Rodinia Kmeans Clustering - serial,"/******************************************************************************/\n/*IMPORTANT:  READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.         */\n/*By downloading, copying, installing or using the software you agree        */\n/*to this license.  If you do not agree to this license, do not download,    */\n/*install, copy or use the software.                                         */\n/*                                                                           */\n/*                                                                           */\n/*Copyright (c) 2005 Northwestern University                                 */\n/*All rights reserved.                                                       */\n\n/*Redistribution of the software in source and binary forms,                 */\n/*with or without modification, is permitted provided that the               */\n/*following conditions are met:                                              */\n/*                                                                           */\n/*1       Redistributions of source code must retain the above copyright     */\n/*        notice, this list of conditions and the following disclaimer.      */\n/*                                                                           */\n/*2       Redistributions in binary form must reproduce the above copyright   */\n/*        notice, this list of conditions and the following disclaimer in the */\n/*        documentation and/or other materials provided with the distribution.*/ \n/*                                                                            */\n/*3       Neither the name of Northwestern University nor the names of its    */\n/*        contributors may be used to endorse or promote products derived     */\n/*        from this software without specific prior written permission.       */\n/*                                                                            */\n/*THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ``AS    */\n/*IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED      */\n/*TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY, NON-INFRINGEMENT AND         */\n/*FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL          */\n/*NORTHWESTERN UNIVERSITY OR ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT,       */\n/*INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES          */\n/*(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR          */\n/*SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)          */\n/*HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,         */\n/*STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN    */\n/*ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE             */\n/*POSSIBILITY OF SUCH DAMAGE.                                                 */\n/******************************************************************************/\n/*************************************************************************/\n/**   File:         kmeans_clustering.c                                 **/\n/**   Description:  Implementation of regular k-means clustering        **/\n/**                 algorithm                                           **/\n/**   Author:  Wei-keng Liao                                            **/\n/**            ECE Department, Northwestern University                  **/\n/**            email: wkliao@ece.northwestern.edu                       **/\n/**                                                                     **/\n/**   Edited by: Jay Pisharath                                          **/\n/**              Northwestern University.                               **/\n/**                                                                     **/\n/**   ================================================================  **/\n/**                                                                     **/\n/**   Edited by: Sang-Ha  Lee                                           **/\n/**                 University of Virginia                              **/\n/**                                                                     **/\n/**   Description:    No longer supports fuzzy c-means clustering;     **/\n/**                     only regular k-means clustering.               **/\n/**                     Simplified for main functionality: regular k-means    **/\n/**                     clustering.                                     **/\n/**                                                                     **/\n/*************************************************************************/\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <float.h>\n#include <math.h>\n#include \kmeans.h\""\n#include <omp.h>\n\n#define RANDOM_MAX 2147483647\n\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\n\nextern double wtime(void);\n\nint find_nearest_point(float  *pt,          /* [nfeatures] */\n                       int     nfeatures,\n                       float **pts,         /* [npts][nfeatures] */\n                       int     npts)\n{\n    int index, i;\n    float min_dist=FLT_MAX;\n\n    /* find the cluster center id with min distance to pt */\n    for (i=0; i<npts; i++) {\n        float dist;\n        dist = euclid_dist_2(pt, pts[i], nfeatures);  /* no need square root */\n        if (dist < min_dist) {\n            min_dist = dist;\n            index    = i;\n        }\n    }\n    return(index);\n}\n\n/*----< euclid_dist_2() >----------------------------------------------------*/\n/* multi-dimensional spatial Euclid distance square */\n__inline\nfloat euclid_dist_2(float *pt1,\n                    float *pt2,\n                    int    numdims)\n{\n    int i;\n    float ans=0.0;\n\n    for (i=0; i<numdims; i++)\n        ans += (pt1[i]-pt2[i]) * (pt1[i]-pt2[i]);\n\n    return(ans);\n}\n\n\n/*----< kmeans_clustering() >---------------------------------------------*/\nfloat** kmeans_clustering(float **feature,    /* in: [npoints][nfeatures] */\n                          int     nfeatures,\n                          int     npoints,\n                          int     nclusters,\n                          float   threshold,\n                          int    *membership) /* out: [npoints] */\n{\n\n    int      i, j, n=0, index, loop=0;\n    int     *new_centers_len; /* [nclusters]: no. of points in each cluster */\n    float    delta;\n    float  **clusters;   /* out: [nclusters][nfeatures] */\n    float  **new_centers;     /* [nclusters][nfeatures] */\n  \n\n    /* allocate space for returning variable clusters[] */\n    clusters    = (float**) malloc(nclusters *             sizeof(float*));\n    clusters[0] = (float*)  malloc(nclusters * nfeatures * sizeof(float));\n    for (i=1; i<nclusters; i++)\n        clusters[i] = clusters[i-1] + nfeatures;\n\n    /* randomly pick cluster centers */\n    for (i=0; i<nclusters; i++) {\n        //n = (int)rand() % npoints;\n        for (j=0; j<nfeatures; j++)\n            clusters[i][j] = feature[n][j];\n\t\tn++;\n    }\n\n    for (i=0; i<npoints; i++)\n\t\tmembership[i] = -1;\n\n    /* need to initialize new_centers_len and new_centers[0] to all 0 */\n    new_centers_len = (int*) calloc(nclusters, sizeof(int));\n\n    new_centers    = (float**) malloc(nclusters *",Does the function 'find_nearest_point' return the index of the cluster center closest to a given point?,Yes
Rodinia Kmeans Clustering - serial,"/******************************************************************************/\n/*IMPORTANT:  READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.         */\n/*By downloading, copying, installing or using the software you agree        */\n/*to this license.  If you do not agree to this license, do not download,    */\n/*install, copy or use the software.                                         */\n/*                                                                           */\n/*                                                                           */\n/*Copyright (c) 2005 Northwestern University                                 */\n/*All rights reserved.                                                       */\n\n/*Redistribution of the software in source and binary forms,                 */\n/*with or without modification, is permitted provided that the               */\n/*following conditions are met:                                              */\n/*                                                                           */\n/*1       Redistributions of source code must retain the above copyright     */\n/*        notice, this list of conditions and the following disclaimer.      */\n/*                                                                           */\n/*2       Redistributions in binary form must reproduce the above copyright   */\n/*        notice, this list of conditions and the following disclaimer in the */\n/*        documentation and/or other materials provided with the distribution.*/ \n/*                                                                            */\n/*3       Neither the name of Northwestern University nor the names of its    */\n/*        contributors may be used to endorse or promote products derived     */\n/*        from this software without specific prior written permission.       */\n/*                                                                            */\n/*THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ``AS    */\n/*IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED      */\n/*TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY, NON-INFRINGEMENT AND         */\n/*FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL          */\n/*NORTHWESTERN UNIVERSITY OR ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT,       */\n/*INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES          */\n/*(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR          */\n/*SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)          */\n/*HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,         */\n/*STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN    */\n/*ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE             */\n/*POSSIBILITY OF SUCH DAMAGE.                                                 */\n/******************************************************************************/\n/*************************************************************************/\n/**   File:         kmeans_clustering.c                                 **/\n/**   Description:  Implementation of regular k-means clustering        **/\n/**                 algorithm                                           **/\n/**   Author:  Wei-keng Liao                                            **/\n/**            ECE Department, Northwestern University                  **/\n/**            email: wkliao@ece.northwestern.edu                       **/\n/**                                                                     **/\n/**   Edited by: Jay Pisharath                                          **/\n/**              Northwestern University.                               **/\n/**                                                                     **/\n/**   ================================================================  **/\n/**                                                                     **/\n/**   Edited by: Sang-Ha  Lee                                           **/\n/**                 University of Virginia                              **/\n/**                                                                     **/\n/**   Description:    No longer supports fuzzy c-means clustering;     **/\n/**                     only regular k-means clustering.               **/\n/**                     Simplified for main functionality: regular k-means    **/\n/**                     clustering.                                     **/\n/**                                                                     **/\n/*************************************************************************/\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <float.h>\n#include <math.h>\n#include \kmeans.h\""\n#include <omp.h>\n\n#define RANDOM_MAX 2147483647\n\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\n\nextern double wtime(void);\n\nint find_nearest_point(float  *pt,          /* [nfeatures] */\n                       int     nfeatures,\n                       float **pts,         /* [npts][nfeatures] */\n                       int     npts)\n{\n    int index, i;\n    float min_dist=FLT_MAX;\n\n    /* find the cluster center id with min distance to pt */\n    for (i=0; i<npts; i++) {\n        float dist;\n        dist = euclid_dist_2(pt, pts[i], nfeatures);  /* no need square root */\n        if (dist < min_dist) {\n            min_dist = dist;\n            index    = i;\n        }\n    }\n    return(index);\n}\n\n/*----< euclid_dist_2() >----------------------------------------------------*/\n/* multi-dimensional spatial Euclid distance square */\n__inline\nfloat euclid_dist_2(float *pt1,\n                    float *pt2,\n                    int    numdims)\n{\n    int i;\n    float ans=0.0;\n\n    for (i=0; i<numdims; i++)\n        ans += (pt1[i]-pt2[i]) * (pt1[i]-pt2[i]);\n\n    return(ans);\n}\n\n\n/*----< kmeans_clustering() >---------------------------------------------*/\nfloat** kmeans_clustering(float **feature,    /* in: [npoints][nfeatures] */\n                          int     nfeatures,\n                          int     npoints,\n                          int     nclusters,\n                          float   threshold,\n                          int    *membership) /* out: [npoints] */\n{\n\n    int      i, j, n=0, index, loop=0;\n    int     *new_centers_len; /* [nclusters]: no. of points in each cluster */\n    float    delta;\n    float  **clusters;   /* out: [nclusters][nfeatures] */\n    float  **new_centers;     /* [nclusters][nfeatures] */\n  \n\n    /* allocate space for returning variable clusters[] */\n    clusters    = (float**) malloc(nclusters *             sizeof(float*));\n    clusters[0] = (float*)  malloc(nclusters * nfeatures * sizeof(float));\n    for (i=1; i<nclusters; i++)\n        clusters[i] = clusters[i-1] + nfeatures;\n\n    /* randomly pick cluster centers */\n    for (i=0; i<nclusters; i++) {\n        //n = (int)rand() % npoints;\n        for (j=0; j<nfeatures; j++)\n            clusters[i][j] = feature[n][j];\n\t\tn++;\n    }\n\n    for (i=0; i<npoints; i++)\n\t\tmembership[i] = -1;\n\n    /* need to initialize new_centers_len and new_centers[0] to all 0 */\n    new_centers_len = (int*) calloc(nclusters, sizeof(int));\n\n    new_centers    = (float**) malloc(nclusters *",Is the function 'kmeans_clustering' used to allocate space for the returning variable 'clusters'?,Yes
Rodinia Kmeans Clustering - serial,"/******************************************************************************/\n/*IMPORTANT:  READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.         */\n/*By downloading, copying, installing or using the software you agree        */\n/*to this license.  If you do not agree to this license, do not download,    */\n/*install, copy or use the software.                                         */\n/*                                                                           */\n/*                                                                           */\n/*Copyright (c) 2005 Northwestern University                                 */\n/*All rights reserved.                                                       */\n\n/*Redistribution of the software in source and binary forms,                 */\n/*with or without modification, is permitted provided that the               */\n/*following conditions are met:                                              */\n/*                                                                           */\n/*1       Redistributions of source code must retain the above copyright     */\n/*        notice, this list of conditions and the following disclaimer.      */\n/*                                                                           */\n/*2       Redistributions in binary form must reproduce the above copyright   */\n/*        notice, this list of conditions and the following disclaimer in the */\n/*        documentation and/or other materials provided with the distribution.*/ \n/*                                                                            */\n/*3       Neither the name of Northwestern University nor the names of its    */\n/*        contributors may be used to endorse or promote products derived     */\n/*        from this software without specific prior written permission.       */\n/*                                                                            */\n/*THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ``AS    */\n/*IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED      */\n/*TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY, NON-INFRINGEMENT AND         */\n/*FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL          */\n/*NORTHWESTERN UNIVERSITY OR ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT,       */\n/*INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES          */\n/*(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR          */\n/*SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)          */\n/*HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,         */\n/*STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN    */\n/*ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE             */\n/*POSSIBILITY OF SUCH DAMAGE.                                                 */\n/******************************************************************************/\n/*************************************************************************/\n/**   File:         kmeans_clustering.c                                 **/\n/**   Description:  Implementation of regular k-means clustering        **/\n/**                 algorithm                                           **/\n/**   Author:  Wei-keng Liao                                            **/\n/**            ECE Department, Northwestern University                  **/\n/**            email: wkliao@ece.northwestern.edu                       **/\n/**                                                                     **/\n/**   Edited by: Jay Pisharath                                          **/\n/**              Northwestern University.                               **/\n/**                                                                     **/\n/**   ================================================================  **/\n/**                                                                     **/\n/**   Edited by: Sang-Ha  Lee                                           **/\n/**                 University of Virginia                              **/\n/**                                                                     **/\n/**   Description:    No longer supports fuzzy c-means clustering;     **/\n/**                     only regular k-means clustering.               **/\n/**                     Simplified for main functionality: regular k-means    **/\n/**                     clustering.                                     **/\n/**                                                                     **/\n/*************************************************************************/\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <float.h>\n#include <math.h>\n#include \kmeans.h\""\n#include <omp.h>\n\n#define RANDOM_MAX 2147483647\n\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\n\nextern double wtime(void);\n\nint find_nearest_point(float  *pt,          /* [nfeatures] */\n                       int     nfeatures,\n                       float **pts,         /* [npts][nfeatures] */\n                       int     npts)\n{\n    int index, i;\n    float min_dist=FLT_MAX;\n\n    /* find the cluster center id with min distance to pt */\n    for (i=0; i<npts; i++) {\n        float dist;\n        dist = euclid_dist_2(pt, pts[i], nfeatures);  /* no need square root */\n        if (dist < min_dist) {\n            min_dist = dist;\n            index    = i;\n        }\n    }\n    return(index);\n}\n\n/*----< euclid_dist_2() >----------------------------------------------------*/\n/* multi-dimensional spatial Euclid distance square */\n__inline\nfloat euclid_dist_2(float *pt1,\n                    float *pt2,\n                    int    numdims)\n{\n    int i;\n    float ans=0.0;\n\n    for (i=0; i<numdims; i++)\n        ans += (pt1[i]-pt2[i]) * (pt1[i]-pt2[i]);\n\n    return(ans);\n}\n\n\n/*----< kmeans_clustering() >---------------------------------------------*/\nfloat** kmeans_clustering(float **feature,    /* in: [npoints][nfeatures] */\n                          int     nfeatures,\n                          int     npoints,\n                          int     nclusters,\n                          float   threshold,\n                          int    *membership) /* out: [npoints] */\n{\n\n    int      i, j, n=0, index, loop=0;\n    int     *new_centers_len; /* [nclusters]: no. of points in each cluster */\n    float    delta;\n    float  **clusters;   /* out: [nclusters][nfeatures] */\n    float  **new_centers;     /* [nclusters][nfeatures] */\n  \n\n    /* allocate space for returning variable clusters[] */\n    clusters    = (float**) malloc(nclusters *             sizeof(float*));\n    clusters[0] = (float*)  malloc(nclusters * nfeatures * sizeof(float));\n    for (i=1; i<nclusters; i++)\n        clusters[i] = clusters[i-1] + nfeatures;\n\n    /* randomly pick cluster centers */\n    for (i=0; i<nclusters; i++) {\n        //n = (int)rand() % npoints;\n        for (j=0; j<nfeatures; j++)\n            clusters[i][j] = feature[n][j];\n\t\tn++;\n    }\n\n    for (i=0; i<npoints; i++)\n\t\tmembership[i] = -1;\n\n    /* need to initialize new_centers_len and new_centers[0] to all 0 */\n    new_centers_len = (int*) calloc(nclusters, sizeof(int));\n\n    new_centers    = (float**) malloc(nclusters *","In the function 'kmeans_clustering', are the initial cluster centers chosen randomly from the dataset?",No
Rodinia Kmeans Clustering - serial,"/******************************************************************************/\n/*IMPORTANT:  READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.         */\n/*By downloading, copying, installing or using the software you agree        */\n/*to this license.  If you do not agree to this license, do not download,    */\n/*install, copy or use the software.                                         */\n/*                                                                           */\n/*                                                                           */\n/*Copyright (c) 2005 Northwestern University                                 */\n/*All rights reserved.                                                       */\n\n/*Redistribution of the software in source and binary forms,                 */\n/*with or without modification, is permitted provided that the               */\n/*following conditions are met:                                              */\n/*                                                                           */\n/*1       Redistributions of source code must retain the above copyright     */\n/*        notice, this list of conditions and the following disclaimer.      */\n/*                                                                           */\n/*2       Redistributions in binary form must reproduce the above copyright   */\n/*        notice, this list of conditions and the following disclaimer in the */\n/*        documentation and/or other materials provided with the distribution.*/ \n/*                                                                            */\n/*3       Neither the name of Northwestern University nor the names of its    */\n/*        contributors may be used to endorse or promote products derived     */\n/*        from this software without specific prior written permission.       */\n/*                                                                            */\n/*THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ``AS    */\n/*IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED      */\n/*TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY, NON-INFRINGEMENT AND         */\n/*FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL          */\n/*NORTHWESTERN UNIVERSITY OR ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT,       */\n/*INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES          */\n/*(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR          */\n/*SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)          */\n/*HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,         */\n/*STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN    */\n/*ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE             */\n/*POSSIBILITY OF SUCH DAMAGE.                                                 */\n/******************************************************************************/\n/*************************************************************************/\n/**   File:         kmeans_clustering.c                                 **/\n/**   Description:  Implementation of regular k-means clustering        **/\n/**                 algorithm                                           **/\n/**   Author:  Wei-keng Liao                                            **/\n/**            ECE Department, Northwestern University                  **/\n/**            email: wkliao@ece.northwestern.edu                       **/\n/**                                                                     **/\n/**   Edited by: Jay Pisharath                                          **/\n/**              Northwestern University.                               **/\n/**                                                                     **/\n/**   ================================================================  **/\n/**                                                                     **/\n/**   Edited by: Sang-Ha  Lee                                           **/\n/**                 University of Virginia                              **/\n/**                                                                     **/\n/**   Description:    No longer supports fuzzy c-means clustering;     **/\n/**                     only regular k-means clustering.               **/\n/**                     Simplified for main functionality: regular k-means    **/\n/**                     clustering.                                     **/\n/**                                                                     **/\n/*************************************************************************/\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <float.h>\n#include <math.h>\n#include \kmeans.h\""\n#include <omp.h>\n\n#define RANDOM_MAX 2147483647\n\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\n\nextern double wtime(void);\n\nint find_nearest_point(float  *pt,          /* [nfeatures] */\n                       int     nfeatures,\n                       float **pts,         /* [npts][nfeatures] */\n                       int     npts)\n{\n    int index, i;\n    float min_dist=FLT_MAX;\n\n    /* find the cluster center id with min distance to pt */\n    for (i=0; i<npts; i++) {\n        float dist;\n        dist = euclid_dist_2(pt, pts[i], nfeatures);  /* no need square root */\n        if (dist < min_dist) {\n            min_dist = dist;\n            index    = i;\n        }\n    }\n    return(index);\n}\n\n/*----< euclid_dist_2() >----------------------------------------------------*/\n/* multi-dimensional spatial Euclid distance square */\n__inline\nfloat euclid_dist_2(float *pt1,\n                    float *pt2,\n                    int    numdims)\n{\n    int i;\n    float ans=0.0;\n\n    for (i=0; i<numdims; i++)\n        ans += (pt1[i]-pt2[i]) * (pt1[i]-pt2[i]);\n\n    return(ans);\n}\n\n\n/*----< kmeans_clustering() >---------------------------------------------*/\nfloat** kmeans_clustering(float **feature,    /* in: [npoints][nfeatures] */\n                          int     nfeatures,\n                          int     npoints,\n                          int     nclusters,\n                          float   threshold,\n                          int    *membership) /* out: [npoints] */\n{\n\n    int      i, j, n=0, index, loop=0;\n    int     *new_centers_len; /* [nclusters]: no. of points in each cluster */\n    float    delta;\n    float  **clusters;   /* out: [nclusters][nfeatures] */\n    float  **new_centers;     /* [nclusters][nfeatures] */\n  \n\n    /* allocate space for returning variable clusters[] */\n    clusters    = (float**) malloc(nclusters *             sizeof(float*));\n    clusters[0] = (float*)  malloc(nclusters * nfeatures * sizeof(float));\n    for (i=1; i<nclusters; i++)\n        clusters[i] = clusters[i-1] + nfeatures;\n\n    /* randomly pick cluster centers */\n    for (i=0; i<nclusters; i++) {\n        //n = (int)rand() % npoints;\n        for (j=0; j<nfeatures; j++)\n            clusters[i][j] = feature[n][j];\n\t\tn++;\n    }\n\n    for (i=0; i<npoints; i++)\n\t\tmembership[i] = -1;\n\n    /* need to initialize new_centers_len and new_centers[0] to all 0 */\n    new_centers_len = (int*) calloc(nclusters, sizeof(int));\n\n    new_centers    = (float**) malloc(nclusters *",Is OpenMP used in the code to parallelize the loop for calculating the Euclidean distance in 'euclid_dist_2'?,No
Rodinia Kmeans Clustering - serial,"/******************************************************************************/\n/*IMPORTANT:  READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.         */\n/*By downloading, copying, installing or using the software you agree        */\n/*to this license.  If you do not agree to this license, do not download,    */\n/*install, copy or use the software.                                         */\n/*                                                                           */\n/*                                                                           */\n/*Copyright (c) 2005 Northwestern University                                 */\n/*All rights reserved.                                                       */\n\n/*Redistribution of the software in source and binary forms,                 */\n/*with or without modification, is permitted provided that the               */\n/*following conditions are met:                                              */\n/*                                                                           */\n/*1       Redistributions of source code must retain the above copyright     */\n/*        notice, this list of conditions and the following disclaimer.      */\n/*                                                                           */\n/*2       Redistributions in binary form must reproduce the above copyright   */\n/*        notice, this list of conditions and the following disclaimer in the */\n/*        documentation and/or other materials provided with the distribution.*/ \n/*                                                                            */\n/*3       Neither the name of Northwestern University nor the names of its    */\n/*        contributors may be used to endorse or promote products derived     */\n/*        from this software without specific prior written permission.       */\n/*                                                                            */\n/*THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ``AS    */\n/*IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED      */\n/*TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY, NON-INFRINGEMENT AND         */\n/*FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL          */\n/*NORTHWESTERN UNIVERSITY OR ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT,       */\n/*INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES          */\n/*(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR          */\n/*SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)          */\n/*HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,         */\n/*STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN    */\n/*ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE             */\n/*POSSIBILITY OF SUCH DAMAGE.                                                 */\n/******************************************************************************/\n/*************************************************************************/\n/**   File:         kmeans_clustering.c                                 **/\n/**   Description:  Implementation of regular k-means clustering        **/\n/**                 algorithm                                           **/\n/**   Author:  Wei-keng Liao                                            **/\n/**            ECE Department, Northwestern University                  **/\n/**            email: wkliao@ece.northwestern.edu                       **/\n/**                                                                     **/\n/**   Edited by: Jay Pisharath                                          **/\n/**              Northwestern University.                               **/\n/**                                                                     **/\n/**   ================================================================  **/\n/**                                                                     **/\n/**   Edited by: Sang-Ha  Lee                                           **/\n/**                 University of Virginia                              **/\n/**                                                                     **/\n/**   Description:    No longer supports fuzzy c-means clustering;     **/\n/**                     only regular k-means clustering.               **/\n/**                     Simplified for main functionality: regular k-means    **/\n/**                     clustering.                                     **/\n/**                                                                     **/\n/*************************************************************************/\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <float.h>\n#include <math.h>\n#include \kmeans.h\""\n#include <omp.h>\n\n#define RANDOM_MAX 2147483647\n\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\n\nextern double wtime(void);\n\nint find_nearest_point(float  *pt,          /* [nfeatures] */\n                       int     nfeatures,\n                       float **pts,         /* [npts][nfeatures] */\n                       int     npts)\n{\n    int index, i;\n    float min_dist=FLT_MAX;\n\n    /* find the cluster center id with min distance to pt */\n    for (i=0; i<npts; i++) {\n        float dist;\n        dist = euclid_dist_2(pt, pts[i], nfeatures);  /* no need square root */\n        if (dist < min_dist) {\n            min_dist = dist;\n            index    = i;\n        }\n    }\n    return(index);\n}\n\n/*----< euclid_dist_2() >----------------------------------------------------*/\n/* multi-dimensional spatial Euclid distance square */\n__inline\nfloat euclid_dist_2(float *pt1,\n                    float *pt2,\n                    int    numdims)\n{\n    int i;\n    float ans=0.0;\n\n    for (i=0; i<numdims; i++)\n        ans += (pt1[i]-pt2[i]) * (pt1[i]-pt2[i]);\n\n    return(ans);\n}\n\n\n/*----< kmeans_clustering() >---------------------------------------------*/\nfloat** kmeans_clustering(float **feature,    /* in: [npoints][nfeatures] */\n                          int     nfeatures,\n                          int     npoints,\n                          int     nclusters,\n                          float   threshold,\n                          int    *membership) /* out: [npoints] */\n{\n\n    int      i, j, n=0, index, loop=0;\n    int     *new_centers_len; /* [nclusters]: no. of points in each cluster */\n    float    delta;\n    float  **clusters;   /* out: [nclusters][nfeatures] */\n    float  **new_centers;     /* [nclusters][nfeatures] */\n  \n\n    /* allocate space for returning variable clusters[] */\n    clusters    = (float**) malloc(nclusters *             sizeof(float*));\n    clusters[0] = (float*)  malloc(nclusters * nfeatures * sizeof(float));\n    for (i=1; i<nclusters; i++)\n        clusters[i] = clusters[i-1] + nfeatures;\n\n    /* randomly pick cluster centers */\n    for (i=0; i<nclusters; i++) {\n        //n = (int)rand() % npoints;\n        for (j=0; j<nfeatures; j++)\n            clusters[i][j] = feature[n][j];\n\t\tn++;\n    }\n\n    for (i=0; i<npoints; i++)\n\t\tmembership[i] = -1;\n\n    /* need to initialize new_centers_len and new_centers[0] to all 0 */\n    new_centers_len = (int*) calloc(nclusters, sizeof(int));\n\n    new_centers    = (float**) malloc(nclusters *",Does the code run the kmeans algorithm till the cluster centers have ceased changing?,No
Rodinia Kmeans Clustering - serial,"/******************************************************************************/\n/*IMPORTANT:  READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.         */\n/*By downloading, copying, installing or using the software you agree        */\n/*to this license.  If you do not agree to this license, do not download,    */\n/*install, copy or use the software.                                         */\n/*                                                                           */\n/*                                                                           */\n/*Copyright (c) 2005 Northwestern University                                 */\n/*All rights reserved.                                                       */\n\n/*Redistribution of the software in source and binary forms,                 */\n/*with or without modification, is permitted provided that the               */\n/*following conditions are met:                                              */\n/*                                                                           */\n/*1       Redistributions of source code must retain the above copyright     */\n/*        notice, this list of conditions and the following disclaimer.      */\n/*                                                                           */\n/*2       Redistributions in binary form must reproduce the above copyright   */\n/*        notice, this list of conditions and the following disclaimer in the */\n/*        documentation and/or other materials provided with the distribution.*/ \n/*                                                                            */\n/*3       Neither the name of Northwestern University nor the names of its    */\n/*        contributors may be used to endorse or promote products derived     */\n/*        from this software without specific prior written permission.       */\n/*                                                                            */\n/*THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ``AS    */\n/*IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED      */\n/*TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY, NON-INFRINGEMENT AND         */\n/*FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL          */\n/*NORTHWESTERN UNIVERSITY OR ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT,       */\n/*INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES          */\n/*(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR          */\n/*SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)          */\n/*HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,         */\n/*STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN    */\n/*ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE             */\n/*POSSIBILITY OF SUCH DAMAGE.                                                 */\n/******************************************************************************/\n/*************************************************************************/\n/**   File:         kmeans_clustering.c                                 **/\n/**   Description:  Implementation of regular k-means clustering        **/\n/**                 algorithm                                           **/\n/**   Author:  Wei-keng Liao                                            **/\n/**            ECE Department, Northwestern University                  **/\n/**            email: wkliao@ece.northwestern.edu                       **/\n/**                                                                     **/\n/**   Edited by: Jay Pisharath                                          **/\n/**              Northwestern University.                               **/\n/**                                                                     **/\n/**   ================================================================  **/\n/**                                                                     **/\n/**   Edited by: Sang-Ha  Lee                                           **/\n/**                 University of Virginia                              **/\n/**                                                                     **/\n/**   Description:    No longer supports fuzzy c-means clustering;     **/\n/**                     only regular k-means clustering.               **/\n/**                     Simplified for main functionality: regular k-means    **/\n/**                     clustering.                                     **/\n/**                                                                     **/\n/*************************************************************************/\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <float.h>\n#include <math.h>\n#include \kmeans.h\""\n#include <omp.h>\n\n#define RANDOM_MAX 2147483647\n\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\n\nextern double wtime(void);\n\nint find_nearest_point(float  *pt,          /* [nfeatures] */\n                       int     nfeatures,\n                       float **pts,         /* [npts][nfeatures] */\n                       int     npts)\n{\n    int index, i;\n    float min_dist=FLT_MAX;\n\n    /* find the cluster center id with min distance to pt */\n    for (i=0; i<npts; i++) {\n        float dist;\n        dist = euclid_dist_2(pt, pts[i], nfeatures);  /* no need square root */\n        if (dist < min_dist) {\n            min_dist = dist;\n            index    = i;\n        }\n    }\n    return(index);\n}\n\n/*----< euclid_dist_2() >----------------------------------------------------*/\n/* multi-dimensional spatial Euclid distance square */\n__inline\nfloat euclid_dist_2(float *pt1,\n                    float *pt2,\n                    int    numdims)\n{\n    int i;\n    float ans=0.0;\n\n    for (i=0; i<numdims; i++)\n        ans += (pt1[i]-pt2[i]) * (pt1[i]-pt2[i]);\n\n    return(ans);\n}\n\n\n/*----< kmeans_clustering() >---------------------------------------------*/\nfloat** kmeans_clustering(float **feature,    /* in: [npoints][nfeatures] */\n                          int     nfeatures,\n                          int     npoints,\n                          int     nclusters,\n                          float   threshold,\n                          int    *membership) /* out: [npoints] */\n{\n\n    int      i, j, n=0, index, loop=0;\n    int     *new_centers_len; /* [nclusters]: no. of points in each cluster */\n    float    delta;\n    float  **clusters;   /* out: [nclusters][nfeatures] */\n    float  **new_centers;     /* [nclusters][nfeatures] */\n  \n\n    /* allocate space for returning variable clusters[] */\n    clusters    = (float**) malloc(nclusters *             sizeof(float*));\n    clusters[0] = (float*)  malloc(nclusters * nfeatures * sizeof(float));\n    for (i=1; i<nclusters; i++)\n        clusters[i] = clusters[i-1] + nfeatures;\n\n    /* randomly pick cluster centers */\n    for (i=0; i<nclusters; i++) {\n        //n = (int)rand() % npoints;\n        for (j=0; j<nfeatures; j++)\n            clusters[i][j] = feature[n][j];\n\t\tn++;\n    }\n\n    for (i=0; i<npoints; i++)\n\t\tmembership[i] = -1;\n\n    /* need to initialize new_centers_len and new_centers[0] to all 0 */\n    new_centers_len = (int*) calloc(nclusters, sizeof(int));\n\n    new_centers    = (float**) malloc(nclusters *",Does the 'kmeans_clustering' function return the final cluster centers?,Yes
Rodinia Kmeans Clustering - serial,"/******************************************************************************/\n/*IMPORTANT:  READ BEFORE DOWNLOADING, COPYING, INSTALLING OR USING.         */\n/*By downloading, copying, installing or using the software you agree        */\n/*to this license.  If you do not agree to this license, do not download,    */\n/*install, copy or use the software.                                         */\n/*                                                                           */\n/*                                                                           */\n/*Copyright (c) 2005 Northwestern University                                 */\n/*All rights reserved.                                                       */\n\n/*Redistribution of the software in source and binary forms,                 */\n/*with or without modification, is permitted provided that the               */\n/*following conditions are met:                                              */\n/*                                                                           */\n/*1       Redistributions of source code must retain the above copyright     */\n/*        notice, this list of conditions and the following disclaimer.      */\n/*                                                                           */\n/*2       Redistributions in binary form must reproduce the above copyright   */\n/*        notice, this list of conditions and the following disclaimer in the */\n/*        documentation and/or other materials provided with the distribution.*/ \n/*                                                                            */\n/*3       Neither the name of Northwestern University nor the names of its    */\n/*        contributors may be used to endorse or promote products derived     */\n/*        from this software without specific prior written permission.       */\n/*                                                                            */\n/*THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ``AS    */\n/*IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED      */\n/*TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY, NON-INFRINGEMENT AND         */\n/*FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL          */\n/*NORTHWESTERN UNIVERSITY OR ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT,       */\n/*INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES          */\n/*(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR          */\n/*SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)          */\n/*HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,         */\n/*STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN    */\n/*ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE             */\n/*POSSIBILITY OF SUCH DAMAGE.                                                 */\n/******************************************************************************/\n/*************************************************************************/\n/**   File:         kmeans_clustering.c                                 **/\n/**   Description:  Implementation of regular k-means clustering        **/\n/**                 algorithm                                           **/\n/**   Author:  Wei-keng Liao                                            **/\n/**            ECE Department, Northwestern University                  **/\n/**            email: wkliao@ece.northwestern.edu                       **/\n/**                                                                     **/\n/**   Edited by: Jay Pisharath                                          **/\n/**              Northwestern University.                               **/\n/**                                                                     **/\n/**   ================================================================  **/\n/**                                                                     **/\n/**   Edited by: Sang-Ha  Lee                                           **/\n/**                 University of Virginia                              **/\n/**                                                                     **/\n/**   Description:    No longer supports fuzzy c-means clustering;     **/\n/**                     only regular k-means clustering.               **/\n/**                     Simplified for main functionality: regular k-means    **/\n/**                     clustering.                                     **/\n/**                                                                     **/\n/*************************************************************************/\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <float.h>\n#include <math.h>\n#include \kmeans.h\""\n#include <omp.h>\n\n#define RANDOM_MAX 2147483647\n\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\n\nextern double wtime(void);\n\nint find_nearest_point(float  *pt,          /* [nfeatures] */\n                       int     nfeatures,\n                       float **pts,         /* [npts][nfeatures] */\n                       int     npts)\n{\n    int index, i;\n    float min_dist=FLT_MAX;\n\n    /* find the cluster center id with min distance to pt */\n    for (i=0; i<npts; i++) {\n        float dist;\n        dist = euclid_dist_2(pt, pts[i], nfeatures);  /* no need square root */\n        if (dist < min_dist) {\n            min_dist = dist;\n            index    = i;\n        }\n    }\n    return(index);\n}\n\n/*----< euclid_dist_2() >----------------------------------------------------*/\n/* multi-dimensional spatial Euclid distance square */\n__inline\nfloat euclid_dist_2(float *pt1,\n                    float *pt2,\n                    int    numdims)\n{\n    int i;\n    float ans=0.0;\n\n    for (i=0; i<numdims; i++)\n        ans += (pt1[i]-pt2[i]) * (pt1[i]-pt2[i]);\n\n    return(ans);\n}\n\n\n/*----< kmeans_clustering() >---------------------------------------------*/\nfloat** kmeans_clustering(float **feature,    /* in: [npoints][nfeatures] */\n                          int     nfeatures,\n                          int     npoints,\n                          int     nclusters,\n                          float   threshold,\n                          int    *membership) /* out: [npoints] */\n{\n\n    int      i, j, n=0, index, loop=0;\n    int     *new_centers_len; /* [nclusters]: no. of points in each cluster */\n    float    delta;\n    float  **clusters;   /* out: [nclusters][nfeatures] */\n    float  **new_centers;     /* [nclusters][nfeatures] */\n  \n\n    /* allocate space for returning variable clusters[] */\n    clusters    = (float**) malloc(nclusters *             sizeof(float*));\n    clusters[0] = (float*)  malloc(nclusters * nfeatures * sizeof(float));\n    for (i=1; i<nclusters; i++)\n        clusters[i] = clusters[i-1] + nfeatures;\n\n    /* randomly pick cluster centers */\n    for (i=0; i<nclusters; i++) {\n        //n = (int)rand() % npoints;\n        for (j=0; j<nfeatures; j++)\n            clusters[i][j] = feature[n][j];\n\t\tn++;\n    }\n\n    for (i=0; i<npoints; i++)\n\t\tmembership[i] = -1;\n\n    /* need to initialize new_centers_len and new_centers[0] to all 0 */\n    new_centers_len = (int*) calloc(nclusters, sizeof(int));\n\n    new_centers    = (float**) malloc(nclusters *",Does the provided code use OpenMP reduction for optimizing the computational load in parallel processing?,No
Rodinia Kmeans Clustering - OpenMP,"#include <stdio.h>\n#include <stdlib.h>\n#include <float.h>\n#include <math.h>\n#include ""kmeans.h""\n#include <omp.h>\n#define RANDOM_MAX 2147483647\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\nextern double wtime(void);\nextern int num_omp_threads;\nint find_nearest_point(float  *pt, int     nfeatures, float **pts, int     npts) {\n    int index, i;\n    float min_dist=FLT_MAX;\n    for (i=0; i<npts; i++) {\n        float dist;\n        dist = euclid_dist_2(pt, pts[i], nfeatures);\n        if (dist < min_dist) {\n            min_dist = dist;\n            index    = i;\n        }\n    }\n    return(index);\n}\n__inline\nfloat euclid_dist_2(float *pt1,float *pt2,int    numdims) {\n    int i;\n    float ans=0.0;\n    for (i=0; i<numdims; i++)\n        ans += (pt1[i]-pt2[i]) * (pt1[i]-pt2[i]);\n    return(ans);\n}\nfloat** kmeans_clustering(float **feature, int     nfeatures, int     npoints, int     nclusters, float   threshold, int    *membership) {\n    int      i, j, k, n=0, index, loop=0;\n    int     *new_centers_len;\n    float  **new_centers;\n    float  **clusters;\n    float    delta;\n    double   timing;\n    int      nthreads;\n    int    **partial_new_centers_len;\n    float ***partial_new_centers;\n    nthreads = num_omp_threads; \n    clusters    = (float**) malloc(nclusters *             sizeof(float*));\n    clusters[0] = (float*)  malloc(nclusters * nfeatures * sizeof(float));\n    for (i=1; i<nclusters; i++)\n        clusters[i] = clusters[i-1] + nfeatures;\n    for (i=0; i<nclusters; i++) {\n        for (j=0; j<nfeatures; j++)\n            clusters[i][j] = feature[n][j];\n        n++;\n    }\n    for (i=0; i<npoints; i++)\n        membership[i] = -1;\n    new_centers_len = (int*) calloc(nclusters, sizeof(int));\n    new_centers    = (float**) malloc(nclusters *            sizeof(float*));\n    new_centers[0] = (float*)  calloc(nclusters * nfeatures, sizeof(float));\n    for (i=1; i<nclusters; i++)\n        new_centers[i] = new_centers[i-1] + nfeatures;\n    partial_new_centers_len    = (int**) malloc(nthreads * sizeof(int*));\n    partial_new_centers_len[0] = (int*)  calloc(nthreads*nclusters, sizeof(int));\n    for (i=1; i<nthreads; i++)\n        partial_new_centers_len[i] = partial_new_centers_len[i-1]+nclusters;\n    partial_new_centers    =(float***)malloc(nthreads * sizeof(float**));\n    partial_new_centers[0] =(float**) malloc(nthreads*nclusters * sizeof(float*));\n    for (i=1; i<nthreads; i++)\n        partial_new_centers[i] = partial_new_centers[i-1] + nclusters;\n    for (i=0; i<nthreads; i++)\n    {\n        for (j=0; j<nclusters; j++)\n            partial_new_centers[i][j] = (float*)calloc(nfeatures, sizeof(float));\n    }\n    printf(""num of threads = %d\n"", num_omp_threads);\n    do {\n        delta = 0.0;\n        omp_set_num_threads(num_omp_threads);\n        #pragma omp parallel shared(feature,clusters,membership,partial_new_centers,partial_new_centers_len)\n        {\n            int tid = omp_get_thread_num();\n            #pragma omp for private(i,j,index) firstprivate(npoints,nclusters,nfeatures) schedule(static) reduction(+:delta)\n            for (i=0; i<npoints; i++) {\n                index = find_nearest_point(feature[i],nfeatures,clusters,nclusters);\n                if (membership[i] != index) delta += 1.0;\n                membership[i] = index;\n                partial_new_centers_len[tid][index]++;\n                for (j=0; j<nfeatures; j++)\n                    partial_new_centers[tid][index][j] += feature[i][j];\n            }\n        }\n        for (i=0; i<nclusters; i++) {\n            for (j=0; j<nthreads; j++) {\n                new_centers_len[i] += partial_new_centers_len[j][i];\n                partial_new_centers_len[j][i]",Does this code use OpenMP directives to parallelize computation across multiple threads?,Yes
Rodinia Kmeans Clustering - OpenMP,"#include <stdio.h>\n#include <stdlib.h>\n#include <float.h>\n#include <math.h>\n#include ""kmeans.h""\n#include <omp.h>\n#define RANDOM_MAX 2147483647\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\nextern double wtime(void);\nextern int num_omp_threads;\nint find_nearest_point(float  *pt, int     nfeatures, float **pts, int     npts) {\n    int index, i;\n    float min_dist=FLT_MAX;\n    for (i=0; i<npts; i++) {\n        float dist;\n        dist = euclid_dist_2(pt, pts[i], nfeatures);\n        if (dist < min_dist) {\n            min_dist = dist;\n            index    = i;\n        }\n    }\n    return(index);\n}\n__inline\nfloat euclid_dist_2(float *pt1,float *pt2,int    numdims) {\n    int i;\n    float ans=0.0;\n    for (i=0; i<numdims; i++)\n        ans += (pt1[i]-pt2[i]) * (pt1[i]-pt2[i]);\n    return(ans);\n}\nfloat** kmeans_clustering(float **feature, int     nfeatures, int     npoints, int     nclusters, float   threshold, int    *membership) {\n    int      i, j, k, n=0, index, loop=0;\n    int     *new_centers_len;\n    float  **new_centers;\n    float  **clusters;\n    float    delta;\n    double   timing;\n    int      nthreads;\n    int    **partial_new_centers_len;\n    float ***partial_new_centers;\n    nthreads = num_omp_threads; \n    clusters    = (float**) malloc(nclusters *             sizeof(float*));\n    clusters[0] = (float*)  malloc(nclusters * nfeatures * sizeof(float));\n    for (i=1; i<nclusters; i++)\n        clusters[i] = clusters[i-1] + nfeatures;\n    for (i=0; i<nclusters; i++) {\n        for (j=0; j<nfeatures; j++)\n            clusters[i][j] = feature[n][j];\n        n++;\n    }\n    for (i=0; i<npoints; i++)\n        membership[i] = -1;\n    new_centers_len = (int*) calloc(nclusters, sizeof(int));\n    new_centers    = (float**) malloc(nclusters *            sizeof(float*));\n    new_centers[0] = (float*)  calloc(nclusters * nfeatures, sizeof(float));\n    for (i=1; i<nclusters; i++)\n        new_centers[i] = new_centers[i-1] + nfeatures;\n    partial_new_centers_len    = (int**) malloc(nthreads * sizeof(int*));\n    partial_new_centers_len[0] = (int*)  calloc(nthreads*nclusters, sizeof(int));\n    for (i=1; i<nthreads; i++)\n        partial_new_centers_len[i] = partial_new_centers_len[i-1]+nclusters;\n    partial_new_centers    =(float***)malloc(nthreads * sizeof(float**));\n    partial_new_centers[0] =(float**) malloc(nthreads*nclusters * sizeof(float*));\n    for (i=1; i<nthreads; i++)\n        partial_new_centers[i] = partial_new_centers[i-1] + nclusters;\n    for (i=0; i<nthreads; i++)\n    {\n        for (j=0; j<nclusters; j++)\n            partial_new_centers[i][j] = (float*)calloc(nfeatures, sizeof(float));\n    }\n    printf(""num of threads = %d\n"", num_omp_threads);\n    do {\n        delta = 0.0;\n        omp_set_num_threads(num_omp_threads);\n        #pragma omp parallel shared(feature,clusters,membership,partial_new_centers,partial_new_centers_len)\n        {\n            int tid = omp_get_thread_num();\n            #pragma omp for private(i,j,index) firstprivate(npoints,nclusters,nfeatures) schedule(static) reduction(+:delta)\n            for (i=0; i<npoints; i++) {\n                index = find_nearest_point(feature[i],nfeatures,clusters,nclusters);\n                if (membership[i] != index) delta += 1.0;\n                membership[i] = index;\n                partial_new_centers_len[tid][index]++;\n                for (j=0; j<nfeatures; j++)\n                    partial_new_centers[tid][index][j] += feature[i][j];\n            }\n        }\n        for (i=0; i<nclusters; i++) {\n            for (j=0; j<nthreads; j++) {\n                new_centers_len[i] += partial_new_centers_len[j][i];\n                partial_new_centers_len[j][i]",Does this code perform reduction operation to calculate the cumulative sum across multiple threads?,Yes
Rodinia Kmeans Clustering - OpenMP,"#include <stdio.h>\n#include <stdlib.h>\n#include <float.h>\n#include <math.h>\n#include ""kmeans.h""\n#include <omp.h>\n#define RANDOM_MAX 2147483647\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\nextern double wtime(void);\nextern int num_omp_threads;\nint find_nearest_point(float  *pt, int     nfeatures, float **pts, int     npts) {\n    int index, i;\n    float min_dist=FLT_MAX;\n    for (i=0; i<npts; i++) {\n        float dist;\n        dist = euclid_dist_2(pt, pts[i], nfeatures);\n        if (dist < min_dist) {\n            min_dist = dist;\n            index    = i;\n        }\n    }\n    return(index);\n}\n__inline\nfloat euclid_dist_2(float *pt1,float *pt2,int    numdims) {\n    int i;\n    float ans=0.0;\n    for (i=0; i<numdims; i++)\n        ans += (pt1[i]-pt2[i]) * (pt1[i]-pt2[i]);\n    return(ans);\n}\nfloat** kmeans_clustering(float **feature, int     nfeatures, int     npoints, int     nclusters, float   threshold, int    *membership) {\n    int      i, j, k, n=0, index, loop=0;\n    int     *new_centers_len;\n    float  **new_centers;\n    float  **clusters;\n    float    delta;\n    double   timing;\n    int      nthreads;\n    int    **partial_new_centers_len;\n    float ***partial_new_centers;\n    nthreads = num_omp_threads; \n    clusters    = (float**) malloc(nclusters *             sizeof(float*));\n    clusters[0] = (float*)  malloc(nclusters * nfeatures * sizeof(float));\n    for (i=1; i<nclusters; i++)\n        clusters[i] = clusters[i-1] + nfeatures;\n    for (i=0; i<nclusters; i++) {\n        for (j=0; j<nfeatures; j++)\n            clusters[i][j] = feature[n][j];\n        n++;\n    }\n    for (i=0; i<npoints; i++)\n        membership[i] = -1;\n    new_centers_len = (int*) calloc(nclusters, sizeof(int));\n    new_centers    = (float**) malloc(nclusters *            sizeof(float*));\n    new_centers[0] = (float*)  calloc(nclusters * nfeatures, sizeof(float));\n    for (i=1; i<nclusters; i++)\n        new_centers[i] = new_centers[i-1] + nfeatures;\n    partial_new_centers_len    = (int**) malloc(nthreads * sizeof(int*));\n    partial_new_centers_len[0] = (int*)  calloc(nthreads*nclusters, sizeof(int));\n    for (i=1; i<nthreads; i++)\n        partial_new_centers_len[i] = partial_new_centers_len[i-1]+nclusters;\n    partial_new_centers    =(float***)malloc(nthreads * sizeof(float**));\n    partial_new_centers[0] =(float**) malloc(nthreads*nclusters * sizeof(float*));\n    for (i=1; i<nthreads; i++)\n        partial_new_centers[i] = partial_new_centers[i-1] + nclusters;\n    for (i=0; i<nthreads; i++)\n    {\n        for (j=0; j<nclusters; j++)\n            partial_new_centers[i][j] = (float*)calloc(nfeatures, sizeof(float));\n    }\n    printf(""num of threads = %d\n"", num_omp_threads);\n    do {\n        delta = 0.0;\n        omp_set_num_threads(num_omp_threads);\n        #pragma omp parallel shared(feature,clusters,membership,partial_new_centers,partial_new_centers_len)\n        {\n            int tid = omp_get_thread_num();\n            #pragma omp for private(i,j,index) firstprivate(npoints,nclusters,nfeatures) schedule(static) reduction(+:delta)\n            for (i=0; i<npoints; i++) {\n                index = find_nearest_point(feature[i],nfeatures,clusters,nclusters);\n                if (membership[i] != index) delta += 1.0;\n                membership[i] = index;\n                partial_new_centers_len[tid][index]++;\n                for (j=0; j<nfeatures; j++)\n                    partial_new_centers[tid][index][j] += feature[i][j];\n            }\n        }\n        for (i=0; i<nclusters; i++) {\n            for (j=0; j<nthreads; j++) {\n                new_centers_len[i] += partial_new_centers_len[j][i];\n                partial_new_centers_len[j][i]","Does this code use OpenMP's 'firstprivate' clause to ensure that each thread gets a private copy of an existing variable, which is initialized with the value that the original variable had at the time the parallel region was encountered?",Yes
Rodinia Kmeans Clustering - OpenMP,"#include <stdio.h>\n#include <stdlib.h>\n#include <float.h>\n#include <math.h>\n#include ""kmeans.h""\n#include <omp.h>\n#define RANDOM_MAX 2147483647\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\nextern double wtime(void);\nextern int num_omp_threads;\nint find_nearest_point(float  *pt, int     nfeatures, float **pts, int     npts) {\n    int index, i;\n    float min_dist=FLT_MAX;\n    for (i=0; i<npts; i++) {\n        float dist;\n        dist = euclid_dist_2(pt, pts[i], nfeatures);\n        if (dist < min_dist) {\n            min_dist = dist;\n            index    = i;\n        }\n    }\n    return(index);\n}\n__inline\nfloat euclid_dist_2(float *pt1,float *pt2,int    numdims) {\n    int i;\n    float ans=0.0;\n    for (i=0; i<numdims; i++)\n        ans += (pt1[i]-pt2[i]) * (pt1[i]-pt2[i]);\n    return(ans);\n}\nfloat** kmeans_clustering(float **feature, int     nfeatures, int     npoints, int     nclusters, float   threshold, int    *membership) {\n    int      i, j, k, n=0, index, loop=0;\n    int     *new_centers_len;\n    float  **new_centers;\n    float  **clusters;\n    float    delta;\n    double   timing;\n    int      nthreads;\n    int    **partial_new_centers_len;\n    float ***partial_new_centers;\n    nthreads = num_omp_threads; \n    clusters    = (float**) malloc(nclusters *             sizeof(float*));\n    clusters[0] = (float*)  malloc(nclusters * nfeatures * sizeof(float));\n    for (i=1; i<nclusters; i++)\n        clusters[i] = clusters[i-1] + nfeatures;\n    for (i=0; i<nclusters; i++) {\n        for (j=0; j<nfeatures; j++)\n            clusters[i][j] = feature[n][j];\n        n++;\n    }\n    for (i=0; i<npoints; i++)\n        membership[i] = -1;\n    new_centers_len = (int*) calloc(nclusters, sizeof(int));\n    new_centers    = (float**) malloc(nclusters *            sizeof(float*));\n    new_centers[0] = (float*)  calloc(nclusters * nfeatures, sizeof(float));\n    for (i=1; i<nclusters; i++)\n        new_centers[i] = new_centers[i-1] + nfeatures;\n    partial_new_centers_len    = (int**) malloc(nthreads * sizeof(int*));\n    partial_new_centers_len[0] = (int*)  calloc(nthreads*nclusters, sizeof(int));\n    for (i=1; i<nthreads; i++)\n        partial_new_centers_len[i] = partial_new_centers_len[i-1]+nclusters;\n    partial_new_centers    =(float***)malloc(nthreads * sizeof(float**));\n    partial_new_centers[0] =(float**) malloc(nthreads*nclusters * sizeof(float*));\n    for (i=1; i<nthreads; i++)\n        partial_new_centers[i] = partial_new_centers[i-1] + nclusters;\n    for (i=0; i<nthreads; i++)\n    {\n        for (j=0; j<nclusters; j++)\n            partial_new_centers[i][j] = (float*)calloc(nfeatures, sizeof(float));\n    }\n    printf(""num of threads = %d\n"", num_omp_threads);\n    do {\n        delta = 0.0;\n        omp_set_num_threads(num_omp_threads);\n        #pragma omp parallel shared(feature,clusters,membership,partial_new_centers,partial_new_centers_len)\n        {\n            int tid = omp_get_thread_num();\n            #pragma omp for private(i,j,index) firstprivate(npoints,nclusters,nfeatures) schedule(static) reduction(+:delta)\n            for (i=0; i<npoints; i++) {\n                index = find_nearest_point(feature[i],nfeatures,clusters,nclusters);\n                if (membership[i] != index) delta += 1.0;\n                membership[i] = index;\n                partial_new_centers_len[tid][index]++;\n                for (j=0; j<nfeatures; j++)\n                    partial_new_centers[tid][index][j] += feature[i][j];\n            }\n        }\n        for (i=0; i<nclusters; i++) {\n            for (j=0; j<nthreads; j++) {\n                new_centers_len[i] += partial_new_centers_len[j][i];\n                partial_new_centers_len[j][i]",Does this code use dynamic scheduling strategy in the 'omp for' directive for load balancing?,No
Rodinia Kmeans Clustering - OpenMP,"#include <stdio.h>\n#include <stdlib.h>\n#include <float.h>\n#include <math.h>\n#include ""kmeans.h""\n#include <omp.h>\n#define RANDOM_MAX 2147483647\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\nextern double wtime(void);\nextern int num_omp_threads;\nint find_nearest_point(float  *pt, int     nfeatures, float **pts, int     npts) {\n    int index, i;\n    float min_dist=FLT_MAX;\n    for (i=0; i<npts; i++) {\n        float dist;\n        dist = euclid_dist_2(pt, pts[i], nfeatures);\n        if (dist < min_dist) {\n            min_dist = dist;\n            index    = i;\n        }\n    }\n    return(index);\n}\n__inline\nfloat euclid_dist_2(float *pt1,float *pt2,int    numdims) {\n    int i;\n    float ans=0.0;\n    for (i=0; i<numdims; i++)\n        ans += (pt1[i]-pt2[i]) * (pt1[i]-pt2[i]);\n    return(ans);\n}\nfloat** kmeans_clustering(float **feature, int     nfeatures, int     npoints, int     nclusters, float   threshold, int    *membership) {\n    int      i, j, k, n=0, index, loop=0;\n    int     *new_centers_len;\n    float  **new_centers;\n    float  **clusters;\n    float    delta;\n    double   timing;\n    int      nthreads;\n    int    **partial_new_centers_len;\n    float ***partial_new_centers;\n    nthreads = num_omp_threads; \n    clusters    = (float**) malloc(nclusters *             sizeof(float*));\n    clusters[0] = (float*)  malloc(nclusters * nfeatures * sizeof(float));\n    for (i=1; i<nclusters; i++)\n        clusters[i] = clusters[i-1] + nfeatures;\n    for (i=0; i<nclusters; i++) {\n        for (j=0; j<nfeatures; j++)\n            clusters[i][j] = feature[n][j];\n        n++;\n    }\n    for (i=0; i<npoints; i++)\n        membership[i] = -1;\n    new_centers_len = (int*) calloc(nclusters, sizeof(int));\n    new_centers    = (float**) malloc(nclusters *            sizeof(float*));\n    new_centers[0] = (float*)  calloc(nclusters * nfeatures, sizeof(float));\n    for (i=1; i<nclusters; i++)\n        new_centers[i] = new_centers[i-1] + nfeatures;\n    partial_new_centers_len    = (int**) malloc(nthreads * sizeof(int*));\n    partial_new_centers_len[0] = (int*)  calloc(nthreads*nclusters, sizeof(int));\n    for (i=1; i<nthreads; i++)\n        partial_new_centers_len[i] = partial_new_centers_len[i-1]+nclusters;\n    partial_new_centers    =(float***)malloc(nthreads * sizeof(float**));\n    partial_new_centers[0] =(float**) malloc(nthreads*nclusters * sizeof(float*));\n    for (i=1; i<nthreads; i++)\n        partial_new_centers[i] = partial_new_centers[i-1] + nclusters;\n    for (i=0; i<nthreads; i++)\n    {\n        for (j=0; j<nclusters; j++)\n            partial_new_centers[i][j] = (float*)calloc(nfeatures, sizeof(float));\n    }\n    printf(""num of threads = %d\n"", num_omp_threads);\n    do {\n        delta = 0.0;\n        omp_set_num_threads(num_omp_threads);\n        #pragma omp parallel shared(feature,clusters,membership,partial_new_centers,partial_new_centers_len)\n        {\n            int tid = omp_get_thread_num();\n            #pragma omp for private(i,j,index) firstprivate(npoints,nclusters,nfeatures) schedule(static) reduction(+:delta)\n            for (i=0; i<npoints; i++) {\n                index = find_nearest_point(feature[i],nfeatures,clusters,nclusters);\n                if (membership[i] != index) delta += 1.0;\n                membership[i] = index;\n                partial_new_centers_len[tid][index]++;\n                for (j=0; j<nfeatures; j++)\n                    partial_new_centers[tid][index][j] += feature[i][j];\n            }\n        }\n        for (i=0; i<nclusters; i++) {\n            for (j=0; j<nthreads; j++) {\n                new_centers_len[i] += partial_new_centers_len[j][i];\n                partial_new_centers_len[j][i]",Does the code use locking or critical sections to manage data race conditions in multithreaded computations?,No
Rodinia Kmeans Clustering - OpenMP,"#include <stdio.h>\n#include <stdlib.h>\n#include <float.h>\n#include <math.h>\n#include ""kmeans.h""\n#include <omp.h>\n#define RANDOM_MAX 2147483647\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\nextern double wtime(void);\nextern int num_omp_threads;\nint find_nearest_point(float  *pt, int     nfeatures, float **pts, int     npts) {\n    int index, i;\n    float min_dist=FLT_MAX;\n    for (i=0; i<npts; i++) {\n        float dist;\n        dist = euclid_dist_2(pt, pts[i], nfeatures);\n        if (dist < min_dist) {\n            min_dist = dist;\n            index    = i;\n        }\n    }\n    return(index);\n}\n__inline\nfloat euclid_dist_2(float *pt1,float *pt2,int    numdims) {\n    int i;\n    float ans=0.0;\n    for (i=0; i<numdims; i++)\n        ans += (pt1[i]-pt2[i]) * (pt1[i]-pt2[i]);\n    return(ans);\n}\nfloat** kmeans_clustering(float **feature, int     nfeatures, int     npoints, int     nclusters, float   threshold, int    *membership) {\n    int      i, j, k, n=0, index, loop=0;\n    int     *new_centers_len;\n    float  **new_centers;\n    float  **clusters;\n    float    delta;\n    double   timing;\n    int      nthreads;\n    int    **partial_new_centers_len;\n    float ***partial_new_centers;\n    nthreads = num_omp_threads; \n    clusters    = (float**) malloc(nclusters *             sizeof(float*));\n    clusters[0] = (float*)  malloc(nclusters * nfeatures * sizeof(float));\n    for (i=1; i<nclusters; i++)\n        clusters[i] = clusters[i-1] + nfeatures;\n    for (i=0; i<nclusters; i++) {\n        for (j=0; j<nfeatures; j++)\n            clusters[i][j] = feature[n][j];\n        n++;\n    }\n    for (i=0; i<npoints; i++)\n        membership[i] = -1;\n    new_centers_len = (int*) calloc(nclusters, sizeof(int));\n    new_centers    = (float**) malloc(nclusters *            sizeof(float*));\n    new_centers[0] = (float*)  calloc(nclusters * nfeatures, sizeof(float));\n    for (i=1; i<nclusters; i++)\n        new_centers[i] = new_centers[i-1] + nfeatures;\n    partial_new_centers_len    = (int**) malloc(nthreads * sizeof(int*));\n    partial_new_centers_len[0] = (int*)  calloc(nthreads*nclusters, sizeof(int));\n    for (i=1; i<nthreads; i++)\n        partial_new_centers_len[i] = partial_new_centers_len[i-1]+nclusters;\n    partial_new_centers    =(float***)malloc(nthreads * sizeof(float**));\n    partial_new_centers[0] =(float**) malloc(nthreads*nclusters * sizeof(float*));\n    for (i=1; i<nthreads; i++)\n        partial_new_centers[i] = partial_new_centers[i-1] + nclusters;\n    for (i=0; i<nthreads; i++)\n    {\n        for (j=0; j<nclusters; j++)\n            partial_new_centers[i][j] = (float*)calloc(nfeatures, sizeof(float));\n    }\n    printf(""num of threads = %d\n"", num_omp_threads);\n    do {\n        delta = 0.0;\n        omp_set_num_threads(num_omp_threads);\n        #pragma omp parallel shared(feature,clusters,membership,partial_new_centers,partial_new_centers_len)\n        {\n            int tid = omp_get_thread_num();\n            #pragma omp for private(i,j,index) firstprivate(npoints,nclusters,nfeatures) schedule(static) reduction(+:delta)\n            for (i=0; i<npoints; i++) {\n                index = find_nearest_point(feature[i],nfeatures,clusters,nclusters);\n                if (membership[i] != index) delta += 1.0;\n                membership[i] = index;\n                partial_new_centers_len[tid][index]++;\n                for (j=0; j<nfeatures; j++)\n                    partial_new_centers[tid][index][j] += feature[i][j];\n            }\n        }\n        for (i=0; i<nclusters; i++) {\n            for (j=0; j<nthreads; j++) {\n                new_centers_len[i] += partial_new_centers_len[j][i];\n                partial_new_centers_len[j][i]",Is the number of OpenMP threads dynamically determined at runtime based on available hardware resources?,No
Rodinia Kmeans Clustering - OpenMP,"#include <stdio.h>\n#include <stdlib.h>\n#include <float.h>\n#include <math.h>\n#include ""kmeans.h""\n#include <omp.h>\n#define RANDOM_MAX 2147483647\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\nextern double wtime(void);\nextern int num_omp_threads;\nint find_nearest_point(float  *pt, int     nfeatures, float **pts, int     npts) {\n    int index, i;\n    float min_dist=FLT_MAX;\n    for (i=0; i<npts; i++) {\n        float dist;\n        dist = euclid_dist_2(pt, pts[i], nfeatures);\n        if (dist < min_dist) {\n            min_dist = dist;\n            index    = i;\n        }\n    }\n    return(index);\n}\n__inline\nfloat euclid_dist_2(float *pt1,float *pt2,int    numdims) {\n    int i;\n    float ans=0.0;\n    for (i=0; i<numdims; i++)\n        ans += (pt1[i]-pt2[i]) * (pt1[i]-pt2[i]);\n    return(ans);\n}\nfloat** kmeans_clustering(float **feature, int     nfeatures, int     npoints, int     nclusters, float   threshold, int    *membership) {\n    int      i, j, k, n=0, index, loop=0;\n    int     *new_centers_len;\n    float  **new_centers;\n    float  **clusters;\n    float    delta;\n    double   timing;\n    int      nthreads;\n    int    **partial_new_centers_len;\n    float ***partial_new_centers;\n    nthreads = num_omp_threads; \n    clusters    = (float**) malloc(nclusters *             sizeof(float*));\n    clusters[0] = (float*)  malloc(nclusters * nfeatures * sizeof(float));\n    for (i=1; i<nclusters; i++)\n        clusters[i] = clusters[i-1] + nfeatures;\n    for (i=0; i<nclusters; i++) {\n        for (j=0; j<nfeatures; j++)\n            clusters[i][j] = feature[n][j];\n        n++;\n    }\n    for (i=0; i<npoints; i++)\n        membership[i] = -1;\n    new_centers_len = (int*) calloc(nclusters, sizeof(int));\n    new_centers    = (float**) malloc(nclusters *            sizeof(float*));\n    new_centers[0] = (float*)  calloc(nclusters * nfeatures, sizeof(float));\n    for (i=1; i<nclusters; i++)\n        new_centers[i] = new_centers[i-1] + nfeatures;\n    partial_new_centers_len    = (int**) malloc(nthreads * sizeof(int*));\n    partial_new_centers_len[0] = (int*)  calloc(nthreads*nclusters, sizeof(int));\n    for (i=1; i<nthreads; i++)\n        partial_new_centers_len[i] = partial_new_centers_len[i-1]+nclusters;\n    partial_new_centers    =(float***)malloc(nthreads * sizeof(float**));\n    partial_new_centers[0] =(float**) malloc(nthreads*nclusters * sizeof(float*));\n    for (i=1; i<nthreads; i++)\n        partial_new_centers[i] = partial_new_centers[i-1] + nclusters;\n    for (i=0; i<nthreads; i++)\n    {\n        for (j=0; j<nclusters; j++)\n            partial_new_centers[i][j] = (float*)calloc(nfeatures, sizeof(float));\n    }\n    printf(""num of threads = %d\n"", num_omp_threads);\n    do {\n        delta = 0.0;\n        omp_set_num_threads(num_omp_threads);\n        #pragma omp parallel shared(feature,clusters,membership,partial_new_centers,partial_new_centers_len)\n        {\n            int tid = omp_get_thread_num();\n            #pragma omp for private(i,j,index) firstprivate(npoints,nclusters,nfeatures) schedule(static) reduction(+:delta)\n            for (i=0; i<npoints; i++) {\n                index = find_nearest_point(feature[i],nfeatures,clusters,nclusters);\n                if (membership[i] != index) delta += 1.0;\n                membership[i] = index;\n                partial_new_centers_len[tid][index]++;\n                for (j=0; j<nfeatures; j++)\n                    partial_new_centers[tid][index][j] += feature[i][j];\n            }\n        }\n        for (i=0; i<nclusters; i++) {\n            for (j=0; j<nthreads; j++) {\n                new_centers_len[i] += partial_new_centers_len[j][i];\n                partial_new_centers_len[j][i]",Is the OpenMP 'omp_get_thread_num' function used to obtain the ID of the thread executing the function?,Yes
Rodinia Kmeans Clustering - OpenMP,"#include <stdio.h>\n#include <stdlib.h>\n#include <float.h>\n#include <math.h>\n#include ""kmeans.h""\n#include <omp.h>\n#define RANDOM_MAX 2147483647\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\nextern double wtime(void);\nextern int num_omp_threads;\nint find_nearest_point(float  *pt, int     nfeatures, float **pts, int     npts) {\n    int index, i;\n    float min_dist=FLT_MAX;\n    for (i=0; i<npts; i++) {\n        float dist;\n        dist = euclid_dist_2(pt, pts[i], nfeatures);\n        if (dist < min_dist) {\n            min_dist = dist;\n            index    = i;\n        }\n    }\n    return(index);\n}\n__inline\nfloat euclid_dist_2(float *pt1,float *pt2,int    numdims) {\n    int i;\n    float ans=0.0;\n    for (i=0; i<numdims; i++)\n        ans += (pt1[i]-pt2[i]) * (pt1[i]-pt2[i]);\n    return(ans);\n}\nfloat** kmeans_clustering(float **feature, int     nfeatures, int     npoints, int     nclusters, float   threshold, int    *membership) {\n    int      i, j, k, n=0, index, loop=0;\n    int     *new_centers_len;\n    float  **new_centers;\n    float  **clusters;\n    float    delta;\n    double   timing;\n    int      nthreads;\n    int    **partial_new_centers_len;\n    float ***partial_new_centers;\n    nthreads = num_omp_threads; \n    clusters    = (float**) malloc(nclusters *             sizeof(float*));\n    clusters[0] = (float*)  malloc(nclusters * nfeatures * sizeof(float));\n    for (i=1; i<nclusters; i++)\n        clusters[i] = clusters[i-1] + nfeatures;\n    for (i=0; i<nclusters; i++) {\n        for (j=0; j<nfeatures; j++)\n            clusters[i][j] = feature[n][j];\n        n++;\n    }\n    for (i=0; i<npoints; i++)\n        membership[i] = -1;\n    new_centers_len = (int*) calloc(nclusters, sizeof(int));\n    new_centers    = (float**) malloc(nclusters *            sizeof(float*));\n    new_centers[0] = (float*)  calloc(nclusters * nfeatures, sizeof(float));\n    for (i=1; i<nclusters; i++)\n        new_centers[i] = new_centers[i-1] + nfeatures;\n    partial_new_centers_len    = (int**) malloc(nthreads * sizeof(int*));\n    partial_new_centers_len[0] = (int*)  calloc(nthreads*nclusters, sizeof(int));\n    for (i=1; i<nthreads; i++)\n        partial_new_centers_len[i] = partial_new_centers_len[i-1]+nclusters;\n    partial_new_centers    =(float***)malloc(nthreads * sizeof(float**));\n    partial_new_centers[0] =(float**) malloc(nthreads*nclusters * sizeof(float*));\n    for (i=1; i<nthreads; i++)\n        partial_new_centers[i] = partial_new_centers[i-1] + nclusters;\n    for (i=0; i<nthreads; i++)\n    {\n        for (j=0; j<nclusters; j++)\n            partial_new_centers[i][j] = (float*)calloc(nfeatures, sizeof(float));\n    }\n    printf(""num of threads = %d\n"", num_omp_threads);\n    do {\n        delta = 0.0;\n        omp_set_num_threads(num_omp_threads);\n        #pragma omp parallel shared(feature,clusters,membership,partial_new_centers,partial_new_centers_len)\n        {\n            int tid = omp_get_thread_num();\n            #pragma omp for private(i,j,index) firstprivate(npoints,nclusters,nfeatures) schedule(static) reduction(+:delta)\n            for (i=0; i<npoints; i++) {\n                index = find_nearest_point(feature[i],nfeatures,clusters,nclusters);\n                if (membership[i] != index) delta += 1.0;\n                membership[i] = index;\n                partial_new_centers_len[tid][index]++;\n                for (j=0; j<nfeatures; j++)\n                    partial_new_centers[tid][index][j] += feature[i][j];\n            }\n        }\n        for (i=0; i<nclusters; i++) {\n            for (j=0; j<nthreads; j++) {\n                new_centers_len[i] += partial_new_centers_len[j][i];\n                partial_new_centers_len[j][i]",Is there any usage of OpenMP's 'task' construct for fine-grained parallelism in this code?,No
Rodinia Kmeans Clustering - OpenMP,"#include <stdio.h>\n#include <stdlib.h>\n#include <float.h>\n#include <math.h>\n#include ""kmeans.h""\n#include <omp.h>\n#define RANDOM_MAX 2147483647\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\nextern double wtime(void);\nextern int num_omp_threads;\nint find_nearest_point(float  *pt, int     nfeatures, float **pts, int     npts) {\n    int index, i;\n    float min_dist=FLT_MAX;\n    for (i=0; i<npts; i++) {\n        float dist;\n        dist = euclid_dist_2(pt, pts[i], nfeatures);\n        if (dist < min_dist) {\n            min_dist = dist;\n            index    = i;\n        }\n    }\n    return(index);\n}\n__inline\nfloat euclid_dist_2(float *pt1,float *pt2,int    numdims) {\n    int i;\n    float ans=0.0;\n    for (i=0; i<numdims; i++)\n        ans += (pt1[i]-pt2[i]) * (pt1[i]-pt2[i]);\n    return(ans);\n}\nfloat** kmeans_clustering(float **feature, int     nfeatures, int     npoints, int     nclusters, float   threshold, int    *membership) {\n    int      i, j, k, n=0, index, loop=0;\n    int     *new_centers_len;\n    float  **new_centers;\n    float  **clusters;\n    float    delta;\n    double   timing;\n    int      nthreads;\n    int    **partial_new_centers_len;\n    float ***partial_new_centers;\n    nthreads = num_omp_threads; \n    clusters    = (float**) malloc(nclusters *             sizeof(float*));\n    clusters[0] = (float*)  malloc(nclusters * nfeatures * sizeof(float));\n    for (i=1; i<nclusters; i++)\n        clusters[i] = clusters[i-1] + nfeatures;\n    for (i=0; i<nclusters; i++) {\n        for (j=0; j<nfeatures; j++)\n            clusters[i][j] = feature[n][j];\n        n++;\n    }\n    for (i=0; i<npoints; i++)\n        membership[i] = -1;\n    new_centers_len = (int*) calloc(nclusters, sizeof(int));\n    new_centers    = (float**) malloc(nclusters *            sizeof(float*));\n    new_centers[0] = (float*)  calloc(nclusters * nfeatures, sizeof(float));\n    for (i=1; i<nclusters; i++)\n        new_centers[i] = new_centers[i-1] + nfeatures;\n    partial_new_centers_len    = (int**) malloc(nthreads * sizeof(int*));\n    partial_new_centers_len[0] = (int*)  calloc(nthreads*nclusters, sizeof(int));\n    for (i=1; i<nthreads; i++)\n        partial_new_centers_len[i] = partial_new_centers_len[i-1]+nclusters;\n    partial_new_centers    =(float***)malloc(nthreads * sizeof(float**));\n    partial_new_centers[0] =(float**) malloc(nthreads*nclusters * sizeof(float*));\n    for (i=1; i<nthreads; i++)\n        partial_new_centers[i] = partial_new_centers[i-1] + nclusters;\n    for (i=0; i<nthreads; i++)\n    {\n        for (j=0; j<nclusters; j++)\n            partial_new_centers[i][j] = (float*)calloc(nfeatures, sizeof(float));\n    }\n    printf(""num of threads = %d\n"", num_omp_threads);\n    do {\n        delta = 0.0;\n        omp_set_num_threads(num_omp_threads);\n        #pragma omp parallel shared(feature,clusters,membership,partial_new_centers,partial_new_centers_len)\n        {\n            int tid = omp_get_thread_num();\n            #pragma omp for private(i,j,index) firstprivate(npoints,nclusters,nfeatures) schedule(static) reduction(+:delta)\n            for (i=0; i<npoints; i++) {\n                index = find_nearest_point(feature[i],nfeatures,clusters,nclusters);\n                if (membership[i] != index) delta += 1.0;\n                membership[i] = index;\n                partial_new_centers_len[tid][index]++;\n                for (j=0; j<nfeatures; j++)\n                    partial_new_centers[tid][index][j] += feature[i][j];\n            }\n        }\n        for (i=0; i<nclusters; i++) {\n            for (j=0; j<nthreads; j++) {\n                new_centers_len[i] += partial_new_centers_len[j][i];\n                partial_new_centers_len[j][i]",Is the code using OpenMP's 'collapse' clause to parallelize nested for-loops?,No
Rodinia Kmeans Clustering - OpenMP,"#include <stdio.h>\n#include <stdlib.h>\n#include <float.h>\n#include <math.h>\n#include ""kmeans.h""\n#include <omp.h>\n#define RANDOM_MAX 2147483647\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\nextern double wtime(void);\nextern int num_omp_threads;\nint find_nearest_point(float  *pt, int     nfeatures, float **pts, int     npts) {\n    int index, i;\n    float min_dist=FLT_MAX;\n    for (i=0; i<npts; i++) {\n        float dist;\n        dist = euclid_dist_2(pt, pts[i], nfeatures);\n        if (dist < min_dist) {\n            min_dist = dist;\n            index    = i;\n        }\n    }\n    return(index);\n}\n__inline\nfloat euclid_dist_2(float *pt1,float *pt2,int    numdims) {\n    int i;\n    float ans=0.0;\n    for (i=0; i<numdims; i++)\n        ans += (pt1[i]-pt2[i]) * (pt1[i]-pt2[i]);\n    return(ans);\n}\nfloat** kmeans_clustering(float **feature, int     nfeatures, int     npoints, int     nclusters, float   threshold, int    *membership) {\n    int      i, j, k, n=0, index, loop=0;\n    int     *new_centers_len;\n    float  **new_centers;\n    float  **clusters;\n    float    delta;\n    double   timing;\n    int      nthreads;\n    int    **partial_new_centers_len;\n    float ***partial_new_centers;\n    nthreads = num_omp_threads; \n    clusters    = (float**) malloc(nclusters *             sizeof(float*));\n    clusters[0] = (float*)  malloc(nclusters * nfeatures * sizeof(float));\n    for (i=1; i<nclusters; i++)\n        clusters[i] = clusters[i-1] + nfeatures;\n    for (i=0; i<nclusters; i++) {\n        for (j=0; j<nfeatures; j++)\n            clusters[i][j] = feature[n][j];\n        n++;\n    }\n    for (i=0; i<npoints; i++)\n        membership[i] = -1;\n    new_centers_len = (int*) calloc(nclusters, sizeof(int));\n    new_centers    = (float**) malloc(nclusters *            sizeof(float*));\n    new_centers[0] = (float*)  calloc(nclusters * nfeatures, sizeof(float));\n    for (i=1; i<nclusters; i++)\n        new_centers[i] = new_centers[i-1] + nfeatures;\n    partial_new_centers_len    = (int**) malloc(nthreads * sizeof(int*));\n    partial_new_centers_len[0] = (int*)  calloc(nthreads*nclusters, sizeof(int));\n    for (i=1; i<nthreads; i++)\n        partial_new_centers_len[i] = partial_new_centers_len[i-1]+nclusters;\n    partial_new_centers    =(float***)malloc(nthreads * sizeof(float**));\n    partial_new_centers[0] =(float**) malloc(nthreads*nclusters * sizeof(float*));\n    for (i=1; i<nthreads; i++)\n        partial_new_centers[i] = partial_new_centers[i-1] + nclusters;\n    for (i=0; i<nthreads; i++)\n    {\n        for (j=0; j<nclusters; j++)\n            partial_new_centers[i][j] = (float*)calloc(nfeatures, sizeof(float));\n    }\n    printf(""num of threads = %d\n"", num_omp_threads);\n    do {\n        delta = 0.0;\n        omp_set_num_threads(num_omp_threads);\n        #pragma omp parallel shared(feature,clusters,membership,partial_new_centers,partial_new_centers_len)\n        {\n            int tid = omp_get_thread_num();\n            #pragma omp for private(i,j,index) firstprivate(npoints,nclusters,nfeatures) schedule(static) reduction(+:delta)\n            for (i=0; i<npoints; i++) {\n                index = find_nearest_point(feature[i],nfeatures,clusters,nclusters);\n                if (membership[i] != index) delta += 1.0;\n                membership[i] = index;\n                partial_new_centers_len[tid][index]++;\n                for (j=0; j<nfeatures; j++)\n                    partial_new_centers[tid][index][j] += feature[i][j];\n            }\n        }\n        for (i=0; i<nclusters; i++) {\n            for (j=0; j<nthreads; j++) {\n                new_centers_len[i] += partial_new_centers_len[j][i];\n                partial_new_centers_len[j][i]",Does the code use 'barrier' directive to synchronize all threads at a certain point in the execution?,No
Rodinia Pathfinder,"#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <assert.h>\n\n#include \timer.h\""\n\nvoid run(int argc, char** argv);\n\n/* define timer macros */\n#define pin_stats_reset()   startCycle()\n#define pin_stats_pause(cycles)   stopCycle(cycles)\n#define pin_stats_dump(cycles)    printf(\""timer: %Lu\\n\"", cycles)\n\n#define BENCH_PRINT\n\nint rows, cols;\nint* data;\nint** wall;\nint* result;\n#define M_SEED 9\n\nvoid\ninit(int argc, char** argv)\n{\n\tif(argc==3){\n\t\tcols = atoi(argv[1]);\n\t\trows = atoi(argv[2]);\n\t}else{\n                printf(\""Usage: pathfiner width num_of_steps\\n\"");\n                exit(0);\n        }\n\tdata = new int[rows*cols];\n\twall = new int*[rows];\n\tfor(int n=0; n<rows; n++)\n\t\twall[n]=data+cols*n;\n\tresult = new int[cols];\n\t\n\tint seed = M_SEED;\n\tsrand(seed);\n\n\tfor (int i = 0; i < rows; i++)\n    {\n        for (int j = 0; j < cols; j++)\n        {\n            wall[i][j] = rand() % 10;\n        }\n    }\n    for (int j = 0; j < cols; j++)\n        result[j] = wall[0][j];\n#ifdef BENCH_PRINT\n    for (int i = 0; i < rows; i++)\n    {\n        for (int j = 0; j < cols; j++)\n        {\n            printf(\""%d \"",wall[i][j]) ;\n        }\n        printf(\""\\n\"") ;\n    }\n#endif\n}\n\nvoid \nfatal(char *s)\n{\n\tfprintf(stderr, \""error: %s\\n\"", s);\n\n}\n\n#define IN_RANGE(x, min, max)   ((x)>=(min) && (x)<=(max))\n#define CLAMP_RANGE(x, min, max) x = (x<(min)) ? min : ((x>(max)) ? max : x )\n#define MIN(a, b) ((a)<=(b) ? (a) : (b))\n\nint main(int argc, char** argv)\n{\n    run(argc,argv);\n\n    return EXIT_SUCCESS;\n}\n\nvoid run(int argc, char** argv)\n{\n    init(argc, argv);\n\n    unsigned long long cycles;\n\n    int *src, *dst, *temp;\n    int min;\n\n    dst = result;\n    src = new int[cols];\n\n    pin_stats_reset();\n    for (int t = 0; t < rows-1; t++) {\n        temp = src;\n        src = dst;\n        dst = temp;\n        #pragma omp parallel for private(min)\n        for(int n = 0; n < cols; n++){\n          min = src[n];\n          if (n > 0)\n            min = MIN(min, src[n-1]);\n          if (n < cols-1)\n            min = MIN(min, src[n+1]);\n          dst[n] = wall[t+1][n]+min;\n        }\n    }\n\n    pin_stats_pause(cycles);\n    pin_stats_dump(cycles);\n\n#ifdef BENCH_PRINT\n\n    for (int i = 0; i < cols; i++)\n\n            printf(\""%d \"",data[i]) ;\n\n    printf(\""\\n\"") ;\n\n    for (int i = 0; i < cols; i++)\n\n            printf(\""%d \"",dst[i]) ;\n\n    printf(\""\\n\"") ;\n\n#endif\n\n    delete [] data;\n    delete [] wall;\n    delete [] dst;\n    delete [] src;\n}\n""",Is the code using OpenMP to execute certain parts of it in parallel?,Yes
Rodinia Pathfinder,"#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <assert.h>\n\n#include \timer.h\""\n\nvoid run(int argc, char** argv);\n\n/* define timer macros */\n#define pin_stats_reset()   startCycle()\n#define pin_stats_pause(cycles)   stopCycle(cycles)\n#define pin_stats_dump(cycles)    printf(\""timer: %Lu\\n\"", cycles)\n\n#define BENCH_PRINT\n\nint rows, cols;\nint* data;\nint** wall;\nint* result;\n#define M_SEED 9\n\nvoid\ninit(int argc, char** argv)\n{\n\tif(argc==3){\n\t\tcols = atoi(argv[1]);\n\t\trows = atoi(argv[2]);\n\t}else{\n                printf(\""Usage: pathfiner width num_of_steps\\n\"");\n                exit(0);\n        }\n\tdata = new int[rows*cols];\n\twall = new int*[rows];\n\tfor(int n=0; n<rows; n++)\n\t\twall[n]=data+cols*n;\n\tresult = new int[cols];\n\t\n\tint seed = M_SEED;\n\tsrand(seed);\n\n\tfor (int i = 0; i < rows; i++)\n    {\n        for (int j = 0; j < cols; j++)\n        {\n            wall[i][j] = rand() % 10;\n        }\n    }\n    for (int j = 0; j < cols; j++)\n        result[j] = wall[0][j];\n#ifdef BENCH_PRINT\n    for (int i = 0; i < rows; i++)\n    {\n        for (int j = 0; j < cols; j++)\n        {\n            printf(\""%d \"",wall[i][j]) ;\n        }\n        printf(\""\\n\"") ;\n    }\n#endif\n}\n\nvoid \nfatal(char *s)\n{\n\tfprintf(stderr, \""error: %s\\n\"", s);\n\n}\n\n#define IN_RANGE(x, min, max)   ((x)>=(min) && (x)<=(max))\n#define CLAMP_RANGE(x, min, max) x = (x<(min)) ? min : ((x>(max)) ? max : x )\n#define MIN(a, b) ((a)<=(b) ? (a) : (b))\n\nint main(int argc, char** argv)\n{\n    run(argc,argv);\n\n    return EXIT_SUCCESS;\n}\n\nvoid run(int argc, char** argv)\n{\n    init(argc, argv);\n\n    unsigned long long cycles;\n\n    int *src, *dst, *temp;\n    int min;\n\n    dst = result;\n    src = new int[cols];\n\n    pin_stats_reset();\n    for (int t = 0; t < rows-1; t++) {\n        temp = src;\n        src = dst;\n        dst = temp;\n        #pragma omp parallel for private(min)\n        for(int n = 0; n < cols; n++){\n          min = src[n];\n          if (n > 0)\n            min = MIN(min, src[n-1]);\n          if (n < cols-1)\n            min = MIN(min, src[n+1]);\n          dst[n] = wall[t+1][n]+min;\n        }\n    }\n\n    pin_stats_pause(cycles);\n    pin_stats_dump(cycles);\n\n#ifdef BENCH_PRINT\n\n    for (int i = 0; i < cols; i++)\n\n            printf(\""%d \"",data[i]) ;\n\n    printf(\""\\n\"") ;\n\n    for (int i = 0; i < cols; i++)\n\n            printf(\""%d \"",dst[i]) ;\n\n    printf(\""\\n\"") ;\n\n#endif\n\n    delete [] data;\n    delete [] wall;\n    delete [] dst;\n    delete [] src;\n}\n""",Does the code use the 'omp parallel for' directive to parallelize the inner loop?,Yes
Rodinia Pathfinder,"#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <assert.h>\n\n#include \timer.h\""\n\nvoid run(int argc, char** argv);\n\n/* define timer macros */\n#define pin_stats_reset()   startCycle()\n#define pin_stats_pause(cycles)   stopCycle(cycles)\n#define pin_stats_dump(cycles)    printf(\""timer: %Lu\\n\"", cycles)\n\n#define BENCH_PRINT\n\nint rows, cols;\nint* data;\nint** wall;\nint* result;\n#define M_SEED 9\n\nvoid\ninit(int argc, char** argv)\n{\n\tif(argc==3){\n\t\tcols = atoi(argv[1]);\n\t\trows = atoi(argv[2]);\n\t}else{\n                printf(\""Usage: pathfiner width num_of_steps\\n\"");\n                exit(0);\n        }\n\tdata = new int[rows*cols];\n\twall = new int*[rows];\n\tfor(int n=0; n<rows; n++)\n\t\twall[n]=data+cols*n;\n\tresult = new int[cols];\n\t\n\tint seed = M_SEED;\n\tsrand(seed);\n\n\tfor (int i = 0; i < rows; i++)\n    {\n        for (int j = 0; j < cols; j++)\n        {\n            wall[i][j] = rand() % 10;\n        }\n    }\n    for (int j = 0; j < cols; j++)\n        result[j] = wall[0][j];\n#ifdef BENCH_PRINT\n    for (int i = 0; i < rows; i++)\n    {\n        for (int j = 0; j < cols; j++)\n        {\n            printf(\""%d \"",wall[i][j]) ;\n        }\n        printf(\""\\n\"") ;\n    }\n#endif\n}\n\nvoid \nfatal(char *s)\n{\n\tfprintf(stderr, \""error: %s\\n\"", s);\n\n}\n\n#define IN_RANGE(x, min, max)   ((x)>=(min) && (x)<=(max))\n#define CLAMP_RANGE(x, min, max) x = (x<(min)) ? min : ((x>(max)) ? max : x )\n#define MIN(a, b) ((a)<=(b) ? (a) : (b))\n\nint main(int argc, char** argv)\n{\n    run(argc,argv);\n\n    return EXIT_SUCCESS;\n}\n\nvoid run(int argc, char** argv)\n{\n    init(argc, argv);\n\n    unsigned long long cycles;\n\n    int *src, *dst, *temp;\n    int min;\n\n    dst = result;\n    src = new int[cols];\n\n    pin_stats_reset();\n    for (int t = 0; t < rows-1; t++) {\n        temp = src;\n        src = dst;\n        dst = temp;\n        #pragma omp parallel for private(min)\n        for(int n = 0; n < cols; n++){\n          min = src[n];\n          if (n > 0)\n            min = MIN(min, src[n-1]);\n          if (n < cols-1)\n            min = MIN(min, src[n+1]);\n          dst[n] = wall[t+1][n]+min;\n        }\n    }\n\n    pin_stats_pause(cycles);\n    pin_stats_dump(cycles);\n\n#ifdef BENCH_PRINT\n\n    for (int i = 0; i < cols; i++)\n\n            printf(\""%d \"",data[i]) ;\n\n    printf(\""\\n\"") ;\n\n    for (int i = 0; i < cols; i++)\n\n            printf(\""%d \"",dst[i]) ;\n\n    printf(\""\\n\"") ;\n\n#endif\n\n    delete [] data;\n    delete [] wall;\n    delete [] dst;\n    delete [] src;\n}\n""","Does the code use 'pin_stats_reset()', 'pin_stats_pause(cycles)', and 'pin_stats_dump(cycles)' functions to measure execution time of the parallel region?",Yes
Rodinia Pathfinder,"#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <assert.h>\n\n#include \timer.h\""\n\nvoid run(int argc, char** argv);\n\n/* define timer macros */\n#define pin_stats_reset()   startCycle()\n#define pin_stats_pause(cycles)   stopCycle(cycles)\n#define pin_stats_dump(cycles)    printf(\""timer: %Lu\\n\"", cycles)\n\n#define BENCH_PRINT\n\nint rows, cols;\nint* data;\nint** wall;\nint* result;\n#define M_SEED 9\n\nvoid\ninit(int argc, char** argv)\n{\n\tif(argc==3){\n\t\tcols = atoi(argv[1]);\n\t\trows = atoi(argv[2]);\n\t}else{\n                printf(\""Usage: pathfiner width num_of_steps\\n\"");\n                exit(0);\n        }\n\tdata = new int[rows*cols];\n\twall = new int*[rows];\n\tfor(int n=0; n<rows; n++)\n\t\twall[n]=data+cols*n;\n\tresult = new int[cols];\n\t\n\tint seed = M_SEED;\n\tsrand(seed);\n\n\tfor (int i = 0; i < rows; i++)\n    {\n        for (int j = 0; j < cols; j++)\n        {\n            wall[i][j] = rand() % 10;\n        }\n    }\n    for (int j = 0; j < cols; j++)\n        result[j] = wall[0][j];\n#ifdef BENCH_PRINT\n    for (int i = 0; i < rows; i++)\n    {\n        for (int j = 0; j < cols; j++)\n        {\n            printf(\""%d \"",wall[i][j]) ;\n        }\n        printf(\""\\n\"") ;\n    }\n#endif\n}\n\nvoid \nfatal(char *s)\n{\n\tfprintf(stderr, \""error: %s\\n\"", s);\n\n}\n\n#define IN_RANGE(x, min, max)   ((x)>=(min) && (x)<=(max))\n#define CLAMP_RANGE(x, min, max) x = (x<(min)) ? min : ((x>(max)) ? max : x )\n#define MIN(a, b) ((a)<=(b) ? (a) : (b))\n\nint main(int argc, char** argv)\n{\n    run(argc,argv);\n\n    return EXIT_SUCCESS;\n}\n\nvoid run(int argc, char** argv)\n{\n    init(argc, argv);\n\n    unsigned long long cycles;\n\n    int *src, *dst, *temp;\n    int min;\n\n    dst = result;\n    src = new int[cols];\n\n    pin_stats_reset();\n    for (int t = 0; t < rows-1; t++) {\n        temp = src;\n        src = dst;\n        dst = temp;\n        #pragma omp parallel for private(min)\n        for(int n = 0; n < cols; n++){\n          min = src[n];\n          if (n > 0)\n            min = MIN(min, src[n-1]);\n          if (n < cols-1)\n            min = MIN(min, src[n+1]);\n          dst[n] = wall[t+1][n]+min;\n        }\n    }\n\n    pin_stats_pause(cycles);\n    pin_stats_dump(cycles);\n\n#ifdef BENCH_PRINT\n\n    for (int i = 0; i < cols; i++)\n\n            printf(\""%d \"",data[i]) ;\n\n    printf(\""\\n\"") ;\n\n    for (int i = 0; i < cols; i++)\n\n            printf(\""%d \"",dst[i]) ;\n\n    printf(\""\\n\"") ;\n\n#endif\n\n    delete [] data;\n    delete [] wall;\n    delete [] dst;\n    delete [] src;\n}\n""",Is the 'MIN' macro used within the parallelized loop potentially causing a race-condition?,No
Rodinia Pathfinder,"#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <assert.h>\n\n#include \timer.h\""\n\nvoid run(int argc, char** argv);\n\n/* define timer macros */\n#define pin_stats_reset()   startCycle()\n#define pin_stats_pause(cycles)   stopCycle(cycles)\n#define pin_stats_dump(cycles)    printf(\""timer: %Lu\\n\"", cycles)\n\n#define BENCH_PRINT\n\nint rows, cols;\nint* data;\nint** wall;\nint* result;\n#define M_SEED 9\n\nvoid\ninit(int argc, char** argv)\n{\n\tif(argc==3){\n\t\tcols = atoi(argv[1]);\n\t\trows = atoi(argv[2]);\n\t}else{\n                printf(\""Usage: pathfiner width num_of_steps\\n\"");\n                exit(0);\n        }\n\tdata = new int[rows*cols];\n\twall = new int*[rows];\n\tfor(int n=0; n<rows; n++)\n\t\twall[n]=data+cols*n;\n\tresult = new int[cols];\n\t\n\tint seed = M_SEED;\n\tsrand(seed);\n\n\tfor (int i = 0; i < rows; i++)\n    {\n        for (int j = 0; j < cols; j++)\n        {\n            wall[i][j] = rand() % 10;\n        }\n    }\n    for (int j = 0; j < cols; j++)\n        result[j] = wall[0][j];\n#ifdef BENCH_PRINT\n    for (int i = 0; i < rows; i++)\n    {\n        for (int j = 0; j < cols; j++)\n        {\n            printf(\""%d \"",wall[i][j]) ;\n        }\n        printf(\""\\n\"") ;\n    }\n#endif\n}\n\nvoid \nfatal(char *s)\n{\n\tfprintf(stderr, \""error: %s\\n\"", s);\n\n}\n\n#define IN_RANGE(x, min, max)   ((x)>=(min) && (x)<=(max))\n#define CLAMP_RANGE(x, min, max) x = (x<(min)) ? min : ((x>(max)) ? max : x )\n#define MIN(a, b) ((a)<=(b) ? (a) : (b))\n\nint main(int argc, char** argv)\n{\n    run(argc,argv);\n\n    return EXIT_SUCCESS;\n}\n\nvoid run(int argc, char** argv)\n{\n    init(argc, argv);\n\n    unsigned long long cycles;\n\n    int *src, *dst, *temp;\n    int min;\n\n    dst = result;\n    src = new int[cols];\n\n    pin_stats_reset();\n    for (int t = 0; t < rows-1; t++) {\n        temp = src;\n        src = dst;\n        dst = temp;\n        #pragma omp parallel for private(min)\n        for(int n = 0; n < cols; n++){\n          min = src[n];\n          if (n > 0)\n            min = MIN(min, src[n-1]);\n          if (n < cols-1)\n            min = MIN(min, src[n+1]);\n          dst[n] = wall[t+1][n]+min;\n        }\n    }\n\n    pin_stats_pause(cycles);\n    pin_stats_dump(cycles);\n\n#ifdef BENCH_PRINT\n\n    for (int i = 0; i < cols; i++)\n\n            printf(\""%d \"",data[i]) ;\n\n    printf(\""\\n\"") ;\n\n    for (int i = 0; i < cols; i++)\n\n            printf(\""%d \"",dst[i]) ;\n\n    printf(\""\\n\"") ;\n\n#endif\n\n    delete [] data;\n    delete [] wall;\n    delete [] dst;\n    delete [] src;\n}\n""",Is there any explicit handling of data dependencies across threads in the code?,No
Rodinia Pathfinder,"#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <assert.h>\n\n#include \timer.h\""\n\nvoid run(int argc, char** argv);\n\n/* define timer macros */\n#define pin_stats_reset()   startCycle()\n#define pin_stats_pause(cycles)   stopCycle(cycles)\n#define pin_stats_dump(cycles)    printf(\""timer: %Lu\\n\"", cycles)\n\n#define BENCH_PRINT\n\nint rows, cols;\nint* data;\nint** wall;\nint* result;\n#define M_SEED 9\n\nvoid\ninit(int argc, char** argv)\n{\n\tif(argc==3){\n\t\tcols = atoi(argv[1]);\n\t\trows = atoi(argv[2]);\n\t}else{\n                printf(\""Usage: pathfiner width num_of_steps\\n\"");\n                exit(0);\n        }\n\tdata = new int[rows*cols];\n\twall = new int*[rows];\n\tfor(int n=0; n<rows; n++)\n\t\twall[n]=data+cols*n;\n\tresult = new int[cols];\n\t\n\tint seed = M_SEED;\n\tsrand(seed);\n\n\tfor (int i = 0; i < rows; i++)\n    {\n        for (int j = 0; j < cols; j++)\n        {\n            wall[i][j] = rand() % 10;\n        }\n    }\n    for (int j = 0; j < cols; j++)\n        result[j] = wall[0][j];\n#ifdef BENCH_PRINT\n    for (int i = 0; i < rows; i++)\n    {\n        for (int j = 0; j < cols; j++)\n        {\n            printf(\""%d \"",wall[i][j]) ;\n        }\n        printf(\""\\n\"") ;\n    }\n#endif\n}\n\nvoid \nfatal(char *s)\n{\n\tfprintf(stderr, \""error: %s\\n\"", s);\n\n}\n\n#define IN_RANGE(x, min, max)   ((x)>=(min) && (x)<=(max))\n#define CLAMP_RANGE(x, min, max) x = (x<(min)) ? min : ((x>(max)) ? max : x )\n#define MIN(a, b) ((a)<=(b) ? (a) : (b))\n\nint main(int argc, char** argv)\n{\n    run(argc,argv);\n\n    return EXIT_SUCCESS;\n}\n\nvoid run(int argc, char** argv)\n{\n    init(argc, argv);\n\n    unsigned long long cycles;\n\n    int *src, *dst, *temp;\n    int min;\n\n    dst = result;\n    src = new int[cols];\n\n    pin_stats_reset();\n    for (int t = 0; t < rows-1; t++) {\n        temp = src;\n        src = dst;\n        dst = temp;\n        #pragma omp parallel for private(min)\n        for(int n = 0; n < cols; n++){\n          min = src[n];\n          if (n > 0)\n            min = MIN(min, src[n-1]);\n          if (n < cols-1)\n            min = MIN(min, src[n+1]);\n          dst[n] = wall[t+1][n]+min;\n        }\n    }\n\n    pin_stats_pause(cycles);\n    pin_stats_dump(cycles);\n\n#ifdef BENCH_PRINT\n\n    for (int i = 0; i < cols; i++)\n\n            printf(\""%d \"",data[i]) ;\n\n    printf(\""\\n\"") ;\n\n    for (int i = 0; i < cols; i++)\n\n            printf(\""%d \"",dst[i]) ;\n\n    printf(\""\\n\"") ;\n\n#endif\n\n    delete [] data;\n    delete [] wall;\n    delete [] dst;\n    delete [] src;\n}\n""",Does the code rely on OpenMP's implicit barrier at the end of the parallel region to enforce synchronization among threads?,Yes
Rodinia Pathfinder,"#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <assert.h>\n\n#include \timer.h\""\n\nvoid run(int argc, char** argv);\n\n/* define timer macros */\n#define pin_stats_reset()   startCycle()\n#define pin_stats_pause(cycles)   stopCycle(cycles)\n#define pin_stats_dump(cycles)    printf(\""timer: %Lu\\n\"", cycles)\n\n#define BENCH_PRINT\n\nint rows, cols;\nint* data;\nint** wall;\nint* result;\n#define M_SEED 9\n\nvoid\ninit(int argc, char** argv)\n{\n\tif(argc==3){\n\t\tcols = atoi(argv[1]);\n\t\trows = atoi(argv[2]);\n\t}else{\n                printf(\""Usage: pathfiner width num_of_steps\\n\"");\n                exit(0);\n        }\n\tdata = new int[rows*cols];\n\twall = new int*[rows];\n\tfor(int n=0; n<rows; n++)\n\t\twall[n]=data+cols*n;\n\tresult = new int[cols];\n\t\n\tint seed = M_SEED;\n\tsrand(seed);\n\n\tfor (int i = 0; i < rows; i++)\n    {\n        for (int j = 0; j < cols; j++)\n        {\n            wall[i][j] = rand() % 10;\n        }\n    }\n    for (int j = 0; j < cols; j++)\n        result[j] = wall[0][j];\n#ifdef BENCH_PRINT\n    for (int i = 0; i < rows; i++)\n    {\n        for (int j = 0; j < cols; j++)\n        {\n            printf(\""%d \"",wall[i][j]) ;\n        }\n        printf(\""\\n\"") ;\n    }\n#endif\n}\n\nvoid \nfatal(char *s)\n{\n\tfprintf(stderr, \""error: %s\\n\"", s);\n\n}\n\n#define IN_RANGE(x, min, max)   ((x)>=(min) && (x)<=(max))\n#define CLAMP_RANGE(x, min, max) x = (x<(min)) ? min : ((x>(max)) ? max : x )\n#define MIN(a, b) ((a)<=(b) ? (a) : (b))\n\nint main(int argc, char** argv)\n{\n    run(argc,argv);\n\n    return EXIT_SUCCESS;\n}\n\nvoid run(int argc, char** argv)\n{\n    init(argc, argv);\n\n    unsigned long long cycles;\n\n    int *src, *dst, *temp;\n    int min;\n\n    dst = result;\n    src = new int[cols];\n\n    pin_stats_reset();\n    for (int t = 0; t < rows-1; t++) {\n        temp = src;\n        src = dst;\n        dst = temp;\n        #pragma omp parallel for private(min)\n        for(int n = 0; n < cols; n++){\n          min = src[n];\n          if (n > 0)\n            min = MIN(min, src[n-1]);\n          if (n < cols-1)\n            min = MIN(min, src[n+1]);\n          dst[n] = wall[t+1][n]+min;\n        }\n    }\n\n    pin_stats_pause(cycles);\n    pin_stats_dump(cycles);\n\n#ifdef BENCH_PRINT\n\n    for (int i = 0; i < cols; i++)\n\n            printf(\""%d \"",data[i]) ;\n\n    printf(\""\\n\"") ;\n\n    for (int i = 0; i < cols; i++)\n\n            printf(\""%d \"",dst[i]) ;\n\n    printf(\""\\n\"") ;\n\n#endif\n\n    delete [] data;\n    delete [] wall;\n    delete [] dst;\n    delete [] src;\n}\n""",Does the code employ any advanced OpenMP directives like 'task' or 'single'?,No
Rodinia Pathfinder,"#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <assert.h>\n\n#include \timer.h\""\n\nvoid run(int argc, char** argv);\n\n/* define timer macros */\n#define pin_stats_reset()   startCycle()\n#define pin_stats_pause(cycles)   stopCycle(cycles)\n#define pin_stats_dump(cycles)    printf(\""timer: %Lu\\n\"", cycles)\n\n#define BENCH_PRINT\n\nint rows, cols;\nint* data;\nint** wall;\nint* result;\n#define M_SEED 9\n\nvoid\ninit(int argc, char** argv)\n{\n\tif(argc==3){\n\t\tcols = atoi(argv[1]);\n\t\trows = atoi(argv[2]);\n\t}else{\n                printf(\""Usage: pathfiner width num_of_steps\\n\"");\n                exit(0);\n        }\n\tdata = new int[rows*cols];\n\twall = new int*[rows];\n\tfor(int n=0; n<rows; n++)\n\t\twall[n]=data+cols*n;\n\tresult = new int[cols];\n\t\n\tint seed = M_SEED;\n\tsrand(seed);\n\n\tfor (int i = 0; i < rows; i++)\n    {\n        for (int j = 0; j < cols; j++)\n        {\n            wall[i][j] = rand() % 10;\n        }\n    }\n    for (int j = 0; j < cols; j++)\n        result[j] = wall[0][j];\n#ifdef BENCH_PRINT\n    for (int i = 0; i < rows; i++)\n    {\n        for (int j = 0; j < cols; j++)\n        {\n            printf(\""%d \"",wall[i][j]) ;\n        }\n        printf(\""\\n\"") ;\n    }\n#endif\n}\n\nvoid \nfatal(char *s)\n{\n\tfprintf(stderr, \""error: %s\\n\"", s);\n\n}\n\n#define IN_RANGE(x, min, max)   ((x)>=(min) && (x)<=(max))\n#define CLAMP_RANGE(x, min, max) x = (x<(min)) ? min : ((x>(max)) ? max : x )\n#define MIN(a, b) ((a)<=(b) ? (a) : (b))\n\nint main(int argc, char** argv)\n{\n    run(argc,argv);\n\n    return EXIT_SUCCESS;\n}\n\nvoid run(int argc, char** argv)\n{\n    init(argc, argv);\n\n    unsigned long long cycles;\n\n    int *src, *dst, *temp;\n    int min;\n\n    dst = result;\n    src = new int[cols];\n\n    pin_stats_reset();\n    for (int t = 0; t < rows-1; t++) {\n        temp = src;\n        src = dst;\n        dst = temp;\n        #pragma omp parallel for private(min)\n        for(int n = 0; n < cols; n++){\n          min = src[n];\n          if (n > 0)\n            min = MIN(min, src[n-1]);\n          if (n < cols-1)\n            min = MIN(min, src[n+1]);\n          dst[n] = wall[t+1][n]+min;\n        }\n    }\n\n    pin_stats_pause(cycles);\n    pin_stats_dump(cycles);\n\n#ifdef BENCH_PRINT\n\n    for (int i = 0; i < cols; i++)\n\n            printf(\""%d \"",data[i]) ;\n\n    printf(\""\\n\"") ;\n\n    for (int i = 0; i < cols; i++)\n\n            printf(\""%d \"",dst[i]) ;\n\n    printf(\""\\n\"") ;\n\n#endif\n\n    delete [] data;\n    delete [] wall;\n    delete [] dst;\n    delete [] src;\n}\n""",Does the code use nested loops? Are they parallelized?,Yes
Rodinia Pathfinder,"#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <assert.h>\n\n#include \timer.h\""\n\nvoid run(int argc, char** argv);\n\n/* define timer macros */\n#define pin_stats_reset()   startCycle()\n#define pin_stats_pause(cycles)   stopCycle(cycles)\n#define pin_stats_dump(cycles)    printf(\""timer: %Lu\\n\"", cycles)\n\n#define BENCH_PRINT\n\nint rows, cols;\nint* data;\nint** wall;\nint* result;\n#define M_SEED 9\n\nvoid\ninit(int argc, char** argv)\n{\n\tif(argc==3){\n\t\tcols = atoi(argv[1]);\n\t\trows = atoi(argv[2]);\n\t}else{\n                printf(\""Usage: pathfiner width num_of_steps\\n\"");\n                exit(0);\n        }\n\tdata = new int[rows*cols];\n\twall = new int*[rows];\n\tfor(int n=0; n<rows; n++)\n\t\twall[n]=data+cols*n;\n\tresult = new int[cols];\n\t\n\tint seed = M_SEED;\n\tsrand(seed);\n\n\tfor (int i = 0; i < rows; i++)\n    {\n        for (int j = 0; j < cols; j++)\n        {\n            wall[i][j] = rand() % 10;\n        }\n    }\n    for (int j = 0; j < cols; j++)\n        result[j] = wall[0][j];\n#ifdef BENCH_PRINT\n    for (int i = 0; i < rows; i++)\n    {\n        for (int j = 0; j < cols; j++)\n        {\n            printf(\""%d \"",wall[i][j]) ;\n        }\n        printf(\""\\n\"") ;\n    }\n#endif\n}\n\nvoid \nfatal(char *s)\n{\n\tfprintf(stderr, \""error: %s\\n\"", s);\n\n}\n\n#define IN_RANGE(x, min, max)   ((x)>=(min) && (x)<=(max))\n#define CLAMP_RANGE(x, min, max) x = (x<(min)) ? min : ((x>(max)) ? max : x )\n#define MIN(a, b) ((a)<=(b) ? (a) : (b))\n\nint main(int argc, char** argv)\n{\n    run(argc,argv);\n\n    return EXIT_SUCCESS;\n}\n\nvoid run(int argc, char** argv)\n{\n    init(argc, argv);\n\n    unsigned long long cycles;\n\n    int *src, *dst, *temp;\n    int min;\n\n    dst = result;\n    src = new int[cols];\n\n    pin_stats_reset();\n    for (int t = 0; t < rows-1; t++) {\n        temp = src;\n        src = dst;\n        dst = temp;\n        #pragma omp parallel for private(min)\n        for(int n = 0; n < cols; n++){\n          min = src[n];\n          if (n > 0)\n            min = MIN(min, src[n-1]);\n          if (n < cols-1)\n            min = MIN(min, src[n+1]);\n          dst[n] = wall[t+1][n]+min;\n        }\n    }\n\n    pin_stats_pause(cycles);\n    pin_stats_dump(cycles);\n\n#ifdef BENCH_PRINT\n\n    for (int i = 0; i < cols; i++)\n\n            printf(\""%d \"",data[i]) ;\n\n    printf(\""\\n\"") ;\n\n    for (int i = 0; i < cols; i++)\n\n            printf(\""%d \"",dst[i]) ;\n\n    printf(\""\\n\"") ;\n\n#endif\n\n    delete [] data;\n    delete [] wall;\n    delete [] dst;\n    delete [] src;\n}\n""",Is the code written in such a way that it will benefit from vectorized operations on the CPU?,Yes
Rodinia Pathfinder,"#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <assert.h>\n\n#include \timer.h\""\n\nvoid run(int argc, char** argv);\n\n/* define timer macros */\n#define pin_stats_reset()   startCycle()\n#define pin_stats_pause(cycles)   stopCycle(cycles)\n#define pin_stats_dump(cycles)    printf(\""timer: %Lu\\n\"", cycles)\n\n#define BENCH_PRINT\n\nint rows, cols;\nint* data;\nint** wall;\nint* result;\n#define M_SEED 9\n\nvoid\ninit(int argc, char** argv)\n{\n\tif(argc==3){\n\t\tcols = atoi(argv[1]);\n\t\trows = atoi(argv[2]);\n\t}else{\n                printf(\""Usage: pathfiner width num_of_steps\\n\"");\n                exit(0);\n        }\n\tdata = new int[rows*cols];\n\twall = new int*[rows];\n\tfor(int n=0; n<rows; n++)\n\t\twall[n]=data+cols*n;\n\tresult = new int[cols];\n\t\n\tint seed = M_SEED;\n\tsrand(seed);\n\n\tfor (int i = 0; i < rows; i++)\n    {\n        for (int j = 0; j < cols; j++)\n        {\n            wall[i][j] = rand() % 10;\n        }\n    }\n    for (int j = 0; j < cols; j++)\n        result[j] = wall[0][j];\n#ifdef BENCH_PRINT\n    for (int i = 0; i < rows; i++)\n    {\n        for (int j = 0; j < cols; j++)\n        {\n            printf(\""%d \"",wall[i][j]) ;\n        }\n        printf(\""\\n\"") ;\n    }\n#endif\n}\n\nvoid \nfatal(char *s)\n{\n\tfprintf(stderr, \""error: %s\\n\"", s);\n\n}\n\n#define IN_RANGE(x, min, max)   ((x)>=(min) && (x)<=(max))\n#define CLAMP_RANGE(x, min, max) x = (x<(min)) ? min : ((x>(max)) ? max : x )\n#define MIN(a, b) ((a)<=(b) ? (a) : (b))\n\nint main(int argc, char** argv)\n{\n    run(argc,argv);\n\n    return EXIT_SUCCESS;\n}\n\nvoid run(int argc, char** argv)\n{\n    init(argc, argv);\n\n    unsigned long long cycles;\n\n    int *src, *dst, *temp;\n    int min;\n\n    dst = result;\n    src = new int[cols];\n\n    pin_stats_reset();\n    for (int t = 0; t < rows-1; t++) {\n        temp = src;\n        src = dst;\n        dst = temp;\n        #pragma omp parallel for private(min)\n        for(int n = 0; n < cols; n++){\n          min = src[n];\n          if (n > 0)\n            min = MIN(min, src[n-1]);\n          if (n < cols-1)\n            min = MIN(min, src[n+1]);\n          dst[n] = wall[t+1][n]+min;\n        }\n    }\n\n    pin_stats_pause(cycles);\n    pin_stats_dump(cycles);\n\n#ifdef BENCH_PRINT\n\n    for (int i = 0; i < cols; i++)\n\n            printf(\""%d \"",data[i]) ;\n\n    printf(\""\\n\"") ;\n\n    for (int i = 0; i < cols; i++)\n\n            printf(\""%d \"",dst[i]) ;\n\n    printf(\""\\n\"") ;\n\n#endif\n\n    delete [] data;\n    delete [] wall;\n    delete [] dst;\n    delete [] src;\n}\n""",Does the code use dynamic scheduling to balance the load among threads?,No
Rodinia rng,"#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <sys/time.h>\n#include <omp.h>\n#include <limits.h>\n#define PI acos(-1)\nlong M = INT_MAX;\nint A = 1103515245;\nint C = 12345;\ndouble randu(int * seed, int index)\n{\n\tint num = A*seed[index] + C;\n\tseed[index] = num % M;\n\treturn fabs(seed[index]/((double) M));\n}\ndouble randn(int * seed, int index)\n{\n\tdouble u = randu(seed, index);\n\tdouble v = randu(seed, index);\n\tdouble cosine = cos(2*PI*v);\n\tdouble rt = -2*log(u);\n\treturn sqrt(rt)*cosine;\n}\nint main()\n{\n\tint length = 10000;\n\tint * seed = (int *)malloc(sizeof(int)*length);\n\tint x;\n\tfor(x = 0; x < length; x++)\n\t{\n\t\tseed[x] = time(0)*x;\n\t}\n\tfree(seed);\n\treturn 0;\n}",Does the given code use OpenMP for parallelism?,No
Rodinia rng,"#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <sys/time.h>\n#include <omp.h>\n#include <limits.h>\n#define PI acos(-1)\nlong M = INT_MAX;\nint A = 1103515245;\nint C = 12345;\ndouble randu(int * seed, int index)\n{\n\tint num = A*seed[index] + C;\n\tseed[index] = num % M;\n\treturn fabs(seed[index]/((double) M));\n}\ndouble randn(int * seed, int index)\n{\n\tdouble u = randu(seed, index);\n\tdouble v = randu(seed, index);\n\tdouble cosine = cos(2*PI*v);\n\tdouble rt = -2*log(u);\n\treturn sqrt(rt)*cosine;\n}\nint main()\n{\n\tint length = 10000;\n\tint * seed = (int *)malloc(sizeof(int)*length);\n\tint x;\n\tfor(x = 0; x < length; x++)\n\t{\n\t\tseed[x] = time(0)*x;\n\t}\n\tfree(seed);\n\treturn 0;\n}",Is there an optimization opportunity to parallelize the for loop in main function with OpenMP?,Yes
Rodinia rng,"#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <sys/time.h>\n#include <omp.h>\n#include <limits.h>\n#define PI acos(-1)\nlong M = INT_MAX;\nint A = 1103515245;\nint C = 12345;\ndouble randu(int * seed, int index)\n{\n\tint num = A*seed[index] + C;\n\tseed[index] = num % M;\n\treturn fabs(seed[index]/((double) M));\n}\ndouble randn(int * seed, int index)\n{\n\tdouble u = randu(seed, index);\n\tdouble v = randu(seed, index);\n\tdouble cosine = cos(2*PI*v);\n\tdouble rt = -2*log(u);\n\treturn sqrt(rt)*cosine;\n}\nint main()\n{\n\tint length = 10000;\n\tint * seed = (int *)malloc(sizeof(int)*length);\n\tint x;\n\tfor(x = 0; x < length; x++)\n\t{\n\t\tseed[x] = time(0)*x;\n\t}\n\tfree(seed);\n\treturn 0;\n}",Would using OpenMP's reduction operation help improve the performance of the given code snippet?,No
Rodinia rng,"#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <sys/time.h>\n#include <omp.h>\n#include <limits.h>\n#define PI acos(-1)\nlong M = INT_MAX;\nint A = 1103515245;\nint C = 12345;\ndouble randu(int * seed, int index)\n{\n\tint num = A*seed[index] + C;\n\tseed[index] = num % M;\n\treturn fabs(seed[index]/((double) M));\n}\ndouble randn(int * seed, int index)\n{\n\tdouble u = randu(seed, index);\n\tdouble v = randu(seed, index);\n\tdouble cosine = cos(2*PI*v);\n\tdouble rt = -2*log(u);\n\treturn sqrt(rt)*cosine;\n}\nint main()\n{\n\tint length = 10000;\n\tint * seed = (int *)malloc(sizeof(int)*length);\n\tint x;\n\tfor(x = 0; x < length; x++)\n\t{\n\t\tseed[x] = time(0)*x;\n\t}\n\tfree(seed);\n\treturn 0;\n}",Is the randu function thread safe for concurrent execution in an OpenMP parallel region?,No
Rodinia rng,"#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <sys/time.h>\n#include <omp.h>\n#include <limits.h>\n#define PI acos(-1)\nlong M = INT_MAX;\nint A = 1103515245;\nint C = 12345;\ndouble randu(int * seed, int index)\n{\n\tint num = A*seed[index] + C;\n\tseed[index] = num % M;\n\treturn fabs(seed[index]/((double) M));\n}\ndouble randn(int * seed, int index)\n{\n\tdouble u = randu(seed, index);\n\tdouble v = randu(seed, index);\n\tdouble cosine = cos(2*PI*v);\n\tdouble rt = -2*log(u);\n\treturn sqrt(rt)*cosine;\n}\nint main()\n{\n\tint length = 10000;\n\tint * seed = (int *)malloc(sizeof(int)*length);\n\tint x;\n\tfor(x = 0; x < length; x++)\n\t{\n\t\tseed[x] = time(0)*x;\n\t}\n\tfree(seed);\n\treturn 0;\n}",Can the generation of random numbers in this code be parallelized safely in OpenMP?,No
Rodinia rng,"#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <sys/time.h>\n#include <omp.h>\n#include <limits.h>\n#define PI acos(-1)\nlong M = INT_MAX;\nint A = 1103515245;\nint C = 12345;\ndouble randu(int * seed, int index)\n{\n\tint num = A*seed[index] + C;\n\tseed[index] = num % M;\n\treturn fabs(seed[index]/((double) M));\n}\ndouble randn(int * seed, int index)\n{\n\tdouble u = randu(seed, index);\n\tdouble v = randu(seed, index);\n\tdouble cosine = cos(2*PI*v);\n\tdouble rt = -2*log(u);\n\treturn sqrt(rt)*cosine;\n}\nint main()\n{\n\tint length = 10000;\n\tint * seed = (int *)malloc(sizeof(int)*length);\n\tint x;\n\tfor(x = 0; x < length; x++)\n\t{\n\t\tseed[x] = time(0)*x;\n\t}\n\tfree(seed);\n\treturn 0;\n}",Is the memory for the 'seed' array freed after its last use in the code snippet?,Yes
Rodinia rng,"#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <sys/time.h>\n#include <omp.h>\n#include <limits.h>\n#define PI acos(-1)\nlong M = INT_MAX;\nint A = 1103515245;\nint C = 12345;\ndouble randu(int * seed, int index)\n{\n\tint num = A*seed[index] + C;\n\tseed[index] = num % M;\n\treturn fabs(seed[index]/((double) M));\n}\ndouble randn(int * seed, int index)\n{\n\tdouble u = randu(seed, index);\n\tdouble v = randu(seed, index);\n\tdouble cosine = cos(2*PI*v);\n\tdouble rt = -2*log(u);\n\treturn sqrt(rt)*cosine;\n}\nint main()\n{\n\tint length = 10000;\n\tint * seed = (int *)malloc(sizeof(int)*length);\n\tint x;\n\tfor(x = 0; x < length; x++)\n\t{\n\t\tseed[x] = time(0)*x;\n\t}\n\tfree(seed);\n\treturn 0;\n}",Can OpenMP's schedule clause be used to improve performance in the 'for' loop?,Yes
Rodinia rng,"#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <sys/time.h>\n#include <omp.h>\n#include <limits.h>\n#define PI acos(-1)\nlong M = INT_MAX;\nint A = 1103515245;\nint C = 12345;\ndouble randu(int * seed, int index)\n{\n\tint num = A*seed[index] + C;\n\tseed[index] = num % M;\n\treturn fabs(seed[index]/((double) M));\n}\ndouble randn(int * seed, int index)\n{\n\tdouble u = randu(seed, index);\n\tdouble v = randu(seed, index);\n\tdouble cosine = cos(2*PI*v);\n\tdouble rt = -2*log(u);\n\treturn sqrt(rt)*cosine;\n}\nint main()\n{\n\tint length = 10000;\n\tint * seed = (int *)malloc(sizeof(int)*length);\n\tint x;\n\tfor(x = 0; x < length; x++)\n\t{\n\t\tseed[x] = time(0)*x;\n\t}\n\tfree(seed);\n\treturn 0;\n}",Would using OpenMP's nowait clause on the for loop result in correct execution of the code?,Yes
Rodinia rng,"#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <sys/time.h>\n#include <omp.h>\n#include <limits.h>\n#define PI acos(-1)\nlong M = INT_MAX;\nint A = 1103515245;\nint C = 12345;\ndouble randu(int * seed, int index)\n{\n\tint num = A*seed[index] + C;\n\tseed[index] = num % M;\n\treturn fabs(seed[index]/((double) M));\n}\ndouble randn(int * seed, int index)\n{\n\tdouble u = randu(seed, index);\n\tdouble v = randu(seed, index);\n\tdouble cosine = cos(2*PI*v);\n\tdouble rt = -2*log(u);\n\treturn sqrt(rt)*cosine;\n}\nint main()\n{\n\tint length = 10000;\n\tint * seed = (int *)malloc(sizeof(int)*length);\n\tint x;\n\tfor(x = 0; x < length; x++)\n\t{\n\t\tseed[x] = time(0)*x;\n\t}\n\tfree(seed);\n\treturn 0;\n}",Can the use of OpenMP's collapse clause improve the performance of this code?,No
Rodinia rng,"#include <stdlib.h>\n#include <stdio.h>\n#include <math.h>\n#include <sys/time.h>\n#include <omp.h>\n#include <limits.h>\n#define PI acos(-1)\nlong M = INT_MAX;\nint A = 1103515245;\nint C = 12345;\ndouble randu(int * seed, int index)\n{\n\tint num = A*seed[index] + C;\n\tseed[index] = num % M;\n\treturn fabs(seed[index]/((double) M));\n}\ndouble randn(int * seed, int index)\n{\n\tdouble u = randu(seed, index);\n\tdouble v = randu(seed, index);\n\tdouble cosine = cos(2*PI*v);\n\tdouble rt = -2*log(u);\n\treturn sqrt(rt)*cosine;\n}\nint main()\n{\n\tint length = 10000;\n\tint * seed = (int *)malloc(sizeof(int)*length);\n\tint x;\n\tfor(x = 0; x < length; x++)\n\t{\n\t\tseed[x] = time(0)*x;\n\t}\n\tfree(seed);\n\treturn 0;\n}",Will using OpenMP private clause for 'x' variable in the loop maintain the correctness of the code?,Yes
Rodinia-hotspot,"#include <stdio.h>\n#include <stdlib.h>\n#include <omp.h>\n#include <sys/time.h>\n\nlong long get_time()\n{\nstruct timeval tv;\ngettimeofday(&tv, NULL);\nreturn (tv.tv_sec * 1000000) + tv.tv_usec;\n}\n\nusing namespace std;\n\n#define BLOCK_SIZE 16\n#define BLOCK_SIZE_C BLOCK_SIZE\n#define BLOCK_SIZE_R BLOCK_SIZE\n\n#define STR_SIZE 256\n\n#define MAX_PD (3.0e6)\n#define PRECISION 0.001\n#define SPEC_HEAT_SI 1.75e6\n#define K_SI 100\n#define FACTOR_CHIP 0.5\n#define OPEN\n#define NUM_THREAD 4\n\ntypedef float FLOAT;\n\nconst FLOAT t_chip = 0.0005;\nconst FLOAT chip_height = 0.016;\nconst FLOAT chip_width = 0.016;\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(push, target(mic))\n#endif\n\nconst FLOAT amb_temp = 80.0;\n\nint num_omp_threads;\n\nvoid single_iteration(FLOAT *result, FLOAT *temp, FLOAT *power, int row, int col,\nFLOAT Cap_1, FLOAT Rx_1, FLOAT Ry_1, FLOAT Rz_1,\nFLOAT step)\n{\nFLOAT delta;\nint r, c;\nint chunk;\nint num_chunk = row*col / (BLOCK_SIZE_R * BLOCK_SIZE_C);\nint chunks_in_row = col/BLOCK_SIZE_C;\nint chunks_in_col = row/BLOCK_SIZE_R;\n\n#ifdef OPEN\n#ifndef __MIC__\nomp_set_num_threads(num_omp_threads);\n#endif\n#pragma omp parallel for shared(power, temp, result) private(chunk, r, c, delta) firstprivate(row, col, num_chunk, chunks_in_row) schedule(static)\n#endif\nfor ( chunk = 0; chunk < num_chunk; ++chunk )\n{\nint r_start = BLOCK_SIZE_R*(chunk/chunks_in_col);\nint c_start = BLOCK_SIZE_C*(chunk%chunks_in_row);\nint r_end = r_start + BLOCK_SIZE_R > row ? row : r_start + BLOCK_SIZE_R;\nint c_end = c_start + BLOCK_SIZE_C > col ? col : c_start + BLOCK_SIZE_C;\n\nif ( r_start == 0 || c_start == 0 || r_end == row || c_end == col )\n{\nfor ( r = r_start; r < r_start + BLOCK_SIZE_R; ++r ) {\nfor ( c = c_start; c < c_start + BLOCK_SIZE_C; ++c ) {\nif ( (r == 0) && (c == 0) ) {\ndelta = (Cap_1) * (power[0] +\n(temp[1] - temp[0]) * Rx_1 +\n(temp[col] - temp[0]) * Ry_1 +\n(amb_temp - temp[0]) * Rz_1);\n} else if ((r == 0) && (c == col-1)) {\ndelta = (Cap_1) * (power[c] +\n(temp[c-1] - temp[c]) * Rx_1 +\n(temp[c+col] - temp[c]) * Ry_1 +\n(amb_temp - temp[c]) * Rz_1);\n} else if ((r == row-1) && (c == col-1)) {\ndelta = (Cap_1) * (power[r*col+c] +\n(temp[r*col+c-1] - temp[r*col+c]) * Rx_1 +\n(temp[(r-1)*col+c] - temp[r*col+c]) * Ry_1 +\n(amb_temp - temp[r*col+c]) * Rz_1);\n} else if ((r == row-1) && (c == 0)) {\ndelta = (Cap_1) * (power[r*col] +\n(temp[r*col+1] - temp[r*col]) * Rx_1 +\n(temp[(r-1)*col] - temp[r*col]) * Ry_1 +\n(amb_temp - temp[r*col]) * Rz_1);\n} else if (r == 0) {\ndelta = (Cap_1) * (power[c] +\n(temp[c+1] + temp[c-1] - 2.0*temp[c]) * Rx_1 +\n(temp[col+c] -
",Does the provided code include nested loop parallelization using OpenMP?,Yes
Rodinia-hotspot,"#include <stdio.h>\n#include <stdlib.h>\n#include <omp.h>\n#include <sys/time.h>\n\nlong long get_time()\n{\nstruct timeval tv;\ngettimeofday(&tv, NULL);\nreturn (tv.tv_sec * 1000000) + tv.tv_usec;\n}\n\nusing namespace std;\n\n#define BLOCK_SIZE 16\n#define BLOCK_SIZE_C BLOCK_SIZE\n#define BLOCK_SIZE_R BLOCK_SIZE\n\n#define STR_SIZE 256\n\n#define MAX_PD (3.0e6)\n#define PRECISION 0.001\n#define SPEC_HEAT_SI 1.75e6\n#define K_SI 100\n#define FACTOR_CHIP 0.5\n#define OPEN\n#define NUM_THREAD 4\n\ntypedef float FLOAT;\n\nconst FLOAT t_chip = 0.0005;\nconst FLOAT chip_height = 0.016;\nconst FLOAT chip_width = 0.016;\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(push, target(mic))\n#endif\n\nconst FLOAT amb_temp = 80.0;\n\nint num_omp_threads;\n\nvoid single_iteration(FLOAT *result, FLOAT *temp, FLOAT *power, int row, int col,\nFLOAT Cap_1, FLOAT Rx_1, FLOAT Ry_1, FLOAT Rz_1,\nFLOAT step)\n{\nFLOAT delta;\nint r, c;\nint chunk;\nint num_chunk = row*col / (BLOCK_SIZE_R * BLOCK_SIZE_C);\nint chunks_in_row = col/BLOCK_SIZE_C;\nint chunks_in_col = row/BLOCK_SIZE_R;\n\n#ifdef OPEN\n#ifndef __MIC__\nomp_set_num_threads(num_omp_threads);\n#endif\n#pragma omp parallel for shared(power, temp, result) private(chunk, r, c, delta) firstprivate(row, col, num_chunk, chunks_in_row) schedule(static)\n#endif\nfor ( chunk = 0; chunk < num_chunk; ++chunk )\n{\nint r_start = BLOCK_SIZE_R*(chunk/chunks_in_col);\nint c_start = BLOCK_SIZE_C*(chunk%chunks_in_row);\nint r_end = r_start + BLOCK_SIZE_R > row ? row : r_start + BLOCK_SIZE_R;\nint c_end = c_start + BLOCK_SIZE_C > col ? col : c_start + BLOCK_SIZE_C;\n\nif ( r_start == 0 || c_start == 0 || r_end == row || c_end == col )\n{\nfor ( r = r_start; r < r_start + BLOCK_SIZE_R; ++r ) {\nfor ( c = c_start; c < c_start + BLOCK_SIZE_C; ++c ) {\nif ( (r == 0) && (c == 0) ) {\ndelta = (Cap_1) * (power[0] +\n(temp[1] - temp[0]) * Rx_1 +\n(temp[col] - temp[0]) * Ry_1 +\n(amb_temp - temp[0]) * Rz_1);\n} else if ((r == 0) && (c == col-1)) {\ndelta = (Cap_1) * (power[c] +\n(temp[c-1] - temp[c]) * Rx_1 +\n(temp[c+col] - temp[c]) * Ry_1 +\n(amb_temp - temp[c]) * Rz_1);\n} else if ((r == row-1) && (c == col-1)) {\ndelta = (Cap_1) * (power[r*col+c] +\n(temp[r*col+c-1] - temp[r*col+c]) * Rx_1 +\n(temp[(r-1)*col+c] - temp[r*col+c]) * Ry_1 +\n(amb_temp - temp[r*col+c]) * Rz_1);\n} else if ((r == row-1) && (c == 0)) {\ndelta = (Cap_1) * (power[r*col] +\n(temp[r*col+1] - temp[r*col]) * Rx_1 +\n(temp[(r-1)*col] - temp[r*col]) * Ry_1 +\n(amb_temp - temp[r*col]) * Rz_1);\n} else if (r == 0) {\ndelta = (Cap_1) * (power[c] +\n(temp[c+1] + temp[c-1] - 2.0*temp[c]) * Rx_1 +\n(temp[col+c] -
",Does the given code use dynamic scheduling for OpenMP threads?,No
Rodinia-hotspot,"#include <stdio.h>\n#include <stdlib.h>\n#include <omp.h>\n#include <sys/time.h>\n\nlong long get_time()\n{\nstruct timeval tv;\ngettimeofday(&tv, NULL);\nreturn (tv.tv_sec * 1000000) + tv.tv_usec;\n}\n\nusing namespace std;\n\n#define BLOCK_SIZE 16\n#define BLOCK_SIZE_C BLOCK_SIZE\n#define BLOCK_SIZE_R BLOCK_SIZE\n\n#define STR_SIZE 256\n\n#define MAX_PD (3.0e6)\n#define PRECISION 0.001\n#define SPEC_HEAT_SI 1.75e6\n#define K_SI 100\n#define FACTOR_CHIP 0.5\n#define OPEN\n#define NUM_THREAD 4\n\ntypedef float FLOAT;\n\nconst FLOAT t_chip = 0.0005;\nconst FLOAT chip_height = 0.016;\nconst FLOAT chip_width = 0.016;\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(push, target(mic))\n#endif\n\nconst FLOAT amb_temp = 80.0;\n\nint num_omp_threads;\n\nvoid single_iteration(FLOAT *result, FLOAT *temp, FLOAT *power, int row, int col,\nFLOAT Cap_1, FLOAT Rx_1, FLOAT Ry_1, FLOAT Rz_1,\nFLOAT step)\n{\nFLOAT delta;\nint r, c;\nint chunk;\nint num_chunk = row*col / (BLOCK_SIZE_R * BLOCK_SIZE_C);\nint chunks_in_row = col/BLOCK_SIZE_C;\nint chunks_in_col = row/BLOCK_SIZE_R;\n\n#ifdef OPEN\n#ifndef __MIC__\nomp_set_num_threads(num_omp_threads);\n#endif\n#pragma omp parallel for shared(power, temp, result) private(chunk, r, c, delta) firstprivate(row, col, num_chunk, chunks_in_row) schedule(static)\n#endif\nfor ( chunk = 0; chunk < num_chunk; ++chunk )\n{\nint r_start = BLOCK_SIZE_R*(chunk/chunks_in_col);\nint c_start = BLOCK_SIZE_C*(chunk%chunks_in_row);\nint r_end = r_start + BLOCK_SIZE_R > row ? row : r_start + BLOCK_SIZE_R;\nint c_end = c_start + BLOCK_SIZE_C > col ? col : c_start + BLOCK_SIZE_C;\n\nif ( r_start == 0 || c_start == 0 || r_end == row || c_end == col )\n{\nfor ( r = r_start; r < r_start + BLOCK_SIZE_R; ++r ) {\nfor ( c = c_start; c < c_start + BLOCK_SIZE_C; ++c ) {\nif ( (r == 0) && (c == 0) ) {\ndelta = (Cap_1) * (power[0] +\n(temp[1] - temp[0]) * Rx_1 +\n(temp[col] - temp[0]) * Ry_1 +\n(amb_temp - temp[0]) * Rz_1);\n} else if ((r == 0) && (c == col-1)) {\ndelta = (Cap_1) * (power[c] +\n(temp[c-1] - temp[c]) * Rx_1 +\n(temp[c+col] - temp[c]) * Ry_1 +\n(amb_temp - temp[c]) * Rz_1);\n} else if ((r == row-1) && (c == col-1)) {\ndelta = (Cap_1) * (power[r*col+c] +\n(temp[r*col+c-1] - temp[r*col+c]) * Rx_1 +\n(temp[(r-1)*col+c] - temp[r*col+c]) * Ry_1 +\n(amb_temp - temp[r*col+c]) * Rz_1);\n} else if ((r == row-1) && (c == 0)) {\ndelta = (Cap_1) * (power[r*col] +\n(temp[r*col+1] - temp[r*col]) * Rx_1 +\n(temp[(r-1)*col] - temp[r*col]) * Ry_1 +\n(amb_temp - temp[r*col]) * Rz_1);\n} else if (r == 0) {\ndelta = (Cap_1) * (power[c] +\n(temp[c+1] + temp[c-1] - 2.0*temp[c]) * Rx_1 +\n(temp[col+c] -
",Is the function 'single_iteration' parallelized using OpenMP in the provided code?,Yes
Rodinia-hotspot,"#include <stdio.h>\n#include <stdlib.h>\n#include <omp.h>\n#include <sys/time.h>\n\nlong long get_time()\n{\nstruct timeval tv;\ngettimeofday(&tv, NULL);\nreturn (tv.tv_sec * 1000000) + tv.tv_usec;\n}\n\nusing namespace std;\n\n#define BLOCK_SIZE 16\n#define BLOCK_SIZE_C BLOCK_SIZE\n#define BLOCK_SIZE_R BLOCK_SIZE\n\n#define STR_SIZE 256\n\n#define MAX_PD (3.0e6)\n#define PRECISION 0.001\n#define SPEC_HEAT_SI 1.75e6\n#define K_SI 100\n#define FACTOR_CHIP 0.5\n#define OPEN\n#define NUM_THREAD 4\n\ntypedef float FLOAT;\n\nconst FLOAT t_chip = 0.0005;\nconst FLOAT chip_height = 0.016;\nconst FLOAT chip_width = 0.016;\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(push, target(mic))\n#endif\n\nconst FLOAT amb_temp = 80.0;\n\nint num_omp_threads;\n\nvoid single_iteration(FLOAT *result, FLOAT *temp, FLOAT *power, int row, int col,\nFLOAT Cap_1, FLOAT Rx_1, FLOAT Ry_1, FLOAT Rz_1,\nFLOAT step)\n{\nFLOAT delta;\nint r, c;\nint chunk;\nint num_chunk = row*col / (BLOCK_SIZE_R * BLOCK_SIZE_C);\nint chunks_in_row = col/BLOCK_SIZE_C;\nint chunks_in_col = row/BLOCK_SIZE_R;\n\n#ifdef OPEN\n#ifndef __MIC__\nomp_set_num_threads(num_omp_threads);\n#endif\n#pragma omp parallel for shared(power, temp, result) private(chunk, r, c, delta) firstprivate(row, col, num_chunk, chunks_in_row) schedule(static)\n#endif\nfor ( chunk = 0; chunk < num_chunk; ++chunk )\n{\nint r_start = BLOCK_SIZE_R*(chunk/chunks_in_col);\nint c_start = BLOCK_SIZE_C*(chunk%chunks_in_row);\nint r_end = r_start + BLOCK_SIZE_R > row ? row : r_start + BLOCK_SIZE_R;\nint c_end = c_start + BLOCK_SIZE_C > col ? col : c_start + BLOCK_SIZE_C;\n\nif ( r_start == 0 || c_start == 0 || r_end == row || c_end == col )\n{\nfor ( r = r_start; r < r_start + BLOCK_SIZE_R; ++r ) {\nfor ( c = c_start; c < c_start + BLOCK_SIZE_C; ++c ) {\nif ( (r == 0) && (c == 0) ) {\ndelta = (Cap_1) * (power[0] +\n(temp[1] - temp[0]) * Rx_1 +\n(temp[col] - temp[0]) * Ry_1 +\n(amb_temp - temp[0]) * Rz_1);\n} else if ((r == 0) && (c == col-1)) {\ndelta = (Cap_1) * (power[c] +\n(temp[c-1] - temp[c]) * Rx_1 +\n(temp[c+col] - temp[c]) * Ry_1 +\n(amb_temp - temp[c]) * Rz_1);\n} else if ((r == row-1) && (c == col-1)) {\ndelta = (Cap_1) * (power[r*col+c] +\n(temp[r*col+c-1] - temp[r*col+c]) * Rx_1 +\n(temp[(r-1)*col+c] - temp[r*col+c]) * Ry_1 +\n(amb_temp - temp[r*col+c]) * Rz_1);\n} else if ((r == row-1) && (c == 0)) {\ndelta = (Cap_1) * (power[r*col] +\n(temp[r*col+1] - temp[r*col]) * Rx_1 +\n(temp[(r-1)*col] - temp[r*col]) * Ry_1 +\n(amb_temp - temp[r*col]) * Rz_1);\n} else if (r == 0) {\ndelta = (Cap_1) * (power[c] +\n(temp[c+1] + temp[c-1] - 2.0*temp[c]) * Rx_1 +\n(temp[col+c] -
",Is the number of OpenMP threads being set manually in the provided code?,Yes
Rodinia-hotspot,"#include <stdio.h>\n#include <stdlib.h>\n#include <omp.h>\n#include <sys/time.h>\n\nlong long get_time()\n{\nstruct timeval tv;\ngettimeofday(&tv, NULL);\nreturn (tv.tv_sec * 1000000) + tv.tv_usec;\n}\n\nusing namespace std;\n\n#define BLOCK_SIZE 16\n#define BLOCK_SIZE_C BLOCK_SIZE\n#define BLOCK_SIZE_R BLOCK_SIZE\n\n#define STR_SIZE 256\n\n#define MAX_PD (3.0e6)\n#define PRECISION 0.001\n#define SPEC_HEAT_SI 1.75e6\n#define K_SI 100\n#define FACTOR_CHIP 0.5\n#define OPEN\n#define NUM_THREAD 4\n\ntypedef float FLOAT;\n\nconst FLOAT t_chip = 0.0005;\nconst FLOAT chip_height = 0.016;\nconst FLOAT chip_width = 0.016;\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(push, target(mic))\n#endif\n\nconst FLOAT amb_temp = 80.0;\n\nint num_omp_threads;\n\nvoid single_iteration(FLOAT *result, FLOAT *temp, FLOAT *power, int row, int col,\nFLOAT Cap_1, FLOAT Rx_1, FLOAT Ry_1, FLOAT Rz_1,\nFLOAT step)\n{\nFLOAT delta;\nint r, c;\nint chunk;\nint num_chunk = row*col / (BLOCK_SIZE_R * BLOCK_SIZE_C);\nint chunks_in_row = col/BLOCK_SIZE_C;\nint chunks_in_col = row/BLOCK_SIZE_R;\n\n#ifdef OPEN\n#ifndef __MIC__\nomp_set_num_threads(num_omp_threads);\n#endif\n#pragma omp parallel for shared(power, temp, result) private(chunk, r, c, delta) firstprivate(row, col, num_chunk, chunks_in_row) schedule(static)\n#endif\nfor ( chunk = 0; chunk < num_chunk; ++chunk )\n{\nint r_start = BLOCK_SIZE_R*(chunk/chunks_in_col);\nint c_start = BLOCK_SIZE_C*(chunk%chunks_in_row);\nint r_end = r_start + BLOCK_SIZE_R > row ? row : r_start + BLOCK_SIZE_R;\nint c_end = c_start + BLOCK_SIZE_C > col ? col : c_start + BLOCK_SIZE_C;\n\nif ( r_start == 0 || c_start == 0 || r_end == row || c_end == col )\n{\nfor ( r = r_start; r < r_start + BLOCK_SIZE_R; ++r ) {\nfor ( c = c_start; c < c_start + BLOCK_SIZE_C; ++c ) {\nif ( (r == 0) && (c == 0) ) {\ndelta = (Cap_1) * (power[0] +\n(temp[1] - temp[0]) * Rx_1 +\n(temp[col] - temp[0]) * Ry_1 +\n(amb_temp - temp[0]) * Rz_1);\n} else if ((r == 0) && (c == col-1)) {\ndelta = (Cap_1) * (power[c] +\n(temp[c-1] - temp[c]) * Rx_1 +\n(temp[c+col] - temp[c]) * Ry_1 +\n(amb_temp - temp[c]) * Rz_1);\n} else if ((r == row-1) && (c == col-1)) {\ndelta = (Cap_1) * (power[r*col+c] +\n(temp[r*col+c-1] - temp[r*col+c]) * Rx_1 +\n(temp[(r-1)*col+c] - temp[r*col+c]) * Ry_1 +\n(amb_temp - temp[r*col+c]) * Rz_1);\n} else if ((r == row-1) && (c == 0)) {\ndelta = (Cap_1) * (power[r*col] +\n(temp[r*col+1] - temp[r*col]) * Rx_1 +\n(temp[(r-1)*col] - temp[r*col]) * Ry_1 +\n(amb_temp - temp[r*col]) * Rz_1);\n} else if (r == 0) {\ndelta = (Cap_1) * (power[c] +\n(temp[c+1] + temp[c-1] - 2.0*temp[c]) * Rx_1 +\n(temp[col+c] -
",Does the code use OpenMP's offloading feature for running on a device such as a GPU?,No
Rodinia-hotspot,"#include <stdio.h>\n#include <stdlib.h>\n#include <omp.h>\n#include <sys/time.h>\n\nlong long get_time()\n{\nstruct timeval tv;\ngettimeofday(&tv, NULL);\nreturn (tv.tv_sec * 1000000) + tv.tv_usec;\n}\n\nusing namespace std;\n\n#define BLOCK_SIZE 16\n#define BLOCK_SIZE_C BLOCK_SIZE\n#define BLOCK_SIZE_R BLOCK_SIZE\n\n#define STR_SIZE 256\n\n#define MAX_PD (3.0e6)\n#define PRECISION 0.001\n#define SPEC_HEAT_SI 1.75e6\n#define K_SI 100\n#define FACTOR_CHIP 0.5\n#define OPEN\n#define NUM_THREAD 4\n\ntypedef float FLOAT;\n\nconst FLOAT t_chip = 0.0005;\nconst FLOAT chip_height = 0.016;\nconst FLOAT chip_width = 0.016;\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(push, target(mic))\n#endif\n\nconst FLOAT amb_temp = 80.0;\n\nint num_omp_threads;\n\nvoid single_iteration(FLOAT *result, FLOAT *temp, FLOAT *power, int row, int col,\nFLOAT Cap_1, FLOAT Rx_1, FLOAT Ry_1, FLOAT Rz_1,\nFLOAT step)\n{\nFLOAT delta;\nint r, c;\nint chunk;\nint num_chunk = row*col / (BLOCK_SIZE_R * BLOCK_SIZE_C);\nint chunks_in_row = col/BLOCK_SIZE_C;\nint chunks_in_col = row/BLOCK_SIZE_R;\n\n#ifdef OPEN\n#ifndef __MIC__\nomp_set_num_threads(num_omp_threads);\n#endif\n#pragma omp parallel for shared(power, temp, result) private(chunk, r, c, delta) firstprivate(row, col, num_chunk, chunks_in_row) schedule(static)\n#endif\nfor ( chunk = 0; chunk < num_chunk; ++chunk )\n{\nint r_start = BLOCK_SIZE_R*(chunk/chunks_in_col);\nint c_start = BLOCK_SIZE_C*(chunk%chunks_in_row);\nint r_end = r_start + BLOCK_SIZE_R > row ? row : r_start + BLOCK_SIZE_R;\nint c_end = c_start + BLOCK_SIZE_C > col ? col : c_start + BLOCK_SIZE_C;\n\nif ( r_start == 0 || c_start == 0 || r_end == row || c_end == col )\n{\nfor ( r = r_start; r < r_start + BLOCK_SIZE_R; ++r ) {\nfor ( c = c_start; c < c_start + BLOCK_SIZE_C; ++c ) {\nif ( (r == 0) && (c == 0) ) {\ndelta = (Cap_1) * (power[0] +\n(temp[1] - temp[0]) * Rx_1 +\n(temp[col] - temp[0]) * Ry_1 +\n(amb_temp - temp[0]) * Rz_1);\n} else if ((r == 0) && (c == col-1)) {\ndelta = (Cap_1) * (power[c] +\n(temp[c-1] - temp[c]) * Rx_1 +\n(temp[c+col] - temp[c]) * Ry_1 +\n(amb_temp - temp[c]) * Rz_1);\n} else if ((r == row-1) && (c == col-1)) {\ndelta = (Cap_1) * (power[r*col+c] +\n(temp[r*col+c-1] - temp[r*col+c]) * Rx_1 +\n(temp[(r-1)*col+c] - temp[r*col+c]) * Ry_1 +\n(amb_temp - temp[r*col+c]) * Rz_1);\n} else if ((r == row-1) && (c == 0)) {\ndelta = (Cap_1) * (power[r*col] +\n(temp[r*col+1] - temp[r*col]) * Rx_1 +\n(temp[(r-1)*col] - temp[r*col]) * Ry_1 +\n(amb_temp - temp[r*col]) * Rz_1);\n} else if (r == 0) {\ndelta = (Cap_1) * (power[c] +\n(temp[c+1] + temp[c-1] - 2.0*temp[c]) * Rx_1 +\n(temp[col+c] -
",Is the provided code using OpenMP to perform reduction operations?,No
Rodinia-hotspot,"#include <stdio.h>\n#include <stdlib.h>\n#include <omp.h>\n#include <sys/time.h>\n\nlong long get_time()\n{\nstruct timeval tv;\ngettimeofday(&tv, NULL);\nreturn (tv.tv_sec * 1000000) + tv.tv_usec;\n}\n\nusing namespace std;\n\n#define BLOCK_SIZE 16\n#define BLOCK_SIZE_C BLOCK_SIZE\n#define BLOCK_SIZE_R BLOCK_SIZE\n\n#define STR_SIZE 256\n\n#define MAX_PD (3.0e6)\n#define PRECISION 0.001\n#define SPEC_HEAT_SI 1.75e6\n#define K_SI 100\n#define FACTOR_CHIP 0.5\n#define OPEN\n#define NUM_THREAD 4\n\ntypedef float FLOAT;\n\nconst FLOAT t_chip = 0.0005;\nconst FLOAT chip_height = 0.016;\nconst FLOAT chip_width = 0.016;\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(push, target(mic))\n#endif\n\nconst FLOAT amb_temp = 80.0;\n\nint num_omp_threads;\n\nvoid single_iteration(FLOAT *result, FLOAT *temp, FLOAT *power, int row, int col,\nFLOAT Cap_1, FLOAT Rx_1, FLOAT Ry_1, FLOAT Rz_1,\nFLOAT step)\n{\nFLOAT delta;\nint r, c;\nint chunk;\nint num_chunk = row*col / (BLOCK_SIZE_R * BLOCK_SIZE_C);\nint chunks_in_row = col/BLOCK_SIZE_C;\nint chunks_in_col = row/BLOCK_SIZE_R;\n\n#ifdef OPEN\n#ifndef __MIC__\nomp_set_num_threads(num_omp_threads);\n#endif\n#pragma omp parallel for shared(power, temp, result) private(chunk, r, c, delta) firstprivate(row, col, num_chunk, chunks_in_row) schedule(static)\n#endif\nfor ( chunk = 0; chunk < num_chunk; ++chunk )\n{\nint r_start = BLOCK_SIZE_R*(chunk/chunks_in_col);\nint c_start = BLOCK_SIZE_C*(chunk%chunks_in_row);\nint r_end = r_start + BLOCK_SIZE_R > row ? row : r_start + BLOCK_SIZE_R;\nint c_end = c_start + BLOCK_SIZE_C > col ? col : c_start + BLOCK_SIZE_C;\n\nif ( r_start == 0 || c_start == 0 || r_end == row || c_end == col )\n{\nfor ( r = r_start; r < r_start + BLOCK_SIZE_R; ++r ) {\nfor ( c = c_start; c < c_start + BLOCK_SIZE_C; ++c ) {\nif ( (r == 0) && (c == 0) ) {\ndelta = (Cap_1) * (power[0] +\n(temp[1] - temp[0]) * Rx_1 +\n(temp[col] - temp[0]) * Ry_1 +\n(amb_temp - temp[0]) * Rz_1);\n} else if ((r == 0) && (c == col-1)) {\ndelta = (Cap_1) * (power[c] +\n(temp[c-1] - temp[c]) * Rx_1 +\n(temp[c+col] - temp[c]) * Ry_1 +\n(amb_temp - temp[c]) * Rz_1);\n} else if ((r == row-1) && (c == col-1)) {\ndelta = (Cap_1) * (power[r*col+c] +\n(temp[r*col+c-1] - temp[r*col+c]) * Rx_1 +\n(temp[(r-1)*col+c] - temp[r*col+c]) * Ry_1 +\n(amb_temp - temp[r*col+c]) * Rz_1);\n} else if ((r == row-1) && (c == 0)) {\ndelta = (Cap_1) * (power[r*col] +\n(temp[r*col+1] - temp[r*col]) * Rx_1 +\n(temp[(r-1)*col] - temp[r*col]) * Ry_1 +\n(amb_temp - temp[r*col]) * Rz_1);\n} else if (r == 0) {\ndelta = (Cap_1) * (power[c] +\n(temp[c+1] + temp[c-1] - 2.0*temp[c]) * Rx_1 +\n(temp[col+c] -
",Does this code use the OpenMP 'shared' clause to specify variables that are shared across threads?,Yes
Rodinia-hotspot,"#include <stdio.h>\n#include <stdlib.h>\n#include <omp.h>\n#include <sys/time.h>\n\nlong long get_time()\n{\nstruct timeval tv;\ngettimeofday(&tv, NULL);\nreturn (tv.tv_sec * 1000000) + tv.tv_usec;\n}\n\nusing namespace std;\n\n#define BLOCK_SIZE 16\n#define BLOCK_SIZE_C BLOCK_SIZE\n#define BLOCK_SIZE_R BLOCK_SIZE\n\n#define STR_SIZE 256\n\n#define MAX_PD (3.0e6)\n#define PRECISION 0.001\n#define SPEC_HEAT_SI 1.75e6\n#define K_SI 100\n#define FACTOR_CHIP 0.5\n#define OPEN\n#define NUM_THREAD 4\n\ntypedef float FLOAT;\n\nconst FLOAT t_chip = 0.0005;\nconst FLOAT chip_height = 0.016;\nconst FLOAT chip_width = 0.016;\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(push, target(mic))\n#endif\n\nconst FLOAT amb_temp = 80.0;\n\nint num_omp_threads;\n\nvoid single_iteration(FLOAT *result, FLOAT *temp, FLOAT *power, int row, int col,\nFLOAT Cap_1, FLOAT Rx_1, FLOAT Ry_1, FLOAT Rz_1,\nFLOAT step)\n{\nFLOAT delta;\nint r, c;\nint chunk;\nint num_chunk = row*col / (BLOCK_SIZE_R * BLOCK_SIZE_C);\nint chunks_in_row = col/BLOCK_SIZE_C;\nint chunks_in_col = row/BLOCK_SIZE_R;\n\n#ifdef OPEN\n#ifndef __MIC__\nomp_set_num_threads(num_omp_threads);\n#endif\n#pragma omp parallel for shared(power, temp, result) private(chunk, r, c, delta) firstprivate(row, col, num_chunk, chunks_in_row) schedule(static)\n#endif\nfor ( chunk = 0; chunk < num_chunk; ++chunk )\n{\nint r_start = BLOCK_SIZE_R*(chunk/chunks_in_col);\nint c_start = BLOCK_SIZE_C*(chunk%chunks_in_row);\nint r_end = r_start + BLOCK_SIZE_R > row ? row : r_start + BLOCK_SIZE_R;\nint c_end = c_start + BLOCK_SIZE_C > col ? col : c_start + BLOCK_SIZE_C;\n\nif ( r_start == 0 || c_start == 0 || r_end == row || c_end == col )\n{\nfor ( r = r_start; r < r_start + BLOCK_SIZE_R; ++r ) {\nfor ( c = c_start; c < c_start + BLOCK_SIZE_C; ++c ) {\nif ( (r == 0) && (c == 0) ) {\ndelta = (Cap_1) * (power[0] +\n(temp[1] - temp[0]) * Rx_1 +\n(temp[col] - temp[0]) * Ry_1 +\n(amb_temp - temp[0]) * Rz_1);\n} else if ((r == 0) && (c == col-1)) {\ndelta = (Cap_1) * (power[c] +\n(temp[c-1] - temp[c]) * Rx_1 +\n(temp[c+col] - temp[c]) * Ry_1 +\n(amb_temp - temp[c]) * Rz_1);\n} else if ((r == row-1) && (c == col-1)) {\ndelta = (Cap_1) * (power[r*col+c] +\n(temp[r*col+c-1] - temp[r*col+c]) * Rx_1 +\n(temp[(r-1)*col+c] - temp[r*col+c]) * Ry_1 +\n(amb_temp - temp[r*col+c]) * Rz_1);\n} else if ((r == row-1) && (c == 0)) {\ndelta = (Cap_1) * (power[r*col] +\n(temp[r*col+1] - temp[r*col]) * Rx_1 +\n(temp[(r-1)*col] - temp[r*col]) * Ry_1 +\n(amb_temp - temp[r*col]) * Rz_1);\n} else if (r == 0) {\ndelta = (Cap_1) * (power[c] +\n(temp[c+1] + temp[c-1] - 2.0*temp[c]) * Rx_1 +\n(temp[col+c] -
",Does the provided code use the OpenMP library for timing its execution?,No
Rodinia-hotspot,"#include <stdio.h>\n#include <stdlib.h>\n#include <omp.h>\n#include <sys/time.h>\n\nlong long get_time()\n{\nstruct timeval tv;\ngettimeofday(&tv, NULL);\nreturn (tv.tv_sec * 1000000) + tv.tv_usec;\n}\n\nusing namespace std;\n\n#define BLOCK_SIZE 16\n#define BLOCK_SIZE_C BLOCK_SIZE\n#define BLOCK_SIZE_R BLOCK_SIZE\n\n#define STR_SIZE 256\n\n#define MAX_PD (3.0e6)\n#define PRECISION 0.001\n#define SPEC_HEAT_SI 1.75e6\n#define K_SI 100\n#define FACTOR_CHIP 0.5\n#define OPEN\n#define NUM_THREAD 4\n\ntypedef float FLOAT;\n\nconst FLOAT t_chip = 0.0005;\nconst FLOAT chip_height = 0.016;\nconst FLOAT chip_width = 0.016;\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(push, target(mic))\n#endif\n\nconst FLOAT amb_temp = 80.0;\n\nint num_omp_threads;\n\nvoid single_iteration(FLOAT *result, FLOAT *temp, FLOAT *power, int row, int col,\nFLOAT Cap_1, FLOAT Rx_1, FLOAT Ry_1, FLOAT Rz_1,\nFLOAT step)\n{\nFLOAT delta;\nint r, c;\nint chunk;\nint num_chunk = row*col / (BLOCK_SIZE_R * BLOCK_SIZE_C);\nint chunks_in_row = col/BLOCK_SIZE_C;\nint chunks_in_col = row/BLOCK_SIZE_R;\n\n#ifdef OPEN\n#ifndef __MIC__\nomp_set_num_threads(num_omp_threads);\n#endif\n#pragma omp parallel for shared(power, temp, result) private(chunk, r, c, delta) firstprivate(row, col, num_chunk, chunks_in_row) schedule(static)\n#endif\nfor ( chunk = 0; chunk < num_chunk; ++chunk )\n{\nint r_start = BLOCK_SIZE_R*(chunk/chunks_in_col);\nint c_start = BLOCK_SIZE_C*(chunk%chunks_in_row);\nint r_end = r_start + BLOCK_SIZE_R > row ? row : r_start + BLOCK_SIZE_R;\nint c_end = c_start + BLOCK_SIZE_C > col ? col : c_start + BLOCK_SIZE_C;\n\nif ( r_start == 0 || c_start == 0 || r_end == row || c_end == col )\n{\nfor ( r = r_start; r < r_start + BLOCK_SIZE_R; ++r ) {\nfor ( c = c_start; c < c_start + BLOCK_SIZE_C; ++c ) {\nif ( (r == 0) && (c == 0) ) {\ndelta = (Cap_1) * (power[0] +\n(temp[1] - temp[0]) * Rx_1 +\n(temp[col] - temp[0]) * Ry_1 +\n(amb_temp - temp[0]) * Rz_1);\n} else if ((r == 0) && (c == col-1)) {\ndelta = (Cap_1) * (power[c] +\n(temp[c-1] - temp[c]) * Rx_1 +\n(temp[c+col] - temp[c]) * Ry_1 +\n(amb_temp - temp[c]) * Rz_1);\n} else if ((r == row-1) && (c == col-1)) {\ndelta = (Cap_1) * (power[r*col+c] +\n(temp[r*col+c-1] - temp[r*col+c]) * Rx_1 +\n(temp[(r-1)*col+c] - temp[r*col+c]) * Ry_1 +\n(amb_temp - temp[r*col+c]) * Rz_1);\n} else if ((r == row-1) && (c == 0)) {\ndelta = (Cap_1) * (power[r*col] +\n(temp[r*col+1] - temp[r*col]) * Rx_1 +\n(temp[(r-1)*col] - temp[r*col]) * Ry_1 +\n(amb_temp - temp[r*col]) * Rz_1);\n} else if (r == 0) {\ndelta = (Cap_1) * (power[c] +\n(temp[c+1] + temp[c-1] - 2.0*temp[c]) * Rx_1 +\n(temp[col+c] -
",Is the code using OpenMP's 'critical' section for avoiding race conditions?,No
Rodinia-hotspot,"#include <stdio.h>\n#include <stdlib.h>\n#include <omp.h>\n#include <sys/time.h>\n\nlong long get_time()\n{\nstruct timeval tv;\ngettimeofday(&tv, NULL);\nreturn (tv.tv_sec * 1000000) + tv.tv_usec;\n}\n\nusing namespace std;\n\n#define BLOCK_SIZE 16\n#define BLOCK_SIZE_C BLOCK_SIZE\n#define BLOCK_SIZE_R BLOCK_SIZE\n\n#define STR_SIZE 256\n\n#define MAX_PD (3.0e6)\n#define PRECISION 0.001\n#define SPEC_HEAT_SI 1.75e6\n#define K_SI 100\n#define FACTOR_CHIP 0.5\n#define OPEN\n#define NUM_THREAD 4\n\ntypedef float FLOAT;\n\nconst FLOAT t_chip = 0.0005;\nconst FLOAT chip_height = 0.016;\nconst FLOAT chip_width = 0.016;\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(push, target(mic))\n#endif\n\nconst FLOAT amb_temp = 80.0;\n\nint num_omp_threads;\n\nvoid single_iteration(FLOAT *result, FLOAT *temp, FLOAT *power, int row, int col,\nFLOAT Cap_1, FLOAT Rx_1, FLOAT Ry_1, FLOAT Rz_1,\nFLOAT step)\n{\nFLOAT delta;\nint r, c;\nint chunk;\nint num_chunk = row*col / (BLOCK_SIZE_R * BLOCK_SIZE_C);\nint chunks_in_row = col/BLOCK_SIZE_C;\nint chunks_in_col = row/BLOCK_SIZE_R;\n\n#ifdef OPEN\n#ifndef __MIC__\nomp_set_num_threads(num_omp_threads);\n#endif\n#pragma omp parallel for shared(power, temp, result) private(chunk, r, c, delta) firstprivate(row, col, num_chunk, chunks_in_row) schedule(static)\n#endif\nfor ( chunk = 0; chunk < num_chunk; ++chunk )\n{\nint r_start = BLOCK_SIZE_R*(chunk/chunks_in_col);\nint c_start = BLOCK_SIZE_C*(chunk%chunks_in_row);\nint r_end = r_start + BLOCK_SIZE_R > row ? row : r_start + BLOCK_SIZE_R;\nint c_end = c_start + BLOCK_SIZE_C > col ? col : c_start + BLOCK_SIZE_C;\n\nif ( r_start == 0 || c_start == 0 || r_end == row || c_end == col )\n{\nfor ( r = r_start; r < r_start + BLOCK_SIZE_R; ++r ) {\nfor ( c = c_start; c < c_start + BLOCK_SIZE_C; ++c ) {\nif ( (r == 0) && (c == 0) ) {\ndelta = (Cap_1) * (power[0] +\n(temp[1] - temp[0]) * Rx_1 +\n(temp[col] - temp[0]) * Ry_1 +\n(amb_temp - temp[0]) * Rz_1);\n} else if ((r == 0) && (c == col-1)) {\ndelta = (Cap_1) * (power[c] +\n(temp[c-1] - temp[c]) * Rx_1 +\n(temp[c+col] - temp[c]) * Ry_1 +\n(amb_temp - temp[c]) * Rz_1);\n} else if ((r == row-1) && (c == col-1)) {\ndelta = (Cap_1) * (power[r*col+c] +\n(temp[r*col+c-1] - temp[r*col+c]) * Rx_1 +\n(temp[(r-1)*col+c] - temp[r*col+c]) * Ry_1 +\n(amb_temp - temp[r*col+c]) * Rz_1);\n} else if ((r == row-1) && (c == 0)) {\ndelta = (Cap_1) * (power[r*col] +\n(temp[r*col+1] - temp[r*col]) * Rx_1 +\n(temp[(r-1)*col] - temp[r*col]) * Ry_1 +\n(amb_temp - temp[r*col]) * Rz_1);\n} else if (r == 0) {\ndelta = (Cap_1) * (power[c] +\n(temp[c+1] + temp[c-1] - 2.0*temp[c]) * Rx_1 +\n(temp[col+c] -
",Is the number of OpenMP threads specified in the code equal to NUM_THREAD?,Yes
Rodinia-LUD,"#include <stdio.h>\n#include <omp.h>\n\nextern int omp_num_threads;\n\n#define BS 16\n\n#define AA(_i,_j) a[offset*size+_i*size+_j+offset]\n#define BB(_i,_j) a[_i*size+_j]\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(push, target(mic))\n#endif\n\nvoid lud_diagonal_omp (float* a, int size, int offset)\n{\n    int i, j, k;\n    for (i = 0; i < BS; i++) {\n\n        for (j = i; j < BS; j++) {\n            for (k = 0; k < i ; k++) {\n                AA(i,j) = AA(i,j) - AA(i,k) * AA(k,j);\n            }\n        }\n   \n        float temp = 1.f/AA(i,i);\n        for (j = i+1; j < BS; j++) {\n            for (k = 0; k < i ; k++) {\n                AA(j,i) = AA(j,i) - AA(j,k) * AA(k,i);\n            }\n            AA(j,i) = AA(j,i)*temp;\n        }\n    }\n\n}\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(pop)\n#endif\n\n\n// implements block LU factorization \nvoid lud_omp(float *a, int size)\n{\n    int offset, chunk_idx, size_inter, chunks_in_inter_row, chunks_per_inter;\n\n#ifdef OMP_OFFLOAD\n#pragma omp target map(to: size) map(a[0:size*size])\n#endif\n\n#ifdef OMP_OFFLOAD\n{\n    omp_set_num_threads(224);\n#else\n    printf(\running OMP on host\\n\"");\n    omp_set_num_threads(omp_num_threads);\n#endif\n    for (offset = 0; offset < size - BS ; offset += BS)\n    {\n        // lu factorization of left-top corner block diagonal matrix \n        //\n        lud_diagonal_omp(a, size, offset);\n            \n        size_inter = size - offset -  BS;\n        chunks_in_inter_row  = size_inter/BS;\n        \n        // calculate perimeter block matrices\n        // \n        #pragma omp parallel for default(none) \\\n          private(chunk_idx) shared(size, chunks_per_inter, chunks_in_inter_row, offset, a) \n        for ( chunk_idx = 0; chunk_idx < chunks_in_inter_row; chunk_idx++)\n        {\n            int i, j, k, i_global, j_global, i_here, j_here;\n            float sum;           \n            float temp[BS*BS] __attribute__ ((aligned (64)));\n\n            for (i = 0; i < BS; i++) {\n                #pragma omp simd\n                for (j =0; j < BS; j++){\n                    temp[i*BS + j] = a[size*(i + offset) + offset + j ];\n                }\n            }\n            i_global = offset;\n            j_global = offset;\n            \n            // processing top perimeter\n            //\n            j_global += BS * (chunk_idx+1);\n            for (j = 0; j < BS; j++) {\n                for (i = 0; i < BS; i++) {\n                    sum = 0.f;\n                    for (k=0; k < i; k++) {\n                        sum += temp[BS*i +k] * BB((i_global+k),(j_global+j));\n                    }\n                    i_here = i_global + i;\n                    j_here = j_global + j;\n                    BB(i_here, j_here) = BB(i_here,j_here) - sum;\n                }\n            }\n\n            // processing left perimeter\n            //\n            j_global = offset;\n            i_global += BS * (chunk_idx + 1);\n            for (i = 0; i < BS; i++) {\n                for (j = 0; j < BS; j++) {\n                    sum = 0.f;\n                    for (k=0; k < j; k++) {\n                        sum += BB((i_global+i),(j_global+k)) * temp[BS*k + j];\n                    }\n                    i_here = i_global + i;\n                    j_here = j_global + j;\n                    a[size*i_here + j_here] = ( a[size*i_here+j_here] - sum ) / a[size*(offset+j) + offset+j];\n                }\n            }\n\n        }\n        \n        // update interior block matrices\n        //\n        chunks_per_inter = chunks_in_inter_row*chunks_in_inter_row;\n\n#pragma omp parallel for schedule(auto) default(none) \\\n         private(chunk_idx ) shared(size, chunks_per_inter, chunks_in_inter_row, offset, a) \n        for  (chunk_idx =0; chunk_idx < chunks_per_inter; chunk_idx++)\n        {\n            int i, j, k, i_global, j_global;\n            float temp_top[BS*BS] __attribute__ ((aligned (64)));\n            float temp_left[BS*BS] __attribute__ ((aligned (64)));\n            float sum[BS] __attribute__ ((aligned (64))) = {0.f};\n            \n            i_global = offset + BS * (1 +  chunk_idx/chunks_in_inter_row);\n            j_global = offset + BS * (1 + chunk_idx%chunks_in_inter_row);\n\n            for (i = 0; i < BS; i++) {\n#pragma omp simd\n                for (j =0; j < BS; j++){\n                    temp_top[i*BS + j]  = a[size*(i + offset) + j + j_global ];\n                    temp_left[i*BS + j] = a[size*(i + i_global) + offset + j];\n                }\n            }\n\n            for (i = 0; i < BS; i++)\n            {\n                for (k=0; k < BS; k++) {\n#pragma omp simd \n                    for (j = 0; j < BS; j++) {\n                        sum[j] += temp_left[BS*i + k] * temp_top[BS*k + j];\n                    }\n                }\n#pragma omp simd \n                for (j = 0; j < BS; j++) {\n                    BB((i+i_global),(j+j_global)) -= sum[j];\n                    sum[j] = 0.f;\n                }\n            }\n        }\n    }\n\n    lud_diagonal_omp(a, size, offset);\n#ifdef OMP_OFFLOAD\n}\n#endif\n\n}\n""",Does the given code sample make use of loop parallelization via OpenMP?,Yes
Rodinia-LUD,"#include <stdio.h>\n#include <omp.h>\n\nextern int omp_num_threads;\n\n#define BS 16\n\n#define AA(_i,_j) a[offset*size+_i*size+_j+offset]\n#define BB(_i,_j) a[_i*size+_j]\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(push, target(mic))\n#endif\n\nvoid lud_diagonal_omp (float* a, int size, int offset)\n{\n    int i, j, k;\n    for (i = 0; i < BS; i++) {\n\n        for (j = i; j < BS; j++) {\n            for (k = 0; k < i ; k++) {\n                AA(i,j) = AA(i,j) - AA(i,k) * AA(k,j);\n            }\n        }\n   \n        float temp = 1.f/AA(i,i);\n        for (j = i+1; j < BS; j++) {\n            for (k = 0; k < i ; k++) {\n                AA(j,i) = AA(j,i) - AA(j,k) * AA(k,i);\n            }\n            AA(j,i) = AA(j,i)*temp;\n        }\n    }\n\n}\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(pop)\n#endif\n\n\n// implements block LU factorization \nvoid lud_omp(float *a, int size)\n{\n    int offset, chunk_idx, size_inter, chunks_in_inter_row, chunks_per_inter;\n\n#ifdef OMP_OFFLOAD\n#pragma omp target map(to: size) map(a[0:size*size])\n#endif\n\n#ifdef OMP_OFFLOAD\n{\n    omp_set_num_threads(224);\n#else\n    printf(\running OMP on host\\n\"");\n    omp_set_num_threads(omp_num_threads);\n#endif\n    for (offset = 0; offset < size - BS ; offset += BS)\n    {\n        // lu factorization of left-top corner block diagonal matrix \n        //\n        lud_diagonal_omp(a, size, offset);\n            \n        size_inter = size - offset -  BS;\n        chunks_in_inter_row  = size_inter/BS;\n        \n        // calculate perimeter block matrices\n        // \n        #pragma omp parallel for default(none) \\\n          private(chunk_idx) shared(size, chunks_per_inter, chunks_in_inter_row, offset, a) \n        for ( chunk_idx = 0; chunk_idx < chunks_in_inter_row; chunk_idx++)\n        {\n            int i, j, k, i_global, j_global, i_here, j_here;\n            float sum;           \n            float temp[BS*BS] __attribute__ ((aligned (64)));\n\n            for (i = 0; i < BS; i++) {\n                #pragma omp simd\n                for (j =0; j < BS; j++){\n                    temp[i*BS + j] = a[size*(i + offset) + offset + j ];\n                }\n            }\n            i_global = offset;\n            j_global = offset;\n            \n            // processing top perimeter\n            //\n            j_global += BS * (chunk_idx+1);\n            for (j = 0; j < BS; j++) {\n                for (i = 0; i < BS; i++) {\n                    sum = 0.f;\n                    for (k=0; k < i; k++) {\n                        sum += temp[BS*i +k] * BB((i_global+k),(j_global+j));\n                    }\n                    i_here = i_global + i;\n                    j_here = j_global + j;\n                    BB(i_here, j_here) = BB(i_here,j_here) - sum;\n                }\n            }\n\n            // processing left perimeter\n            //\n            j_global = offset;\n            i_global += BS * (chunk_idx + 1);\n            for (i = 0; i < BS; i++) {\n                for (j = 0; j < BS; j++) {\n                    sum = 0.f;\n                    for (k=0; k < j; k++) {\n                        sum += BB((i_global+i),(j_global+k)) * temp[BS*k + j];\n                    }\n                    i_here = i_global + i;\n                    j_here = j_global + j;\n                    a[size*i_here + j_here] = ( a[size*i_here+j_here] - sum ) / a[size*(offset+j) + offset+j];\n                }\n            }\n\n        }\n        \n        // update interior block matrices\n        //\n        chunks_per_inter = chunks_in_inter_row*chunks_in_inter_row;\n\n#pragma omp parallel for schedule(auto) default(none) \\\n         private(chunk_idx ) shared(size, chunks_per_inter, chunks_in_inter_row, offset, a) \n        for  (chunk_idx =0; chunk_idx < chunks_per_inter; chunk_idx++)\n        {\n            int i, j, k, i_global, j_global;\n            float temp_top[BS*BS] __attribute__ ((aligned (64)));\n            float temp_left[BS*BS] __attribute__ ((aligned (64)));\n            float sum[BS] __attribute__ ((aligned (64))) = {0.f};\n            \n            i_global = offset + BS * (1 +  chunk_idx/chunks_in_inter_row);\n            j_global = offset + BS * (1 + chunk_idx%chunks_in_inter_row);\n\n            for (i = 0; i < BS; i++) {\n#pragma omp simd\n                for (j =0; j < BS; j++){\n                    temp_top[i*BS + j]  = a[size*(i + offset) + j + j_global ];\n                    temp_left[i*BS + j] = a[size*(i + i_global) + offset + j];\n                }\n            }\n\n            for (i = 0; i < BS; i++)\n            {\n                for (k=0; k < BS; k++) {\n#pragma omp simd \n                    for (j = 0; j < BS; j++) {\n                        sum[j] += temp_left[BS*i + k] * temp_top[BS*k + j];\n                    }\n                }\n#pragma omp simd \n                for (j = 0; j < BS; j++) {\n                    BB((i+i_global),(j+j_global)) -= sum[j];\n                    sum[j] = 0.f;\n                }\n            }\n        }\n    }\n\n    lud_diagonal_omp(a, size, offset);\n#ifdef OMP_OFFLOAD\n}\n#endif\n\n}\n""",Does this code demonstrate the use of SIMD instructions with OpenMP?,Yes
Rodinia-LUD,"#include <stdio.h>\n#include <omp.h>\n\nextern int omp_num_threads;\n\n#define BS 16\n\n#define AA(_i,_j) a[offset*size+_i*size+_j+offset]\n#define BB(_i,_j) a[_i*size+_j]\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(push, target(mic))\n#endif\n\nvoid lud_diagonal_omp (float* a, int size, int offset)\n{\n    int i, j, k;\n    for (i = 0; i < BS; i++) {\n\n        for (j = i; j < BS; j++) {\n            for (k = 0; k < i ; k++) {\n                AA(i,j) = AA(i,j) - AA(i,k) * AA(k,j);\n            }\n        }\n   \n        float temp = 1.f/AA(i,i);\n        for (j = i+1; j < BS; j++) {\n            for (k = 0; k < i ; k++) {\n                AA(j,i) = AA(j,i) - AA(j,k) * AA(k,i);\n            }\n            AA(j,i) = AA(j,i)*temp;\n        }\n    }\n\n}\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(pop)\n#endif\n\n\n// implements block LU factorization \nvoid lud_omp(float *a, int size)\n{\n    int offset, chunk_idx, size_inter, chunks_in_inter_row, chunks_per_inter;\n\n#ifdef OMP_OFFLOAD\n#pragma omp target map(to: size) map(a[0:size*size])\n#endif\n\n#ifdef OMP_OFFLOAD\n{\n    omp_set_num_threads(224);\n#else\n    printf(\running OMP on host\\n\"");\n    omp_set_num_threads(omp_num_threads);\n#endif\n    for (offset = 0; offset < size - BS ; offset += BS)\n    {\n        // lu factorization of left-top corner block diagonal matrix \n        //\n        lud_diagonal_omp(a, size, offset);\n            \n        size_inter = size - offset -  BS;\n        chunks_in_inter_row  = size_inter/BS;\n        \n        // calculate perimeter block matrices\n        // \n        #pragma omp parallel for default(none) \\\n          private(chunk_idx) shared(size, chunks_per_inter, chunks_in_inter_row, offset, a) \n        for ( chunk_idx = 0; chunk_idx < chunks_in_inter_row; chunk_idx++)\n        {\n            int i, j, k, i_global, j_global, i_here, j_here;\n            float sum;           \n            float temp[BS*BS] __attribute__ ((aligned (64)));\n\n            for (i = 0; i < BS; i++) {\n                #pragma omp simd\n                for (j =0; j < BS; j++){\n                    temp[i*BS + j] = a[size*(i + offset) + offset + j ];\n                }\n            }\n            i_global = offset;\n            j_global = offset;\n            \n            // processing top perimeter\n            //\n            j_global += BS * (chunk_idx+1);\n            for (j = 0; j < BS; j++) {\n                for (i = 0; i < BS; i++) {\n                    sum = 0.f;\n                    for (k=0; k < i; k++) {\n                        sum += temp[BS*i +k] * BB((i_global+k),(j_global+j));\n                    }\n                    i_here = i_global + i;\n                    j_here = j_global + j;\n                    BB(i_here, j_here) = BB(i_here,j_here) - sum;\n                }\n            }\n\n            // processing left perimeter\n            //\n            j_global = offset;\n            i_global += BS * (chunk_idx + 1);\n            for (i = 0; i < BS; i++) {\n                for (j = 0; j < BS; j++) {\n                    sum = 0.f;\n                    for (k=0; k < j; k++) {\n                        sum += BB((i_global+i),(j_global+k)) * temp[BS*k + j];\n                    }\n                    i_here = i_global + i;\n                    j_here = j_global + j;\n                    a[size*i_here + j_here] = ( a[size*i_here+j_here] - sum ) / a[size*(offset+j) + offset+j];\n                }\n            }\n\n        }\n        \n        // update interior block matrices\n        //\n        chunks_per_inter = chunks_in_inter_row*chunks_in_inter_row;\n\n#pragma omp parallel for schedule(auto) default(none) \\\n         private(chunk_idx ) shared(size, chunks_per_inter, chunks_in_inter_row, offset, a) \n        for  (chunk_idx =0; chunk_idx < chunks_per_inter; chunk_idx++)\n        {\n            int i, j, k, i_global, j_global;\n            float temp_top[BS*BS] __attribute__ ((aligned (64)));\n            float temp_left[BS*BS] __attribute__ ((aligned (64)));\n            float sum[BS] __attribute__ ((aligned (64))) = {0.f};\n            \n            i_global = offset + BS * (1 +  chunk_idx/chunks_in_inter_row);\n            j_global = offset + BS * (1 + chunk_idx%chunks_in_inter_row);\n\n            for (i = 0; i < BS; i++) {\n#pragma omp simd\n                for (j =0; j < BS; j++){\n                    temp_top[i*BS + j]  = a[size*(i + offset) + j + j_global ];\n                    temp_left[i*BS + j] = a[size*(i + i_global) + offset + j];\n                }\n            }\n\n            for (i = 0; i < BS; i++)\n            {\n                for (k=0; k < BS; k++) {\n#pragma omp simd \n                    for (j = 0; j < BS; j++) {\n                        sum[j] += temp_left[BS*i + k] * temp_top[BS*k + j];\n                    }\n                }\n#pragma omp simd \n                for (j = 0; j < BS; j++) {\n                    BB((i+i_global),(j+j_global)) -= sum[j];\n                    sum[j] = 0.f;\n                }\n            }\n        }\n    }\n\n    lud_diagonal_omp(a, size, offset);\n#ifdef OMP_OFFLOAD\n}\n#endif\n\n}\n""",Is there any instance of barrier synchronization in the given OpenMP code?,No
Rodinia-LUD,"#include <stdio.h>\n#include <omp.h>\n\nextern int omp_num_threads;\n\n#define BS 16\n\n#define AA(_i,_j) a[offset*size+_i*size+_j+offset]\n#define BB(_i,_j) a[_i*size+_j]\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(push, target(mic))\n#endif\n\nvoid lud_diagonal_omp (float* a, int size, int offset)\n{\n    int i, j, k;\n    for (i = 0; i < BS; i++) {\n\n        for (j = i; j < BS; j++) {\n            for (k = 0; k < i ; k++) {\n                AA(i,j) = AA(i,j) - AA(i,k) * AA(k,j);\n            }\n        }\n   \n        float temp = 1.f/AA(i,i);\n        for (j = i+1; j < BS; j++) {\n            for (k = 0; k < i ; k++) {\n                AA(j,i) = AA(j,i) - AA(j,k) * AA(k,i);\n            }\n            AA(j,i) = AA(j,i)*temp;\n        }\n    }\n\n}\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(pop)\n#endif\n\n\n// implements block LU factorization \nvoid lud_omp(float *a, int size)\n{\n    int offset, chunk_idx, size_inter, chunks_in_inter_row, chunks_per_inter;\n\n#ifdef OMP_OFFLOAD\n#pragma omp target map(to: size) map(a[0:size*size])\n#endif\n\n#ifdef OMP_OFFLOAD\n{\n    omp_set_num_threads(224);\n#else\n    printf(\running OMP on host\\n\"");\n    omp_set_num_threads(omp_num_threads);\n#endif\n    for (offset = 0; offset < size - BS ; offset += BS)\n    {\n        // lu factorization of left-top corner block diagonal matrix \n        //\n        lud_diagonal_omp(a, size, offset);\n            \n        size_inter = size - offset -  BS;\n        chunks_in_inter_row  = size_inter/BS;\n        \n        // calculate perimeter block matrices\n        // \n        #pragma omp parallel for default(none) \\\n          private(chunk_idx) shared(size, chunks_per_inter, chunks_in_inter_row, offset, a) \n        for ( chunk_idx = 0; chunk_idx < chunks_in_inter_row; chunk_idx++)\n        {\n            int i, j, k, i_global, j_global, i_here, j_here;\n            float sum;           \n            float temp[BS*BS] __attribute__ ((aligned (64)));\n\n            for (i = 0; i < BS; i++) {\n                #pragma omp simd\n                for (j =0; j < BS; j++){\n                    temp[i*BS + j] = a[size*(i + offset) + offset + j ];\n                }\n            }\n            i_global = offset;\n            j_global = offset;\n            \n            // processing top perimeter\n            //\n            j_global += BS * (chunk_idx+1);\n            for (j = 0; j < BS; j++) {\n                for (i = 0; i < BS; i++) {\n                    sum = 0.f;\n                    for (k=0; k < i; k++) {\n                        sum += temp[BS*i +k] * BB((i_global+k),(j_global+j));\n                    }\n                    i_here = i_global + i;\n                    j_here = j_global + j;\n                    BB(i_here, j_here) = BB(i_here,j_here) - sum;\n                }\n            }\n\n            // processing left perimeter\n            //\n            j_global = offset;\n            i_global += BS * (chunk_idx + 1);\n            for (i = 0; i < BS; i++) {\n                for (j = 0; j < BS; j++) {\n                    sum = 0.f;\n                    for (k=0; k < j; k++) {\n                        sum += BB((i_global+i),(j_global+k)) * temp[BS*k + j];\n                    }\n                    i_here = i_global + i;\n                    j_here = j_global + j;\n                    a[size*i_here + j_here] = ( a[size*i_here+j_here] - sum ) / a[size*(offset+j) + offset+j];\n                }\n            }\n\n        }\n        \n        // update interior block matrices\n        //\n        chunks_per_inter = chunks_in_inter_row*chunks_in_inter_row;\n\n#pragma omp parallel for schedule(auto) default(none) \\\n         private(chunk_idx ) shared(size, chunks_per_inter, chunks_in_inter_row, offset, a) \n        for  (chunk_idx =0; chunk_idx < chunks_per_inter; chunk_idx++)\n        {\n            int i, j, k, i_global, j_global;\n            float temp_top[BS*BS] __attribute__ ((aligned (64)));\n            float temp_left[BS*BS] __attribute__ ((aligned (64)));\n            float sum[BS] __attribute__ ((aligned (64))) = {0.f};\n            \n            i_global = offset + BS * (1 +  chunk_idx/chunks_in_inter_row);\n            j_global = offset + BS * (1 + chunk_idx%chunks_in_inter_row);\n\n            for (i = 0; i < BS; i++) {\n#pragma omp simd\n                for (j =0; j < BS; j++){\n                    temp_top[i*BS + j]  = a[size*(i + offset) + j + j_global ];\n                    temp_left[i*BS + j] = a[size*(i + i_global) + offset + j];\n                }\n            }\n\n            for (i = 0; i < BS; i++)\n            {\n                for (k=0; k < BS; k++) {\n#pragma omp simd \n                    for (j = 0; j < BS; j++) {\n                        sum[j] += temp_left[BS*i + k] * temp_top[BS*k + j];\n                    }\n                }\n#pragma omp simd \n                for (j = 0; j < BS; j++) {\n                    BB((i+i_global),(j+j_global)) -= sum[j];\n                    sum[j] = 0.f;\n                }\n            }\n        }\n    }\n\n    lud_diagonal_omp(a, size, offset);\n#ifdef OMP_OFFLOAD\n}\n#endif\n\n}\n""",Does the code use OpenMP's tasking feature to manage the parallel execution of tasks?,No
Rodinia-LUD,"#include <stdio.h>\n#include <omp.h>\n\nextern int omp_num_threads;\n\n#define BS 16\n\n#define AA(_i,_j) a[offset*size+_i*size+_j+offset]\n#define BB(_i,_j) a[_i*size+_j]\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(push, target(mic))\n#endif\n\nvoid lud_diagonal_omp (float* a, int size, int offset)\n{\n    int i, j, k;\n    for (i = 0; i < BS; i++) {\n\n        for (j = i; j < BS; j++) {\n            for (k = 0; k < i ; k++) {\n                AA(i,j) = AA(i,j) - AA(i,k) * AA(k,j);\n            }\n        }\n   \n        float temp = 1.f/AA(i,i);\n        for (j = i+1; j < BS; j++) {\n            for (k = 0; k < i ; k++) {\n                AA(j,i) = AA(j,i) - AA(j,k) * AA(k,i);\n            }\n            AA(j,i) = AA(j,i)*temp;\n        }\n    }\n\n}\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(pop)\n#endif\n\n\n// implements block LU factorization \nvoid lud_omp(float *a, int size)\n{\n    int offset, chunk_idx, size_inter, chunks_in_inter_row, chunks_per_inter;\n\n#ifdef OMP_OFFLOAD\n#pragma omp target map(to: size) map(a[0:size*size])\n#endif\n\n#ifdef OMP_OFFLOAD\n{\n    omp_set_num_threads(224);\n#else\n    printf(\running OMP on host\\n\"");\n    omp_set_num_threads(omp_num_threads);\n#endif\n    for (offset = 0; offset < size - BS ; offset += BS)\n    {\n        // lu factorization of left-top corner block diagonal matrix \n        //\n        lud_diagonal_omp(a, size, offset);\n            \n        size_inter = size - offset -  BS;\n        chunks_in_inter_row  = size_inter/BS;\n        \n        // calculate perimeter block matrices\n        // \n        #pragma omp parallel for default(none) \\\n          private(chunk_idx) shared(size, chunks_per_inter, chunks_in_inter_row, offset, a) \n        for ( chunk_idx = 0; chunk_idx < chunks_in_inter_row; chunk_idx++)\n        {\n            int i, j, k, i_global, j_global, i_here, j_here;\n            float sum;           \n            float temp[BS*BS] __attribute__ ((aligned (64)));\n\n            for (i = 0; i < BS; i++) {\n                #pragma omp simd\n                for (j =0; j < BS; j++){\n                    temp[i*BS + j] = a[size*(i + offset) + offset + j ];\n                }\n            }\n            i_global = offset;\n            j_global = offset;\n            \n            // processing top perimeter\n            //\n            j_global += BS * (chunk_idx+1);\n            for (j = 0; j < BS; j++) {\n                for (i = 0; i < BS; i++) {\n                    sum = 0.f;\n                    for (k=0; k < i; k++) {\n                        sum += temp[BS*i +k] * BB((i_global+k),(j_global+j));\n                    }\n                    i_here = i_global + i;\n                    j_here = j_global + j;\n                    BB(i_here, j_here) = BB(i_here,j_here) - sum;\n                }\n            }\n\n            // processing left perimeter\n            //\n            j_global = offset;\n            i_global += BS * (chunk_idx + 1);\n            for (i = 0; i < BS; i++) {\n                for (j = 0; j < BS; j++) {\n                    sum = 0.f;\n                    for (k=0; k < j; k++) {\n                        sum += BB((i_global+i),(j_global+k)) * temp[BS*k + j];\n                    }\n                    i_here = i_global + i;\n                    j_here = j_global + j;\n                    a[size*i_here + j_here] = ( a[size*i_here+j_here] - sum ) / a[size*(offset+j) + offset+j];\n                }\n            }\n\n        }\n        \n        // update interior block matrices\n        //\n        chunks_per_inter = chunks_in_inter_row*chunks_in_inter_row;\n\n#pragma omp parallel for schedule(auto) default(none) \\\n         private(chunk_idx ) shared(size, chunks_per_inter, chunks_in_inter_row, offset, a) \n        for  (chunk_idx =0; chunk_idx < chunks_per_inter; chunk_idx++)\n        {\n            int i, j, k, i_global, j_global;\n            float temp_top[BS*BS] __attribute__ ((aligned (64)));\n            float temp_left[BS*BS] __attribute__ ((aligned (64)));\n            float sum[BS] __attribute__ ((aligned (64))) = {0.f};\n            \n            i_global = offset + BS * (1 +  chunk_idx/chunks_in_inter_row);\n            j_global = offset + BS * (1 + chunk_idx%chunks_in_inter_row);\n\n            for (i = 0; i < BS; i++) {\n#pragma omp simd\n                for (j =0; j < BS; j++){\n                    temp_top[i*BS + j]  = a[size*(i + offset) + j + j_global ];\n                    temp_left[i*BS + j] = a[size*(i + i_global) + offset + j];\n                }\n            }\n\n            for (i = 0; i < BS; i++)\n            {\n                for (k=0; k < BS; k++) {\n#pragma omp simd \n                    for (j = 0; j < BS; j++) {\n                        sum[j] += temp_left[BS*i + k] * temp_top[BS*k + j];\n                    }\n                }\n#pragma omp simd \n                for (j = 0; j < BS; j++) {\n                    BB((i+i_global),(j+j_global)) -= sum[j];\n                    sum[j] = 0.f;\n                }\n            }\n        }\n    }\n\n    lud_diagonal_omp(a, size, offset);\n#ifdef OMP_OFFLOAD\n}\n#endif\n\n}\n""",Is the number of threads explicitly set in this code using 'omp_set_num_threads(224)'?,Yes
Rodinia-LUD,"#include <stdio.h>\n#include <omp.h>\n\nextern int omp_num_threads;\n\n#define BS 16\n\n#define AA(_i,_j) a[offset*size+_i*size+_j+offset]\n#define BB(_i,_j) a[_i*size+_j]\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(push, target(mic))\n#endif\n\nvoid lud_diagonal_omp (float* a, int size, int offset)\n{\n    int i, j, k;\n    for (i = 0; i < BS; i++) {\n\n        for (j = i; j < BS; j++) {\n            for (k = 0; k < i ; k++) {\n                AA(i,j) = AA(i,j) - AA(i,k) * AA(k,j);\n            }\n        }\n   \n        float temp = 1.f/AA(i,i);\n        for (j = i+1; j < BS; j++) {\n            for (k = 0; k < i ; k++) {\n                AA(j,i) = AA(j,i) - AA(j,k) * AA(k,i);\n            }\n            AA(j,i) = AA(j,i)*temp;\n        }\n    }\n\n}\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(pop)\n#endif\n\n\n// implements block LU factorization \nvoid lud_omp(float *a, int size)\n{\n    int offset, chunk_idx, size_inter, chunks_in_inter_row, chunks_per_inter;\n\n#ifdef OMP_OFFLOAD\n#pragma omp target map(to: size) map(a[0:size*size])\n#endif\n\n#ifdef OMP_OFFLOAD\n{\n    omp_set_num_threads(224);\n#else\n    printf(\running OMP on host\\n\"");\n    omp_set_num_threads(omp_num_threads);\n#endif\n    for (offset = 0; offset < size - BS ; offset += BS)\n    {\n        // lu factorization of left-top corner block diagonal matrix \n        //\n        lud_diagonal_omp(a, size, offset);\n            \n        size_inter = size - offset -  BS;\n        chunks_in_inter_row  = size_inter/BS;\n        \n        // calculate perimeter block matrices\n        // \n        #pragma omp parallel for default(none) \\\n          private(chunk_idx) shared(size, chunks_per_inter, chunks_in_inter_row, offset, a) \n        for ( chunk_idx = 0; chunk_idx < chunks_in_inter_row; chunk_idx++)\n        {\n            int i, j, k, i_global, j_global, i_here, j_here;\n            float sum;           \n            float temp[BS*BS] __attribute__ ((aligned (64)));\n\n            for (i = 0; i < BS; i++) {\n                #pragma omp simd\n                for (j =0; j < BS; j++){\n                    temp[i*BS + j] = a[size*(i + offset) + offset + j ];\n                }\n            }\n            i_global = offset;\n            j_global = offset;\n            \n            // processing top perimeter\n            //\n            j_global += BS * (chunk_idx+1);\n            for (j = 0; j < BS; j++) {\n                for (i = 0; i < BS; i++) {\n                    sum = 0.f;\n                    for (k=0; k < i; k++) {\n                        sum += temp[BS*i +k] * BB((i_global+k),(j_global+j));\n                    }\n                    i_here = i_global + i;\n                    j_here = j_global + j;\n                    BB(i_here, j_here) = BB(i_here,j_here) - sum;\n                }\n            }\n\n            // processing left perimeter\n            //\n            j_global = offset;\n            i_global += BS * (chunk_idx + 1);\n            for (i = 0; i < BS; i++) {\n                for (j = 0; j < BS; j++) {\n                    sum = 0.f;\n                    for (k=0; k < j; k++) {\n                        sum += BB((i_global+i),(j_global+k)) * temp[BS*k + j];\n                    }\n                    i_here = i_global + i;\n                    j_here = j_global + j;\n                    a[size*i_here + j_here] = ( a[size*i_here+j_here] - sum ) / a[size*(offset+j) + offset+j];\n                }\n            }\n\n        }\n        \n        // update interior block matrices\n        //\n        chunks_per_inter = chunks_in_inter_row*chunks_in_inter_row;\n\n#pragma omp parallel for schedule(auto) default(none) \\\n         private(chunk_idx ) shared(size, chunks_per_inter, chunks_in_inter_row, offset, a) \n        for  (chunk_idx =0; chunk_idx < chunks_per_inter; chunk_idx++)\n        {\n            int i, j, k, i_global, j_global;\n            float temp_top[BS*BS] __attribute__ ((aligned (64)));\n            float temp_left[BS*BS] __attribute__ ((aligned (64)));\n            float sum[BS] __attribute__ ((aligned (64))) = {0.f};\n            \n            i_global = offset + BS * (1 +  chunk_idx/chunks_in_inter_row);\n            j_global = offset + BS * (1 + chunk_idx%chunks_in_inter_row);\n\n            for (i = 0; i < BS; i++) {\n#pragma omp simd\n                for (j =0; j < BS; j++){\n                    temp_top[i*BS + j]  = a[size*(i + offset) + j + j_global ];\n                    temp_left[i*BS + j] = a[size*(i + i_global) + offset + j];\n                }\n            }\n\n            for (i = 0; i < BS; i++)\n            {\n                for (k=0; k < BS; k++) {\n#pragma omp simd \n                    for (j = 0; j < BS; j++) {\n                        sum[j] += temp_left[BS*i + k] * temp_top[BS*k + j];\n                    }\n                }\n#pragma omp simd \n                for (j = 0; j < BS; j++) {\n                    BB((i+i_global),(j+j_global)) -= sum[j];\n                    sum[j] = 0.f;\n                }\n            }\n        }\n    }\n\n    lud_diagonal_omp(a, size, offset);\n#ifdef OMP_OFFLOAD\n}\n#endif\n\n}\n""",Does this code use explicit data scoping (#pragma omp parallel for default(none)) to avoid race conditions and promote data locality?,Yes
Rodinia-LUD,"#include <stdio.h>\n#include <omp.h>\n\nextern int omp_num_threads;\n\n#define BS 16\n\n#define AA(_i,_j) a[offset*size+_i*size+_j+offset]\n#define BB(_i,_j) a[_i*size+_j]\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(push, target(mic))\n#endif\n\nvoid lud_diagonal_omp (float* a, int size, int offset)\n{\n    int i, j, k;\n    for (i = 0; i < BS; i++) {\n\n        for (j = i; j < BS; j++) {\n            for (k = 0; k < i ; k++) {\n                AA(i,j) = AA(i,j) - AA(i,k) * AA(k,j);\n            }\n        }\n   \n        float temp = 1.f/AA(i,i);\n        for (j = i+1; j < BS; j++) {\n            for (k = 0; k < i ; k++) {\n                AA(j,i) = AA(j,i) - AA(j,k) * AA(k,i);\n            }\n            AA(j,i) = AA(j,i)*temp;\n        }\n    }\n\n}\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(pop)\n#endif\n\n\n// implements block LU factorization \nvoid lud_omp(float *a, int size)\n{\n    int offset, chunk_idx, size_inter, chunks_in_inter_row, chunks_per_inter;\n\n#ifdef OMP_OFFLOAD\n#pragma omp target map(to: size) map(a[0:size*size])\n#endif\n\n#ifdef OMP_OFFLOAD\n{\n    omp_set_num_threads(224);\n#else\n    printf(\running OMP on host\\n\"");\n    omp_set_num_threads(omp_num_threads);\n#endif\n    for (offset = 0; offset < size - BS ; offset += BS)\n    {\n        // lu factorization of left-top corner block diagonal matrix \n        //\n        lud_diagonal_omp(a, size, offset);\n            \n        size_inter = size - offset -  BS;\n        chunks_in_inter_row  = size_inter/BS;\n        \n        // calculate perimeter block matrices\n        // \n        #pragma omp parallel for default(none) \\\n          private(chunk_idx) shared(size, chunks_per_inter, chunks_in_inter_row, offset, a) \n        for ( chunk_idx = 0; chunk_idx < chunks_in_inter_row; chunk_idx++)\n        {\n            int i, j, k, i_global, j_global, i_here, j_here;\n            float sum;           \n            float temp[BS*BS] __attribute__ ((aligned (64)));\n\n            for (i = 0; i < BS; i++) {\n                #pragma omp simd\n                for (j =0; j < BS; j++){\n                    temp[i*BS + j] = a[size*(i + offset) + offset + j ];\n                }\n            }\n            i_global = offset;\n            j_global = offset;\n            \n            // processing top perimeter\n            //\n            j_global += BS * (chunk_idx+1);\n            for (j = 0; j < BS; j++) {\n                for (i = 0; i < BS; i++) {\n                    sum = 0.f;\n                    for (k=0; k < i; k++) {\n                        sum += temp[BS*i +k] * BB((i_global+k),(j_global+j));\n                    }\n                    i_here = i_global + i;\n                    j_here = j_global + j;\n                    BB(i_here, j_here) = BB(i_here,j_here) - sum;\n                }\n            }\n\n            // processing left perimeter\n            //\n            j_global = offset;\n            i_global += BS * (chunk_idx + 1);\n            for (i = 0; i < BS; i++) {\n                for (j = 0; j < BS; j++) {\n                    sum = 0.f;\n                    for (k=0; k < j; k++) {\n                        sum += BB((i_global+i),(j_global+k)) * temp[BS*k + j];\n                    }\n                    i_here = i_global + i;\n                    j_here = j_global + j;\n                    a[size*i_here + j_here] = ( a[size*i_here+j_here] - sum ) / a[size*(offset+j) + offset+j];\n                }\n            }\n\n        }\n        \n        // update interior block matrices\n        //\n        chunks_per_inter = chunks_in_inter_row*chunks_in_inter_row;\n\n#pragma omp parallel for schedule(auto) default(none) \\\n         private(chunk_idx ) shared(size, chunks_per_inter, chunks_in_inter_row, offset, a) \n        for  (chunk_idx =0; chunk_idx < chunks_per_inter; chunk_idx++)\n        {\n            int i, j, k, i_global, j_global;\n            float temp_top[BS*BS] __attribute__ ((aligned (64)));\n            float temp_left[BS*BS] __attribute__ ((aligned (64)));\n            float sum[BS] __attribute__ ((aligned (64))) = {0.f};\n            \n            i_global = offset + BS * (1 +  chunk_idx/chunks_in_inter_row);\n            j_global = offset + BS * (1 + chunk_idx%chunks_in_inter_row);\n\n            for (i = 0; i < BS; i++) {\n#pragma omp simd\n                for (j =0; j < BS; j++){\n                    temp_top[i*BS + j]  = a[size*(i + offset) + j + j_global ];\n                    temp_left[i*BS + j] = a[size*(i + i_global) + offset + j];\n                }\n            }\n\n            for (i = 0; i < BS; i++)\n            {\n                for (k=0; k < BS; k++) {\n#pragma omp simd \n                    for (j = 0; j < BS; j++) {\n                        sum[j] += temp_left[BS*i + k] * temp_top[BS*k + j];\n                    }\n                }\n#pragma omp simd \n                for (j = 0; j < BS; j++) {\n                    BB((i+i_global),(j+j_global)) -= sum[j];\n                    sum[j] = 0.f;\n                }\n            }\n        }\n    }\n\n    lud_diagonal_omp(a, size, offset);\n#ifdef OMP_OFFLOAD\n}\n#endif\n\n}\n""",Does the code use the OpenMP 'schedule' directive to specify how iterations of the loop are distributed among the threads in the team?,Yes
Rodinia-LUD,"#include <stdio.h>\n#include <omp.h>\n\nextern int omp_num_threads;\n\n#define BS 16\n\n#define AA(_i,_j) a[offset*size+_i*size+_j+offset]\n#define BB(_i,_j) a[_i*size+_j]\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(push, target(mic))\n#endif\n\nvoid lud_diagonal_omp (float* a, int size, int offset)\n{\n    int i, j, k;\n    for (i = 0; i < BS; i++) {\n\n        for (j = i; j < BS; j++) {\n            for (k = 0; k < i ; k++) {\n                AA(i,j) = AA(i,j) - AA(i,k) * AA(k,j);\n            }\n        }\n   \n        float temp = 1.f/AA(i,i);\n        for (j = i+1; j < BS; j++) {\n            for (k = 0; k < i ; k++) {\n                AA(j,i) = AA(j,i) - AA(j,k) * AA(k,i);\n            }\n            AA(j,i) = AA(j,i)*temp;\n        }\n    }\n\n}\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(pop)\n#endif\n\n\n// implements block LU factorization \nvoid lud_omp(float *a, int size)\n{\n    int offset, chunk_idx, size_inter, chunks_in_inter_row, chunks_per_inter;\n\n#ifdef OMP_OFFLOAD\n#pragma omp target map(to: size) map(a[0:size*size])\n#endif\n\n#ifdef OMP_OFFLOAD\n{\n    omp_set_num_threads(224);\n#else\n    printf(\running OMP on host\\n\"");\n    omp_set_num_threads(omp_num_threads);\n#endif\n    for (offset = 0; offset < size - BS ; offset += BS)\n    {\n        // lu factorization of left-top corner block diagonal matrix \n        //\n        lud_diagonal_omp(a, size, offset);\n            \n        size_inter = size - offset -  BS;\n        chunks_in_inter_row  = size_inter/BS;\n        \n        // calculate perimeter block matrices\n        // \n        #pragma omp parallel for default(none) \\\n          private(chunk_idx) shared(size, chunks_per_inter, chunks_in_inter_row, offset, a) \n        for ( chunk_idx = 0; chunk_idx < chunks_in_inter_row; chunk_idx++)\n        {\n            int i, j, k, i_global, j_global, i_here, j_here;\n            float sum;           \n            float temp[BS*BS] __attribute__ ((aligned (64)));\n\n            for (i = 0; i < BS; i++) {\n                #pragma omp simd\n                for (j =0; j < BS; j++){\n                    temp[i*BS + j] = a[size*(i + offset) + offset + j ];\n                }\n            }\n            i_global = offset;\n            j_global = offset;\n            \n            // processing top perimeter\n            //\n            j_global += BS * (chunk_idx+1);\n            for (j = 0; j < BS; j++) {\n                for (i = 0; i < BS; i++) {\n                    sum = 0.f;\n                    for (k=0; k < i; k++) {\n                        sum += temp[BS*i +k] * BB((i_global+k),(j_global+j));\n                    }\n                    i_here = i_global + i;\n                    j_here = j_global + j;\n                    BB(i_here, j_here) = BB(i_here,j_here) - sum;\n                }\n            }\n\n            // processing left perimeter\n            //\n            j_global = offset;\n            i_global += BS * (chunk_idx + 1);\n            for (i = 0; i < BS; i++) {\n                for (j = 0; j < BS; j++) {\n                    sum = 0.f;\n                    for (k=0; k < j; k++) {\n                        sum += BB((i_global+i),(j_global+k)) * temp[BS*k + j];\n                    }\n                    i_here = i_global + i;\n                    j_here = j_global + j;\n                    a[size*i_here + j_here] = ( a[size*i_here+j_here] - sum ) / a[size*(offset+j) + offset+j];\n                }\n            }\n\n        }\n        \n        // update interior block matrices\n        //\n        chunks_per_inter = chunks_in_inter_row*chunks_in_inter_row;\n\n#pragma omp parallel for schedule(auto) default(none) \\\n         private(chunk_idx ) shared(size, chunks_per_inter, chunks_in_inter_row, offset, a) \n        for  (chunk_idx =0; chunk_idx < chunks_per_inter; chunk_idx++)\n        {\n            int i, j, k, i_global, j_global;\n            float temp_top[BS*BS] __attribute__ ((aligned (64)));\n            float temp_left[BS*BS] __attribute__ ((aligned (64)));\n            float sum[BS] __attribute__ ((aligned (64))) = {0.f};\n            \n            i_global = offset + BS * (1 +  chunk_idx/chunks_in_inter_row);\n            j_global = offset + BS * (1 + chunk_idx%chunks_in_inter_row);\n\n            for (i = 0; i < BS; i++) {\n#pragma omp simd\n                for (j =0; j < BS; j++){\n                    temp_top[i*BS + j]  = a[size*(i + offset) + j + j_global ];\n                    temp_left[i*BS + j] = a[size*(i + i_global) + offset + j];\n                }\n            }\n\n            for (i = 0; i < BS; i++)\n            {\n                for (k=0; k < BS; k++) {\n#pragma omp simd \n                    for (j = 0; j < BS; j++) {\n                        sum[j] += temp_left[BS*i + k] * temp_top[BS*k + j];\n                    }\n                }\n#pragma omp simd \n                for (j = 0; j < BS; j++) {\n                    BB((i+i_global),(j+j_global)) -= sum[j];\n                    sum[j] = 0.f;\n                }\n            }\n        }\n    }\n\n    lud_diagonal_omp(a, size, offset);\n#ifdef OMP_OFFLOAD\n}\n#endif\n\n}\n""",Does this code use '#pragma omp simd' to hint the compiler to vectorize the code?,Yes
Rodinia-LUD,"#include <stdio.h>\n#include <omp.h>\n\nextern int omp_num_threads;\n\n#define BS 16\n\n#define AA(_i,_j) a[offset*size+_i*size+_j+offset]\n#define BB(_i,_j) a[_i*size+_j]\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(push, target(mic))\n#endif\n\nvoid lud_diagonal_omp (float* a, int size, int offset)\n{\n    int i, j, k;\n    for (i = 0; i < BS; i++) {\n\n        for (j = i; j < BS; j++) {\n            for (k = 0; k < i ; k++) {\n                AA(i,j) = AA(i,j) - AA(i,k) * AA(k,j);\n            }\n        }\n   \n        float temp = 1.f/AA(i,i);\n        for (j = i+1; j < BS; j++) {\n            for (k = 0; k < i ; k++) {\n                AA(j,i) = AA(j,i) - AA(j,k) * AA(k,i);\n            }\n            AA(j,i) = AA(j,i)*temp;\n        }\n    }\n\n}\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(pop)\n#endif\n\n\n// implements block LU factorization \nvoid lud_omp(float *a, int size)\n{\n    int offset, chunk_idx, size_inter, chunks_in_inter_row, chunks_per_inter;\n\n#ifdef OMP_OFFLOAD\n#pragma omp target map(to: size) map(a[0:size*size])\n#endif\n\n#ifdef OMP_OFFLOAD\n{\n    omp_set_num_threads(224);\n#else\n    printf(\running OMP on host\\n\"");\n    omp_set_num_threads(omp_num_threads);\n#endif\n    for (offset = 0; offset < size - BS ; offset += BS)\n    {\n        // lu factorization of left-top corner block diagonal matrix \n        //\n        lud_diagonal_omp(a, size, offset);\n            \n        size_inter = size - offset -  BS;\n        chunks_in_inter_row  = size_inter/BS;\n        \n        // calculate perimeter block matrices\n        // \n        #pragma omp parallel for default(none) \\\n          private(chunk_idx) shared(size, chunks_per_inter, chunks_in_inter_row, offset, a) \n        for ( chunk_idx = 0; chunk_idx < chunks_in_inter_row; chunk_idx++)\n        {\n            int i, j, k, i_global, j_global, i_here, j_here;\n            float sum;           \n            float temp[BS*BS] __attribute__ ((aligned (64)));\n\n            for (i = 0; i < BS; i++) {\n                #pragma omp simd\n                for (j =0; j < BS; j++){\n                    temp[i*BS + j] = a[size*(i + offset) + offset + j ];\n                }\n            }\n            i_global = offset;\n            j_global = offset;\n            \n            // processing top perimeter\n            //\n            j_global += BS * (chunk_idx+1);\n            for (j = 0; j < BS; j++) {\n                for (i = 0; i < BS; i++) {\n                    sum = 0.f;\n                    for (k=0; k < i; k++) {\n                        sum += temp[BS*i +k] * BB((i_global+k),(j_global+j));\n                    }\n                    i_here = i_global + i;\n                    j_here = j_global + j;\n                    BB(i_here, j_here) = BB(i_here,j_here) - sum;\n                }\n            }\n\n            // processing left perimeter\n            //\n            j_global = offset;\n            i_global += BS * (chunk_idx + 1);\n            for (i = 0; i < BS; i++) {\n                for (j = 0; j < BS; j++) {\n                    sum = 0.f;\n                    for (k=0; k < j; k++) {\n                        sum += BB((i_global+i),(j_global+k)) * temp[BS*k + j];\n                    }\n                    i_here = i_global + i;\n                    j_here = j_global + j;\n                    a[size*i_here + j_here] = ( a[size*i_here+j_here] - sum ) / a[size*(offset+j) + offset+j];\n                }\n            }\n\n        }\n        \n        // update interior block matrices\n        //\n        chunks_per_inter = chunks_in_inter_row*chunks_in_inter_row;\n\n#pragma omp parallel for schedule(auto) default(none) \\\n         private(chunk_idx ) shared(size, chunks_per_inter, chunks_in_inter_row, offset, a) \n        for  (chunk_idx =0; chunk_idx < chunks_per_inter; chunk_idx++)\n        {\n            int i, j, k, i_global, j_global;\n            float temp_top[BS*BS] __attribute__ ((aligned (64)));\n            float temp_left[BS*BS] __attribute__ ((aligned (64)));\n            float sum[BS] __attribute__ ((aligned (64))) = {0.f};\n            \n            i_global = offset + BS * (1 +  chunk_idx/chunks_in_inter_row);\n            j_global = offset + BS * (1 + chunk_idx%chunks_in_inter_row);\n\n            for (i = 0; i < BS; i++) {\n#pragma omp simd\n                for (j =0; j < BS; j++){\n                    temp_top[i*BS + j]  = a[size*(i + offset) + j + j_global ];\n                    temp_left[i*BS + j] = a[size*(i + i_global) + offset + j];\n                }\n            }\n\n            for (i = 0; i < BS; i++)\n            {\n                for (k=0; k < BS; k++) {\n#pragma omp simd \n                    for (j = 0; j < BS; j++) {\n                        sum[j] += temp_left[BS*i + k] * temp_top[BS*k + j];\n                    }\n                }\n#pragma omp simd \n                for (j = 0; j < BS; j++) {\n                    BB((i+i_global),(j+j_global)) -= sum[j];\n                    sum[j] = 0.f;\n                }\n            }\n        }\n    }\n\n    lud_diagonal_omp(a, size, offset);\n#ifdef OMP_OFFLOAD\n}\n#endif\n\n}\n""",Does the code utilize OpenMP's nested parallelism feature?,No
Rodinia-LUD,"#include <stdio.h>\n#include <omp.h>\n\nextern int omp_num_threads;\n\n#define BS 16\n\n#define AA(_i,_j) a[offset*size+_i*size+_j+offset]\n#define BB(_i,_j) a[_i*size+_j]\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(push, target(mic))\n#endif\n\nvoid lud_diagonal_omp (float* a, int size, int offset)\n{\n    int i, j, k;\n    for (i = 0; i < BS; i++) {\n\n        for (j = i; j < BS; j++) {\n            for (k = 0; k < i ; k++) {\n                AA(i,j) = AA(i,j) - AA(i,k) * AA(k,j);\n            }\n        }\n   \n        float temp = 1.f/AA(i,i);\n        for (j = i+1; j < BS; j++) {\n            for (k = 0; k < i ; k++) {\n                AA(j,i) = AA(j,i) - AA(j,k) * AA(k,i);\n            }\n            AA(j,i) = AA(j,i)*temp;\n        }\n    }\n\n}\n\n#ifdef OMP_OFFLOAD\n#pragma offload_attribute(pop)\n#endif\n\n\n// implements block LU factorization \nvoid lud_omp(float *a, int size)\n{\n    int offset, chunk_idx, size_inter, chunks_in_inter_row, chunks_per_inter;\n\n#ifdef OMP_OFFLOAD\n#pragma omp target map(to: size) map(a[0:size*size])\n#endif\n\n#ifdef OMP_OFFLOAD\n{\n    omp_set_num_threads(224);\n#else\n    printf(\running OMP on host\\n\"");\n    omp_set_num_threads(omp_num_threads);\n#endif\n    for (offset = 0; offset < size - BS ; offset += BS)\n    {\n        // lu factorization of left-top corner block diagonal matrix \n        //\n        lud_diagonal_omp(a, size, offset);\n            \n        size_inter = size - offset -  BS;\n        chunks_in_inter_row  = size_inter/BS;\n        \n        // calculate perimeter block matrices\n        // \n        #pragma omp parallel for default(none) \\\n          private(chunk_idx) shared(size, chunks_per_inter, chunks_in_inter_row, offset, a) \n        for ( chunk_idx = 0; chunk_idx < chunks_in_inter_row; chunk_idx++)\n        {\n            int i, j, k, i_global, j_global, i_here, j_here;\n            float sum;           \n            float temp[BS*BS] __attribute__ ((aligned (64)));\n\n            for (i = 0; i < BS; i++) {\n                #pragma omp simd\n                for (j =0; j < BS; j++){\n                    temp[i*BS + j] = a[size*(i + offset) + offset + j ];\n                }\n            }\n            i_global = offset;\n            j_global = offset;\n            \n            // processing top perimeter\n            //\n            j_global += BS * (chunk_idx+1);\n            for (j = 0; j < BS; j++) {\n                for (i = 0; i < BS; i++) {\n                    sum = 0.f;\n                    for (k=0; k < i; k++) {\n                        sum += temp[BS*i +k] * BB((i_global+k),(j_global+j));\n                    }\n                    i_here = i_global + i;\n                    j_here = j_global + j;\n                    BB(i_here, j_here) = BB(i_here,j_here) - sum;\n                }\n            }\n\n            // processing left perimeter\n            //\n            j_global = offset;\n            i_global += BS * (chunk_idx + 1);\n            for (i = 0; i < BS; i++) {\n                for (j = 0; j < BS; j++) {\n                    sum = 0.f;\n                    for (k=0; k < j; k++) {\n                        sum += BB((i_global+i),(j_global+k)) * temp[BS*k + j];\n                    }\n                    i_here = i_global + i;\n                    j_here = j_global + j;\n                    a[size*i_here + j_here] = ( a[size*i_here+j_here] - sum ) / a[size*(offset+j) + offset+j];\n                }\n            }\n\n        }\n        \n        // update interior block matrices\n        //\n        chunks_per_inter = chunks_in_inter_row*chunks_in_inter_row;\n\n#pragma omp parallel for schedule(auto) default(none) \\\n         private(chunk_idx ) shared(size, chunks_per_inter, chunks_in_inter_row, offset, a) \n        for  (chunk_idx =0; chunk_idx < chunks_per_inter; chunk_idx++)\n        {\n            int i, j, k, i_global, j_global;\n            float temp_top[BS*BS] __attribute__ ((aligned (64)));\n            float temp_left[BS*BS] __attribute__ ((aligned (64)));\n            float sum[BS] __attribute__ ((aligned (64))) = {0.f};\n            \n            i_global = offset + BS * (1 +  chunk_idx/chunks_in_inter_row);\n            j_global = offset + BS * (1 + chunk_idx%chunks_in_inter_row);\n\n            for (i = 0; i < BS; i++) {\n#pragma omp simd\n                for (j =0; j < BS; j++){\n                    temp_top[i*BS + j]  = a[size*(i + offset) + j + j_global ];\n                    temp_left[i*BS + j] = a[size*(i + i_global) + offset + j];\n                }\n            }\n\n            for (i = 0; i < BS; i++)\n            {\n                for (k=0; k < BS; k++) {\n#pragma omp simd \n                    for (j = 0; j < BS; j++) {\n                        sum[j] += temp_left[BS*i + k] * temp_top[BS*k + j];\n                    }\n                }\n#pragma omp simd \n                for (j = 0; j < BS; j++) {\n                    BB((i+i_global),(j+j_global)) -= sum[j];\n                    sum[j] = 0.f;\n                }\n            }\n        }\n    }\n\n    lud_diagonal_omp(a, size, offset);\n#ifdef OMP_OFFLOAD\n}\n#endif\n\n}\n""",Is OpenMP offloading to a device like a Graphics Processing Unit (GPU) being performed in this code?,No
